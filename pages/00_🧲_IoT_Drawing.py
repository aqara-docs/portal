import streamlit as st
import os
from dotenv import load_dotenv
from openai import OpenAI
import anthropic
import base64
import io
from PIL import Image
import requests
import json
from datetime import datetime
import re
import traceback
import asyncio
import threading
from concurrent.futures import ThreadPoolExecutor
import time

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
openai = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

# Anthropic í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
anthropic_client = anthropic.Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="âš¡ ì „ê¸°/IoT íšŒë¡œë„ & ê°œë…ë„ ìƒì„±ê¸°", 
    page_icon="âš¡", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ í´ë˜ìŠ¤ë“¤
class ExpertAgent:
    """ì „ë¬¸ê°€ ì—ì´ì „íŠ¸ ê¸°ë³¸ í´ë˜ìŠ¤"""
    
    def __init__(self, name, expertise, system_prompt):
        self.name = name
        self.expertise = expertise
        self.system_prompt = system_prompt
        self.conversation_history = []
    
    async def analyze_question(self, question, context=""):
        """ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  ì „ë¬¸ ë¶„ì•¼ì— ëŒ€í•œ ë‹µë³€ ìƒì„±"""
        try:
            full_prompt = f"""
            {self.system_prompt}
            
            ì‚¬ìš©ì ì§ˆë¬¸: {question}
            ì»¨í…ìŠ¤íŠ¸: {context}
            
            ë‹¹ì‹ ì˜ ì „ë¬¸ ë¶„ì•¼({self.expertise})ì— ê´€í•´ ë‹µë³€í•´ì£¼ì„¸ìš”.
            ë‹µë³€ì€ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
            1. í•µì‹¬ ë‹µë³€
            2. ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­
            3. ê¶Œì¥ì‚¬í•­
            4. ì¶”ê°€ ê³ ë ¤ì‚¬í•­
            """
            
            response = openai.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": full_prompt}],
                temperature=0.7,
                max_tokens=1000
            )
            
            answer = response.choices[0].message.content
            self.conversation_history.append({
                "question": question,
                "answer": answer,
                "timestamp": datetime.now()
            })
            
            return answer
            
        except Exception as e:
            return f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    
    def needs_drawing(self, question, answer):
        """ë„ë©´ ìƒì„±ì´ í•„ìš”í•œì§€ íŒë‹¨"""
        drawing_keywords = [
            "íšŒë¡œë„", "ë°°ì„ ë„", "ë„ë©´", "ë‹¤ì´ì–´ê·¸ë¨", "ì‹œìŠ¤í…œ êµ¬ì„±ë„", 
            "ë°°ì¹˜ë„", "ì—°ê²°ë„", "í† í´ë¡œì§€", "ì•„í‚¤í…ì²˜", "ì„¤ê³„ë„"
        ]
        
        question_lower = question.lower()
        answer_lower = answer.lower()
        
        for keyword in drawing_keywords:
            if keyword in question_lower or keyword in answer_lower:
                return True
        
        return False

class IoTExpert(ExpertAgent):
    """IoT ì „ë¬¸ê°€ ì—ì´ì „íŠ¸"""
    
    def __init__(self):
        super().__init__(
            name="IoT ì „ë¬¸ê°€",
            expertise="IoT ì‹œìŠ¤í…œ ì„¤ê³„ ë° êµ¬í˜„",
            system_prompt="""
            ë‹¹ì‹ ì€ IoT(Internet of Things) ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
            ë‹¤ìŒ ë¶„ì•¼ì— ëŒ€í•œ ì „ë¬¸ ì§€ì‹ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤:
            - IoT ë””ë°”ì´ìŠ¤ ë° ì„¼ì„œ ê¸°ìˆ 
            - ë¬´ì„  í†µì‹  í”„ë¡œí† ì½œ (WiFi, Bluetooth, Zigbee, LoRa, NB-IoT)
            - IoT í”Œë«í¼ ë° í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤
            - ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„
            - IoT ë³´ì•ˆ ë° í”„ë¼ì´ë²„ì‹œ
            - ì—£ì§€ ì»´í“¨íŒ… ë° íŒì›¨ì–´
            - IoT ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ì„¤ê³„
            
            í•­ìƒ ì‹¤ìš©ì ì´ê³  êµ¬í˜„ ê°€ëŠ¥í•œ ì†”ë£¨ì…˜ì„ ì œì‹œí•˜ì„¸ìš”.
            """
        )

class AIExpert(ExpertAgent):
    """AI ì „ë¬¸ê°€ ì—ì´ì „íŠ¸"""
    
    def __init__(self):
        super().__init__(
            name="AI ì „ë¬¸ê°€",
            expertise="ì¸ê³µì§€ëŠ¥ ë° ë¨¸ì‹ ëŸ¬ë‹",
            system_prompt="""
            ë‹¹ì‹ ì€ AI(ì¸ê³µì§€ëŠ¥) ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
            ë‹¤ìŒ ë¶„ì•¼ì— ëŒ€í•œ ì „ë¬¸ ì§€ì‹ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤:
            - ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ ë° ëª¨ë¸
            - ë”¥ëŸ¬ë‹ ë° ì‹ ê²½ë§
            - ì»´í“¨í„° ë¹„ì „ ë° ì´ë¯¸ì§€ ì²˜ë¦¬
            - ìì—°ì–´ ì²˜ë¦¬ (NLP)
            - ê°•í™”í•™ìŠµ ë° ìµœì í™”
            - AI í•˜ë“œì›¨ì–´ ë° ì—£ì§€ AI
            - AI ìœ¤ë¦¬ ë° ì±…ì„ìˆëŠ” AI
            - AI ì‹œìŠ¤í…œ í†µí•© ë° ë°°í¬
            
            ìµœì‹  AI íŠ¸ë Œë“œì™€ ì‹¤ìš©ì ì¸ ì ìš© ë°©ì•ˆì„ ì œì‹œí•˜ì„¸ìš”.
            """
        )

class ElectricalExpert(ExpertAgent):
    """ì „ê¸° ì „ë¬¸ê°€ ì—ì´ì „íŠ¸"""
    
    def __init__(self):
        super().__init__(
            name="ì „ê¸° ì „ë¬¸ê°€",
            expertise="ì „ê¸° ì‹œìŠ¤í…œ ì„¤ê³„ ë° ì•ˆì „",
            system_prompt="""
            ë‹¹ì‹ ì€ ì „ê¸° ì‹œìŠ¤í…œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
            ë‹¤ìŒ ë¶„ì•¼ì— ëŒ€í•œ ì „ë¬¸ ì§€ì‹ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤:
            - ì „ê¸°íšŒë¡œ ì„¤ê³„ ë° ë¶„ì„
            - ì „ë ¥ ì‹œìŠ¤í…œ ë° ë¶„ë°°
            - ì „ê¸° ì•ˆì „ ë° ë³´í˜¸ ì¥ì¹˜
            - ì „ê¸° ì½”ë“œ ë° ê·œê²© (NEC, IEC, KS)
            - ì „ê¸° ì¸¡ì • ë° ê³„ì¸¡
            - ì „ê¸° ê¸°ê¸° ë° ì¥ë¹„
            - ì „ê¸° ì‹œê³µ ë° ìœ ì§€ë³´ìˆ˜
            - ì „ê¸° ì—ë„ˆì§€ íš¨ìœ¨ì„±
            
            í•­ìƒ ì•ˆì „ì„ ìµœìš°ì„ ìœ¼ë¡œ í•˜ëŠ” ì†”ë£¨ì…˜ì„ ì œì‹œí•˜ì„¸ìš”.
            """
        )

class LightingExpert(ExpertAgent):
    """ì¡°ëª… ì „ë¬¸ê°€ ì—ì´ì „íŠ¸"""
    
    def __init__(self):
        super().__init__(
            name="ì¡°ëª… ì „ë¬¸ê°€",
            expertise="ì¡°ëª… ì‹œìŠ¤í…œ ì„¤ê³„ ë° ì œì–´",
            system_prompt="""
            ë‹¹ì‹ ì€ ì¡°ëª… ì‹œìŠ¤í…œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
            ë‹¤ìŒ ë¶„ì•¼ì— ëŒ€í•œ ì „ë¬¸ ì§€ì‹ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤:
            - LED ì¡°ëª… ê¸°ìˆ  ë° ì œì–´
            - ì¡°ëª… ì„¤ê³„ ë° ì¡°ë„ ê³„ì‚°
            - ìŠ¤ë§ˆíŠ¸ ì¡°ëª… ì‹œìŠ¤í…œ
            - ì¡°ëª… ì œì–´ í”„ë¡œí† ì½œ (DALI, DMX, 0-10V)
            - ìƒ‰ì˜¨ë„ ë° ìƒ‰ ë Œë”ë§ ì§€ìˆ˜
            - ì—ë„ˆì§€ íš¨ìœ¨ ì¡°ëª… ì†”ë£¨ì…˜
            - ì¸ê°„ ì¤‘ì‹¬ ì¡°ëª… (HCL)
            - ì¡°ëª… ìë™í™” ë° IoT í†µí•©
            
            ì‚¬ìš©ì ê²½í—˜ê³¼ ì—ë„ˆì§€ íš¨ìœ¨ì„±ì„ ê³ ë ¤í•œ ì†”ë£¨ì…˜ì„ ì œì‹œí•˜ì„¸ìš”.
            """
        )

class ProjectManager(ExpertAgent):
    """í”„ë¡œì íŠ¸ ë§¤ë‹ˆì € ì—ì´ì „íŠ¸"""
    
    def __init__(self):
        super().__init__(
            name="í”„ë¡œì íŠ¸ ë§¤ë‹ˆì €",
            expertise="í”„ë¡œì íŠ¸ ê´€ë¦¬ ë° í†µí•©",
            system_prompt="""
            ë‹¹ì‹ ì€ í”„ë¡œì íŠ¸ ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.
            ë‹¤ìŒ ë¶„ì•¼ì— ëŒ€í•œ ì „ë¬¸ ì§€ì‹ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤:
            - í”„ë¡œì íŠ¸ ê³„íš ë° ì¼ì • ê´€ë¦¬
            - ì˜ˆì‚° ê´€ë¦¬ ë° ë¹„ìš© ë¶„ì„
            - ë¦¬ìŠ¤í¬ ê´€ë¦¬ ë° í’ˆì§ˆ ë³´ì¦
            - íŒ€ ê´€ë¦¬ ë° ì»¤ë®¤ë‹ˆì¼€ì´ì…˜
            - ê³µê¸‰ì—…ì²´ ê´€ë¦¬ ë° ê³„ì•½
            - í”„ë¡œì íŠ¸ ìƒëª…ì£¼ê¸° ê´€ë¦¬
            - ë³€ê²½ ê´€ë¦¬ ë° í†µí•©
            - í”„ë¡œì íŠ¸ ì„±ê³µ ì§€í‘œ ë° í‰ê°€
            
            ì‹¤í˜„ ê°€ëŠ¥í•˜ê³  íš¨ìœ¨ì ì¸ í”„ë¡œì íŠ¸ ë°©ì•ˆì„ ì œì‹œí•˜ì„¸ìš”.
            """
        )

class MultiAgentSystem:
    """ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ê´€ë¦¬ì"""
    
    def __init__(self):
        self.agents = {
            "iot": IoTExpert(),
            "ai": AIExpert(),
            "electrical": ElectricalExpert(),
            "lighting": LightingExpert(),
            "pm": ProjectManager()
        }
        self.conversation_history = []
    
    async def process_question(self, question, selected_experts=None):
        """ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ê³  ê´€ë ¨ ì „ë¬¸ê°€ë“¤ì˜ ë‹µë³€ì„ ìˆ˜ì§‘"""
        if selected_experts is None:
            selected_experts = list(self.agents.keys())
        
        results = {}
        
        # ê° ì „ë¬¸ê°€ì˜ ë‹µë³€ ìˆ˜ì§‘
        for expert_key in selected_experts:
            if expert_key in self.agents:
                agent = self.agents[expert_key]
                answer = await agent.analyze_question(question)
                results[expert_key] = {
                    "agent": agent,
                    "answer": answer,
                    "needs_drawing": agent.needs_drawing(question, answer)
                }
        
        # ëŒ€í™” ê¸°ë¡ ì €ì¥
        self.conversation_history.append({
            "question": question,
            "answers": results,
            "timestamp": datetime.now()
        })
        
        return results
    
    def get_integrated_answer(self, results):
        """ì—¬ëŸ¬ ì „ë¬¸ê°€ì˜ ë‹µë³€ì„ í†µí•©í•˜ì—¬ ì¢…í•©ì ì¸ ë‹µë³€ ìƒì„±"""
        try:
            integrated_prompt = """
            ë‹¤ìŒì€ ì—¬ëŸ¬ ì „ë¬¸ê°€ë“¤ì˜ ë‹µë³€ì…ë‹ˆë‹¤. ì´ë“¤ì„ ì¢…í•©í•˜ì—¬ 
            ì‚¬ìš©ìì—ê²Œ ì¼ê´€ë˜ê³  ì‹¤ìš©ì ì¸ ì¢…í•© ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.
            
            """
            
            for expert_key, result in results.items():
                agent = result["agent"]
                answer = result["answer"]
                integrated_prompt += f"\n{agent.name}ì˜ ë‹µë³€:\n{answer}\n"
            
            integrated_prompt += """
            
            ìœ„ ë‹µë³€ë“¤ì„ ì¢…í•©í•˜ì—¬ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”:
            1. í•µì‹¬ ìš”ì•½
            2. ê¸°ìˆ ì  ê¶Œì¥ì‚¬í•­
            3. êµ¬í˜„ ë°©ì•ˆ
            4. ì£¼ì˜ì‚¬í•­
            5. ë‹¤ìŒ ë‹¨ê³„
            """
            
            response = openai.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": integrated_prompt}],
                temperature=0.7,
                max_tokens=1500
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            return f"í†µí•© ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤
multi_agent_system = MultiAgentSystem()

def perform_perplexity_search(query, debug_mode=False):
    """Perplexity APIë¥¼ ì‚¬ìš©í•œ ê²€ìƒ‰ ìˆ˜í–‰"""
    api_key = os.getenv('PERPLEXITY_API_KEY')
    if not api_key:
        st.error("Perplexity API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None

    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    url = "https://api.perplexity.ai/chat/completions"
    
    data = {
        "model": "sonar",
        "messages": [
            {
                "role": "system",
                "content": "You are an expert in visual arts and image analysis. Provide detailed, accurate information about visual elements, styles, and artistic references. Always include sources when available."
            },
            {
                "role": "user",
                "content": query
            }
        ]
    }
    
    if debug_mode:
        st.write("=== Perplexity API ìš”ì²­ ë””ë²„ê·¸ ì •ë³´ ===")
        st.write("URL:", url)
        st.write("Headers:", {k: v if k != 'Authorization' else f'Bearer {api_key[:8]}...' for k, v in headers.items()})
        st.write("Request Data:", json.dumps(data, indent=2, ensure_ascii=False))
    
    try:
        response = requests.post(url, headers=headers, json=data)
        
        if debug_mode:
            st.write("\n=== Perplexity API ì‘ë‹µ ë””ë²„ê·¸ ì •ë³´ ===")
            st.write(f"Status Code: {response.status_code}")
            st.write("Response Headers:", dict(response.headers))
            try:
                response_data = response.json()
                st.write("Response JSON:", json.dumps(response_data, indent=2, ensure_ascii=False))
            except:
                st.write("Raw Response:", response.text)
        
        if response.status_code != 200:
            error_msg = f"Perplexity API ì˜¤ë¥˜ (ìƒíƒœ ì½”ë“œ: {response.status_code})"
            try:
                error_data = response.json()
                if 'error' in error_data:
                    error_msg += f"\nì˜¤ë¥˜ ë‚´ìš©: {error_data['error']}"
            except:
                error_msg += f"\nì‘ë‹µ ë‚´ìš©: {response.text}"
            st.error(error_msg)
            return None
        
        result = response.json()
        
        # ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ì™€ ì¶œì²˜ ì¶”ì¶œ
        if 'choices' in result and len(result['choices']) > 0:
            content = result['choices'][0]['message']['content']
            
            # ì¶œì²˜ ì •ë³´ê°€ ìˆëŠ” ê²½ìš° ë³„ë„ë¡œ í‘œì‹œ
            sources = []
            if 'sources' in result['choices'][0]['message']:
                sources = result['choices'][0]['message']['sources']
            
            # ì¶œì²˜ ì •ë³´ê°€ ë³¸ë¬¸ì— í¬í•¨ëœ ê²½ìš° (URLì´ë‚˜ ì°¸ì¡° í˜•ì‹ìœ¼ë¡œ)
            source_section = "\n\n**ì¶œì²˜:**"
            if sources:
                source_section += "\n" + "\n".join([f"- {source}" for source in sources])
            elif "[" in content and "]" in content:  # ë³¸ë¬¸ì— ì°¸ì¡° í˜•ì‹ìœ¼ë¡œ í¬í•¨ëœ ê²½ìš°
                citations = re.findall(r'\[(.*?)\]', content)
                if citations:
                    source_section += "\n" + "\n".join([f"- {citation}" for citation in citations])
            
            # URL í˜•ì‹ì˜ ì¶œì²˜ ì¶”ì¶œ
            urls = re.findall(r'https?://(?:[-\w.]|(?:%[\da-fA-F]{2}))+[^\s)"\']', content)
            if urls:
                if source_section == "\n\n**ì¶œì²˜:**":
                    source_section += "\n" + "\n".join([f"- {url}" for url in urls])
            
            # ì¶œì²˜ ì •ë³´ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì¶”ê°€
            if source_section != "\n\n**ì¶œì²˜:**":
                return content + source_section
            return content
            
        return None
        
    except requests.exceptions.RequestException as e:
        st.error(f"Perplexity API ìš”ì²­ ì‹¤íŒ¨: {str(e)}")
        if debug_mode:
            st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return None
    except Exception as e:
        st.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        if debug_mode:
            st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return None

def search_for_reference_info(prompt, search_type="circuit"):
    """í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ ì°¸ì¡° ì •ë³´ ê²€ìƒ‰"""
    search_queries = {
        "circuit": f"""
        ë‹¤ìŒ ì „ê¸°íšŒë¡œë„ì— ëŒ€í•œ ì •í™•í•œ ì°¸ì¡° ì •ë³´ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”:
        {prompt}
        
        ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”:
        1. íšŒë¡œ êµ¬ì„± ìš”ì†Œì™€ ê¸°í˜¸ (ì €í•­, ì½˜ë´ì„œ, ì¸ë•í„°, ë‹¤ì´ì˜¤ë“œ, íŠ¸ëœì§€ìŠ¤í„° ë“±)
        2. í‘œì¤€ ì „ê¸°íšŒë¡œë„ ê¸°í˜¸ì™€ í‘œê¸°ë²• (IEC, IEEE, ANSI í‘œì¤€)
        3. íšŒë¡œ ì—°ê²° ë°©ì‹ê³¼ ë°°ì„  íŒ¨í„´
        4. ì „ì••, ì „ë¥˜, ì €í•­ ê°’ í‘œì‹œ ë°©ë²•
        5. ìœ ì‚¬í•œ íšŒë¡œë„ ì˜ˆì‹œë‚˜ ì°¸ì¡° ìë£Œ
        6. íšŒë¡œë„ ì‘ì„± ê·œì¹™ê³¼ í‘œì¤€
        7. ê° êµ¬ì„± ìš”ì†Œì˜ ì •í™•í•œ ê¸°í˜¸ì™€ í‘œê¸°ë²•
        """,
        "wiring": f"""
        ë‹¤ìŒ ì „ê¸° ë°°ì„ ë„ì— ëŒ€í•œ ì •í™•í•œ ì°¸ì¡° ì •ë³´ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”:
        {prompt}
        
        ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”:
        1. ì „ì„  ì¢…ë¥˜ì™€ ê·œê²© (AWG, mmÂ²)
        2. ìŠ¤ìœ„ì¹˜, ì½˜ì„¼íŠ¸, ì¡°ëª… ê¸°êµ¬ì˜ í‘œì¤€ ê¸°í˜¸
        3. ë°°ì„  ê²½ë¡œì™€ ì¼€ì´ë¸” íŠ¸ë ˆì´ ë°°ì¹˜
        4. ë‹¨ìí•¨ê³¼ ì ‘ì† ë°•ìŠ¤ ìœ„ì¹˜
        5. ì „ê¸° ì•ˆì „ ê·œê²©ê³¼ ì½”ë“œ (NEC, IEC)
        6. ì ‘ì§€ ì‹œìŠ¤í…œê³¼ ë³´í˜¸ ì¥ì¹˜
        7. ì „ì•• ë ˆë²¨ê³¼ ìœ„ìƒ í‘œì‹œ
        """,
        "iot": f"""
        ë‹¤ìŒ IoT ì‹œìŠ¤í…œì— ëŒ€í•œ ì •í™•í•œ ì°¸ì¡° ì •ë³´ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”:
        {prompt}
        
        ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”:
        1. IoT ë””ë°”ì´ìŠ¤ì™€ ì„¼ì„œ ì¢…ë¥˜
        2. ë¬´ì„  í†µì‹  í”„ë¡œí† ì½œ (WiFi, Bluetooth, Zigbee, LoRa)
        3. ê²Œì´íŠ¸ì›¨ì´ì™€ í´ë¼ìš°ë“œ ì—°ê²° ë°©ì‹
        4. ë°ì´í„° í”Œë¡œìš°ì™€ í”„ë¡œí† ì½œ (MQTT, HTTP, CoAP)
        5. ì „ì› ê´€ë¦¬ì™€ ë°°í„°ë¦¬ ìˆ˜ëª…
        6. ë³´ì•ˆ í”„ë¡œí† ì½œê³¼ ì•”í˜¸í™”
        7. IoT í”Œë«í¼ê³¼ ì„œë¹„ìŠ¤
        """,
        "automation": f"""
        ë‹¤ìŒ ìë™í™” ì œì–´ ì‹œìŠ¤í…œì— ëŒ€í•œ ì •í™•í•œ ì°¸ì¡° ì •ë³´ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”:
        {prompt}
        
        ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”:
        1. PLCì™€ ì œì–´ ì‹œìŠ¤í…œ ì¢…ë¥˜
        2. ì„¼ì„œì™€ ì•¡ì¶”ì—ì´í„° ì¸í„°í˜ì´ìŠ¤
        3. ì œì–´ ë¡œì§ê³¼ ë˜ë” ë‹¤ì´ì–´ê·¸ë¨
        4. HMIì™€ SCADA ì‹œìŠ¤í…œ
        5. ì•ˆì „ íšŒë¡œì™€ ì¸í„°ë½ ì‹œìŠ¤í…œ
        6. í†µì‹  í”„ë¡œí† ì½œ (Modbus, Profinet, EtherCAT)
        7. ì‚°ì—…ìš© ë„¤íŠ¸ì›Œí¬ í† í´ë¡œì§€
        """,
        "power": f"""
        ë‹¤ìŒ ì „ë ¥ ì‹œìŠ¤í…œì— ëŒ€í•œ ì •í™•í•œ ì°¸ì¡° ì •ë³´ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”:
        {prompt}
        
        ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”:
        1. ì „ë ¥ ë¶„ì „ë°˜ê³¼ ì°¨ë‹¨ê¸° ì¢…ë¥˜
        2. ì „ë ¥ ê³„ëŸ‰ê¸°ì™€ CT/PT
        3. ì ‘ì§€ ì‹œìŠ¤í…œê³¼ ë³´í˜¸ ì ‘ì§€
        4. ì „ì•• ë ˆë²¨ê³¼ ìœ„ìƒ êµ¬ì„±
        5. ì „ë ¥ í’ˆì§ˆê³¼ ë³´í˜¸ ì¥ì¹˜
        6. UPSì™€ ë°±ì—… ì „ì› ì‹œìŠ¤í…œ
        7. ì „ë ¥ ë¶„ë°° í† í´ë¡œì§€
        """,
        "control": f"""
        ë‹¤ìŒ ì œì–´ ì‹œìŠ¤í…œì— ëŒ€í•œ ì •í™•í•œ ì°¸ì¡° ì •ë³´ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”:
        {prompt}
        
        ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”:
        1. ì œì–´ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜
        2. í”¼ë“œë°± ë£¨í”„ì™€ ì œì–´ ì•Œê³ ë¦¬ì¦˜
        3. ì„¼ì„œì™€ ì•¡ì¶”ì—ì´í„° ì¸í„°í˜ì´ìŠ¤
        4. ì œì–´ ì‹ í˜¸ì™€ í†µì‹  í”„ë¡œí† ì½œ
        5. ì•ˆì „ ì‹œìŠ¤í…œê³¼ ì¸í„°ë½
        6. ì œì–´ íŒ¨ë„ê³¼ HMI
        7. ì‹œìŠ¤í…œ í†µí•©ê³¼ ì¸í„°í˜ì´ìŠ¤
        """
    }
    
    query = search_queries.get(search_type, search_queries["circuit"])
    return perform_perplexity_search(query)

def generate_enhanced_prompt(original_prompt, reference_info, search_type="general"):
    """ì°¸ì¡° ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í–¥ìƒëœ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    enhancement_prompt = f"""
    ë‹¤ìŒ ì›ë³¸ í”„ë¡¬í”„íŠ¸ì™€ ì›¹ ê²€ìƒ‰ì„ í†µí•´ ì–»ì€ ì°¸ì¡° ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, 
    ë” êµ¬ì²´ì ì´ê³  í˜„ì‹¤ì ì¸ ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

    ì›ë³¸ í”„ë¡¬í”„íŠ¸: {original_prompt}
    
    ì°¸ì¡° ì •ë³´:
    {reference_info}
    
    ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
    1. í–¥ìƒëœ í”„ë¡¬í”„íŠ¸ (êµ¬ì²´ì ì´ê³  ìƒì„¸í•œ ì„¤ëª…)
    2. ì£¼ìš” ì‹œê°ì  ìš”ì†Œ (ìƒ‰ìƒ, ì¡°ëª…, êµ¬ë„, ìŠ¤íƒ€ì¼)
    3. ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­ (í•´ìƒë„, í’ˆì§ˆ, íš¨ê³¼)
    4. ì°¸ì¡° ì¶œì²˜ ìš”ì•½
    
    í”„ë¡¬í”„íŠ¸ëŠ” ì˜ì–´ë¡œ ì‘ì„±í•˜ê³ , êµ¬ì²´ì ì´ê³  ì‹œê°ì ìœ¼ë¡œ ëª…í™•í•´ì•¼ í•©ë‹ˆë‹¤.
    """
    
    try:
        response = openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": enhancement_prompt}],
            temperature=0.7,
            max_tokens=1000
        )
        return response.choices[0].message.content
    except Exception as e:
        st.error(f"í”„ë¡¬í”„íŠ¸ í–¥ìƒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return original_prompt

def generate_image_with_dalle(prompt, model="dall-e-3", size="1024x1024", quality="standard", style="vivid"):
    """OpenAI DALL-Eë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ìƒì„±"""
    try:
        response = openai.images.generate(
            model=model,
            prompt=prompt,
            size=size,
            quality=quality,
            style=style,
            n=1
        )
        
        # ì´ë¯¸ì§€ URLì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        image_url = response.data[0].url
        image_response = requests.get(image_url)
        image = Image.open(io.BytesIO(image_response.content))
        
        return {
            'image': image,
            'url': image_url,
            'model': model,
            'prompt': prompt,
            'created_at': datetime.now()
        }
    except Exception as e:
        st.error(f"DALL-E ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def generate_image_with_claude(prompt, model="claude-3-5-sonnet-20241022"):
    """Anthropic Claude Artifactsë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ìƒì„±"""
    try:
        # Claude Artifactsë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ìƒì„±
        response = anthropic_client.messages.create(
            model=model,
            max_tokens=1000,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": f"ë‹¤ìŒ í”„ë¡¬í”„íŠ¸ë¡œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”: {prompt}"
                        }
                    ]
                }
            ]
        )
        
        # Claude Artifactsì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ
        if response.content and len(response.content) > 0:
            for content in response.content:
                if hasattr(content, 'type') and content.type == 'image':
                    # ì´ë¯¸ì§€ ë°ì´í„° ì²˜ë¦¬
                    image_data = content.source.data
                    image = Image.open(io.BytesIO(base64.b64decode(image_data)))
                    
                    return {
                        'image': image,
                        'url': None,  # ClaudeëŠ” URLì„ ì œê³µí•˜ì§€ ì•ŠìŒ
                        'model': model,
                        'prompt': prompt,
                        'created_at': datetime.now()
                    }
        
        st.warning("Claudeì—ì„œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ ì‘ë‹µë§Œ ë°›ì•˜ìŠµë‹ˆë‹¤.")
        return None
        
    except Exception as e:
        st.error(f"Claude ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def save_image_to_session(image_data):
    """ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ ì„¸ì…˜ì— ì €ì¥"""
    if 'generated_images' not in st.session_state:
        st.session_state.generated_images = []
    
    st.session_state.generated_images.append(image_data)

def download_image(image, filename):
    """ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜"""
    img_byte_arr = io.BytesIO()
    image.save(img_byte_arr, format='PNG')
    img_byte_arr = img_byte_arr.getvalue()
    
    return img_byte_arr

def main():
    st.title("âš¡ ì „ê¸°/IoT ì „ë¬¸ ê¸°ìˆ  ì»¨ì„¤íŒ… & ë„ë©´ ìƒì„±ê¸°")
    st.markdown("IoT, AI, ì „ê¸°, ì¡°ëª… ì „ë¬¸ê°€ë“¤ê³¼ í”„ë¡œì íŠ¸ ë§¤ë‹ˆì €ê°€ í˜‘ë ¥í•˜ì—¬ ê¸°ìˆ ì  ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  í•„ìš”í•œ ë„ë©´ì„ ìƒì„±í•©ë‹ˆë‹¤!")
    
    # íƒ­ ìƒì„±
    tab1, tab2 = st.tabs(["ğŸ¤– ì „ë¬¸ê°€ ì»¨ì„¤íŒ…", "âš¡ ë„ë©´ ìƒì„±"])
    
    with tab1:
        st.header("ğŸ¤– ì „ë¬¸ê°€ ì»¨ì„¤íŒ… ì‹œìŠ¤í…œ")
        
        # ì „ë¬¸ê°€ ì„ íƒ
        st.subheader("ğŸ‘¥ ì „ë¬¸ê°€ ì„ íƒ")
        col_experts = st.columns(5)
        
        with col_experts[0]:
            iot_selected = st.checkbox("ğŸŒ IoT ì „ë¬¸ê°€", value=True, key="iot_expert")
        with col_experts[1]:
            ai_selected = st.checkbox("ğŸ§  AI ì „ë¬¸ê°€", value=True, key="ai_expert")
        with col_experts[2]:
            electrical_selected = st.checkbox("âš¡ ì „ê¸° ì „ë¬¸ê°€", value=True, key="electrical_expert")
        with col_experts[3]:
            lighting_selected = st.checkbox("ğŸ’¡ ì¡°ëª… ì „ë¬¸ê°€", value=True, key="lighting_expert")
        with col_experts[4]:
            pm_selected = st.checkbox("ğŸ“Š í”„ë¡œì íŠ¸ ë§¤ë‹ˆì €", value=True, key="pm_expert")
        
        # ì„ íƒëœ ì „ë¬¸ê°€ë“¤
        selected_experts = []
        if iot_selected:
            selected_experts.append("iot")
        if ai_selected:
            selected_experts.append("ai")
        if electrical_selected:
            selected_experts.append("electrical")
        if lighting_selected:
            selected_experts.append("lighting")
        if pm_selected:
            selected_experts.append("pm")
        
        if not selected_experts:
            st.warning("ìµœì†Œ í•œ ëª…ì˜ ì „ë¬¸ê°€ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”!")
            return
        
        # ì§ˆë¬¸ ì…ë ¥
        st.subheader("â“ ì§ˆë¬¸í•˜ê¸°")
        question = st.text_area(
            "ê¸°ìˆ ì  ì§ˆë¬¸ì´ë‚˜ í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ì„ ì…ë ¥í•˜ì„¸ìš”",
            placeholder="ì˜ˆ: ìŠ¤ë§ˆíŠ¸ í™ˆ IoT ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ë ¤ê³  í•˜ëŠ”ë°, ì–´ë–¤ ì„¼ì„œì™€ í†µì‹  ë°©ì‹ì„ ì‚¬ìš©í•´ì•¼ í• ê¹Œìš”?",
            height=120,
            key="expert_question"
        )
        
        # ì»¨í…ìŠ¤íŠ¸ ì…ë ¥ (ì„ íƒì‚¬í•­)
        context = st.text_area(
            "ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ (ì„ íƒì‚¬í•­)",
            placeholder="ì˜ˆ: 100í‰ ì•„íŒŒíŠ¸, ì˜ˆì‚° 500ë§Œì›, 6ê°œì›” ë‚´ ì™„ë£Œ",
            height=80,
            key="expert_context"
        )
        
        # ì§ˆë¬¸ ì œì¶œ
        col_submit1, col_submit2 = st.columns([1, 1])
        
        with col_submit1:
            if st.button("ğŸ¤– ì „ë¬¸ê°€ë“¤ì—ê²Œ ì§ˆë¬¸í•˜ê¸°", type="primary", use_container_width=True, key="ask_experts"):
                if not question.strip():
                    st.error("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")
                    return
                
                # ì§„í–‰ ìƒí™© í‘œì‹œ
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                try:
                    # ë¹„ë™ê¸° ì²˜ë¦¬ë¥¼ ìœ„í•œ ë˜í¼ í•¨ìˆ˜
                    def run_async_question():
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                        try:
                            return loop.run_until_complete(
                                multi_agent_system.process_question(question, selected_experts)
                            )
                        finally:
                            loop.close()
                    
                    # ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
                    with ThreadPoolExecutor() as executor:
                        future = executor.submit(run_async_question)
                        
                        # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
                        for i in range(5):
                            progress_bar.progress((i + 1) * 20)
                            status_text.text(f"ì „ë¬¸ê°€ë“¤ì´ ë‹µë³€ì„ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤... ({i + 1}/5)")
                            time.sleep(0.5)
                        
                        results = future.result()
                    
                    # ê²°ê³¼ í‘œì‹œ
                    st.success("âœ… ì „ë¬¸ê°€ë“¤ì˜ ë‹µë³€ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    
                    # ê° ì „ë¬¸ê°€ë³„ ë‹µë³€ í‘œì‹œ
                    st.subheader("ğŸ‘¥ ì „ë¬¸ê°€ë³„ ë‹µë³€")
                    
                    for expert_key, result in results.items():
                        agent = result["agent"]
                        answer = result["answer"]
                        needs_drawing = result["needs_drawing"]
                        
                        with st.expander(f"ğŸ’¬ {agent.name}ì˜ ë‹µë³€", expanded=True):
                            st.markdown(answer)
                            
                            if needs_drawing:
                                st.info("ğŸ¨ ì´ ë‹µë³€ê³¼ ê´€ë ¨ëœ ë„ë©´ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 'ë„ë©´ ìƒì„±' íƒ­ì—ì„œ ê´€ë ¨ ë„ë©´ì„ ìƒì„±í•´ë³´ì„¸ìš”!")
                    
                    # í†µí•© ë‹µë³€ ìƒì„±
                    st.subheader("ğŸ“‹ ì¢…í•© ë‹µë³€")
                    with st.spinner("ì „ë¬¸ê°€ë“¤ì˜ ë‹µë³€ì„ ì¢…í•©í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                        integrated_answer = multi_agent_system.get_integrated_answer(results)
                        st.markdown(integrated_answer)
                    
                    # ë„ë©´ ìƒì„± ì œì•ˆ
                    drawing_needed = any(result["needs_drawing"] for result in results.values())
                    if drawing_needed:
                        st.info("ğŸ¨ ë„ë©´ ìƒì„±ì´ í•„ìš”í•©ë‹ˆë‹¤! 'ë„ë©´ ìƒì„±' íƒ­ìœ¼ë¡œ ì´ë™í•˜ì—¬ ê´€ë ¨ ë„ë©´ì„ ìƒì„±í•´ë³´ì„¸ìš”.")
                
                except Exception as e:
                    st.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    st.error(traceback.format_exc())
        
        with col_submit2:
            if st.button("ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”", use_container_width=True, key="reset_conversation"):
                multi_agent_system.conversation_history = []
                for agent in multi_agent_system.agents.values():
                    agent.conversation_history = []
                st.success("âœ… ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.rerun()
        
        # ëŒ€í™” ê¸°ë¡ í‘œì‹œ
        if multi_agent_system.conversation_history:
            st.subheader("ğŸ“š ëŒ€í™” ê¸°ë¡")
            for i, conversation in enumerate(reversed(multi_agent_system.conversation_history)):
                with st.expander(f"ëŒ€í™” {len(multi_agent_system.conversation_history) - i} - {conversation['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}"):
                    st.write(f"**ì§ˆë¬¸:** {conversation['question']}")
                    
                    for expert_key, result in conversation['answers'].items():
                        agent = result["agent"]
                        answer = result["answer"]
                        st.write(f"**{agent.name}:** {answer[:200]}...")
    
    with tab2:
        # ê¸°ì¡´ ë„ë©´ ìƒì„± ê¸°ëŠ¥
        #st.header("âš¡ ë„ë©´ ìƒì„±")
        
        # ì‚¬ì´ë“œë°” ì„¤ì •
        with st.sidebar:
            st.header("âš™ï¸ ë„ë©´ ìƒì„± ì„¤ì •")
            
            # ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ í™œì„±í™”
            enable_web_search = st.checkbox(
                "ğŸŒ ì›¹ ê²€ìƒ‰ ê¸°ë°˜ ìƒì„±",
                value=True,
                help="Perplexity APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì›¹ì—ì„œ ìµœì‹  ê¸°ìˆ  ì •ë³´ì™€ í‘œì¤€ì„ ê²€ìƒ‰í•˜ê³  ì •í™•í•œ ë„ë©´ì„ ìƒì„±í•©ë‹ˆë‹¤"
            )
            
            if enable_web_search:
                st.subheader("ğŸ” ê²€ìƒ‰ ì„¤ì •")
                search_type = st.selectbox(
                    "ê²€ìƒ‰ ìœ í˜•",
                    ["circuit", "wiring", "iot", "automation", "power", "control"],
                    format_func=lambda x: {
                        "circuit": "ì „ê¸°íšŒë¡œë„",
                        "wiring": "ë°°ì„ ë„",
                        "iot": "IoT ì‹œìŠ¤í…œ",
                        "automation": "ìë™í™” ì‹œìŠ¤í…œ",
                        "power": "ì „ë ¥ ì‹œìŠ¤í…œ",
                        "control": "ì œì–´ ì‹œìŠ¤í…œ"
                    }[x],
                    help="ê²€ìƒ‰í•  ê¸°ìˆ  ì •ë³´ì˜ ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”"
                )
                
                debug_mode = st.checkbox(
                    "ë””ë²„ê·¸ ëª¨ë“œ",
                    help="API ìš”ì²­/ì‘ë‹µ ì •ë³´ë¥¼ ìì„¸íˆ í‘œì‹œí•©ë‹ˆë‹¤"
                )
            
            # ëª¨ë¸ ì„ íƒ
            model_choice = st.selectbox(
                "ì‚¬ìš©í•  AI ëª¨ë¸",
                ["OpenAI DALL-E 3", "OpenAI DALL-E 2", "Anthropic Claude"],
                help="ë„ë©´ ìƒì„±ì„ ìœ„í•œ AI ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”"
            )
            
            # DALL-E ì„¤ì •
            if "DALL-E" in model_choice:
                st.subheader("DALL-E ì„¤ì •")
                
                # ëª¨ë¸ ë²„ì „
                dalle_model = st.selectbox(
                    "DALL-E ë²„ì „",
                    ["dall-e-3", "dall-e-2"] if model_choice == "OpenAI DALL-E 3" else ["dall-e-2"],
                    help="DALL-E ëª¨ë¸ ë²„ì „ì„ ì„ íƒí•˜ì„¸ìš”"
                )
                
                # ì´ë¯¸ì§€ í¬ê¸°
                image_size = st.selectbox(
                    "ë„ë©´ í¬ê¸°",
                    ["1024x1024", "1792x1024", "1024x1792"] if dalle_model == "dall-e-3" else ["256x256", "512x512", "1024x1024"],
                    help="ìƒì„±í•  ë„ë©´ì˜ í¬ê¸°ë¥¼ ì„ íƒí•˜ì„¸ìš”"
                )
                
                # í’ˆì§ˆ ì„¤ì • (DALL-E 3ë§Œ)
                if dalle_model == "dall-e-3":
                    image_quality = st.selectbox(
                        "ë„ë©´ í’ˆì§ˆ",
                        ["standard", "hd"],
                        help="ë„ë©´ í’ˆì§ˆì„ ì„ íƒí•˜ì„¸ìš” (HDëŠ” ë” ë†’ì€ í’ˆì§ˆì´ì§€ë§Œ ë” ë§ì€ í¬ë ˆë”§ì„ ì‚¬ìš©í•©ë‹ˆë‹¤)"
                    )
                else:
                    image_quality = "standard"
                
                # ìŠ¤íƒ€ì¼ ì„¤ì • (DALL-E 3ë§Œ)
                if dalle_model == "dall-e-3":
                    image_style = st.selectbox(
                        "ë„ë©´ ìŠ¤íƒ€ì¼",
                        ["vivid", "natural"],
                        help="ë„ë©´ ìŠ¤íƒ€ì¼ì„ ì„ íƒí•˜ì„¸ìš”"
                    )
                else:
                    image_style = "vivid"
            
            # Claude ì„¤ì •
            elif model_choice == "Anthropic Claude":
                st.subheader("Claude ì„¤ì •")
                claude_model = st.selectbox(
                    "Claude ëª¨ë¸",
                    ["claude-3-5-sonnet-20241022", "claude-3-sonnet-20240229"],
                    help="Claude ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”"
                )
            
            st.markdown("---")
            
            # ë„ë©´ í…œí”Œë¦¿
            st.subheader("ğŸ“‹ ë„ë©´ í…œí”Œë¦¿")
            template_choice = st.selectbox(
                "í…œí”Œë¦¿ ì„ íƒ",
                ["ì§ì ‘ ì…ë ¥", "ì „ê¸°íšŒë¡œë„", "ë°°ì„ ë„", "IoT ì‹œìŠ¤í…œ", "ìë™í™” ì œì–´", "ì „ë ¥ ë¶„ë°°", "ì„¼ì„œ ë„¤íŠ¸ì›Œí¬", "í†µì‹  ì‹œìŠ¤í…œ"]
            )
            
            if template_choice != "ì§ì ‘ ì…ë ¥":
                templates = {
                    "ì „ê¸°íšŒë¡œë„": "ì „ë¬¸ì ì¸ ì „ê¸°íšŒë¡œë„, í‘œì¤€ ê¸°í˜¸ ì‚¬ìš©, ê¹”ë”í•œ ì„ ê³¼ ì—°ê²°, ì •í™•í•œ êµ¬ì„± ìš”ì†Œ ê¸°í˜¸, ê³ í•´ìƒë„, ê³µí•™ ë„ë©´ ìŠ¤íƒ€ì¼",
                    "ë°°ì„ ë„": "ì „ê¸° ë°°ì„ ë„, ì „ì„  ê²½ë¡œ, ìŠ¤ìœ„ì¹˜, ì½˜ì„¼íŠ¸, ì¡°ëª… ë°°ì¹˜, ë‹¨ìí•¨ ìœ„ì¹˜, ì•ˆì „ ê·œê²© ì¤€ìˆ˜",
                    "IoT ì‹œìŠ¤í…œ": "IoT ë””ë°”ì´ìŠ¤ ë„¤íŠ¸ì›Œí¬, ì„¼ì„œ ì—°ê²°, ê²Œì´íŠ¸ì›¨ì´, í´ë¼ìš°ë“œ ì—°ê²°, ë°ì´í„° í”Œë¡œìš°, ë¬´ì„  í†µì‹ ",
                    "ìë™í™” ì œì–´": "PLC ì œì–´ ì‹œìŠ¤í…œ, ì„¼ì„œ ì…ë ¥, ì•¡ì¶”ì—ì´í„° ì¶œë ¥, ì œì–´ ë¡œì§, ì•ˆì „ íšŒë¡œ, HMI ì¸í„°í˜ì´ìŠ¤",
                    "ì „ë ¥ ë¶„ë°°": "ì „ë ¥ ë¶„ì „ë°˜, ì°¨ë‹¨ê¸°, í“¨ì¦ˆ, ì „ë ¥ ê³„ëŸ‰ê¸°, ì ‘ì§€ ì‹œìŠ¤í…œ, ì „ì•• ë ˆë²¨ í‘œì‹œ",
                    "ì„¼ì„œ ë„¤íŠ¸ì›Œí¬": "ë‹¤ì–‘í•œ ì„¼ì„œ ë°°ì¹˜, ë°ì´í„° ìˆ˜ì§‘ ë…¸ë“œ, ë¬´ì„  í†µì‹  ë§í¬, ë°°í„°ë¦¬ ì „ì›, í™˜ê²½ ëª¨ë‹ˆí„°ë§",
                    "í†µì‹  ì‹œìŠ¤í…œ": "ì´ë”ë„·, RS485, Modbus, CAN ë²„ìŠ¤, ë¬´ì„  í†µì‹ , í”„ë¡œí† ì½œ ë³€í™˜ê¸°, ë„¤íŠ¸ì›Œí¬ í† í´ë¡œì§€"
                }
                st.text_area("í…œí”Œë¦¿ í”„ë¡¬í”„íŠ¸", templates[template_choice], height=100, key="sidebar_template_prompt_1")
        
        # ë©”ì¸ ì»¨í…ì¸ 
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.header("âš¡ ë„ë©´ ìƒì„±")
            
            # í”„ë¡¬í”„íŠ¸ ì…ë ¥
            if template_choice == "ì§ì ‘ ì…ë ¥":
                prompt = st.text_area(
                    "ë„ë©´ ì„¤ëª…ì„ ì…ë ¥í•˜ì„¸ìš”",
                    placeholder="ì˜ˆ: 3ìƒ ì „ë ¥ ë¶„ì „ë°˜ ë°°ì„ ë„, 220V ì½˜ì„¼íŠ¸ 10ê°œ, ì¡°ëª… ìŠ¤ìœ„ì¹˜ 5ê°œ",
                    height=120,
                    help="ìƒì„±í•˜ê³  ì‹¶ì€ ë„ë©´ì— ëŒ€í•´ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”",
                    key="main_prompt_input"
                )
            else:
                base_prompt = st.text_area(
                    "ê¸°ë³¸ í”„ë¡¬í”„íŠ¸",
                    placeholder="ì˜ˆ: ê³µì¥ ìë™í™” ì‹œìŠ¤í…œ, ìŠ¤ë§ˆíŠ¸ í™ˆ IoT ë„¤íŠ¸ì›Œí¬ ë“±",
                    height=80,
                    key="base_prompt_input"
                )
                template_prompt = st.sidebar.text_area("í…œí”Œë¦¿ í”„ë¡¬í”„íŠ¸", templates[template_choice], height=100, key="sidebar_template_prompt_2")
                prompt = f"{base_prompt}, {template_prompt}" if base_prompt else template_prompt
            
            # ì¶”ê°€ ì˜µì…˜
            with st.expander("ğŸ”§ ì¶”ê°€ ì˜µì…˜"):
                col_a, col_b = st.columns(2)
                
                with col_a:
                    negative_prompt = st.text_area(
                        "ì œì™¸í•  ìš”ì†Œ",
                        placeholder="ì˜ˆ: ìƒ‰ìƒ, ì¥ì‹ ìš”ì†Œ, ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸",
                        height=80,
                        help="ë„ë©´ì—ì„œ ì œì™¸í•˜ê³  ì‹¶ì€ ìš”ì†Œë¥¼ ì…ë ¥í•˜ì„¸ìš”",
                        key="negative_prompt_input"
                    )
                
                with col_b:
                    style_guide = st.text_area(
                        "ìŠ¤íƒ€ì¼ ê°€ì´ë“œ",
                        placeholder="ì˜ˆ: ë‹¨ìˆœí™”ëœ ë„ë©´, ìƒì„¸í•œ ë„ë©´, 3D ë Œë”ë§",
                        height=80,
                        help="ì›í•˜ëŠ” ë„ë©´ ìŠ¤íƒ€ì¼ì„ ì¶”ê°€ë¡œ ì§€ì •í•˜ì„¸ìš”",
                        key="style_guide_input"
                    )
            
            # ì›¹ ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
            if enable_web_search and prompt.strip():
                with st.expander("ğŸ” ì›¹ ê²€ìƒ‰ ê²°ê³¼", expanded=True):
                    with st.spinner("ì›¹ì—ì„œ ì°¸ì¡° ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                        reference_info = search_for_reference_info(prompt, search_type)
                        
                        if reference_info:
                            st.markdown("### ğŸ“š ì°¸ì¡° ì •ë³´")
                            st.markdown(reference_info)
                            
                            # í–¥ìƒëœ í”„ë¡¬í”„íŠ¸ ìƒì„±
                            with st.spinner("ì°¸ì¡° ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ë¥¼ í–¥ìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                                enhanced_prompt = generate_enhanced_prompt(prompt, reference_info, search_type)
                                
                                st.markdown("### âœ¨ í–¥ìƒëœ í”„ë¡¬í”„íŠ¸")
                                st.text_area(
                                    "í–¥ìƒëœ í”„ë¡¬í”„íŠ¸",
                                    enhanced_prompt,
                                    height=150,
                                    help="ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í–¥ìƒëœ í”„ë¡¬í”„íŠ¸ì…ë‹ˆë‹¤",
                                    key="enhanced_prompt_display"
                                )
                                
                                # í–¥ìƒëœ í”„ë¡¬í”„íŠ¸ ì‚¬ìš© ì—¬ë¶€
                                use_enhanced = st.checkbox(
                                    "í–¥ìƒëœ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©",
                                    value=True,
                                    help="ì²´í¬í•˜ë©´ ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í–¥ìƒëœ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤",
                                    key="use_enhanced_prompt"
                                )
                                
                                if use_enhanced:
                                    prompt = enhanced_prompt
                        else:
                            st.warning("ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì›ë³¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            
            # ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            final_prompt = prompt
            if negative_prompt:
                final_prompt += f" (ì œì™¸: {negative_prompt})"
            if style_guide:
                final_prompt += f" (ìŠ¤íƒ€ì¼: {style_guide})"
            
            # ìƒì„± ë²„íŠ¼
            col_gen1, col_gen2, col_gen3 = st.columns([1, 1, 1])
            
            with col_gen1:
                if st.button("âš¡ ë„ë©´ ìƒì„±", type="primary", use_container_width=True, key="generate_button"):
                    if not final_prompt.strip():
                        st.error("í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
                        return
                    
                    with st.spinner("AIê°€ ë„ë©´ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                        if "DALL-E" in model_choice:
                            result = generate_image_with_dalle(
                                final_prompt,
                                dalle_model,
                                image_size,
                                image_quality,
                                image_style
                            )
                        else:  # Claude
                            result = generate_image_with_claude(final_prompt, claude_model)
                        
                        if result:
                            save_image_to_session(result)
                            st.success("âœ… ë„ë©´ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                            st.rerun()
            
            with col_gen2:
                if st.button("ğŸ”„ ë‹¤ì‹œ ìƒì„±", use_container_width=True, key="regenerate_button"):
                    if not final_prompt.strip():
                        st.error("í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
                        return
                    
                    with st.spinner("AIê°€ ìƒˆë¡œìš´ ë„ë©´ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                        if "DALL-E" in model_choice:
                            result = generate_image_with_dalle(
                                final_prompt,
                                dalle_model,
                                image_size,
                                image_quality,
                                image_style
                            )
                        else:  # Claude
                            result = generate_image_with_claude(final_prompt, claude_model)
                        
                        if result:
                            save_image_to_session(result)
                            st.success("âœ… ìƒˆë¡œìš´ ë„ë©´ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                            st.rerun()
            
            with col_gen3:
                if st.button("ğŸ—‘ï¸ ì´ˆê¸°í™”", use_container_width=True, key="reset_button"):
                    if 'generated_images' in st.session_state:
                        del st.session_state.generated_images
                    st.success("âœ… ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.rerun()
        
        with col2:
            st.header("ğŸ“Š ìƒì„± ì •ë³´")
            
            if 'generated_images' in st.session_state and st.session_state.generated_images:
                latest_image = st.session_state.generated_images[-1]
                
                st.info(f"""
                **ëª¨ë¸:** {latest_image['model']}
                **ìƒì„± ì‹œê°„:** {latest_image['created_at'].strftime('%Y-%m-%d %H:%M:%S')}
                **í”„ë¡¬í”„íŠ¸:** {latest_image['prompt'][:100]}...
                """)
                
                if latest_image['url']:
                    st.markdown(f"[ì›ë³¸ ë„ë©´]({latest_image['url']})")
        
        # ìƒì„±ëœ ì´ë¯¸ì§€ í‘œì‹œ
        if 'generated_images' in st.session_state and st.session_state.generated_images:
            st.header("ğŸ“‹ ìƒì„±ëœ ë„ë©´ë“¤")
            
            # ì´ë¯¸ì§€ ê°¤ëŸ¬ë¦¬
            num_images = len(st.session_state.generated_images)
            cols = st.columns(min(3, num_images))
            
            for idx, image_data in enumerate(st.session_state.generated_images):
                col_idx = idx % 3
                with cols[col_idx]:
                    st.subheader(f"ë„ë©´ {idx + 1}")
                    st.image(image_data['image'], use_container_width=True)
                    
                    # ì´ë¯¸ì§€ ì •ë³´
                    with st.expander(f"ğŸ“‹ ë„ë©´ {idx + 1} ì •ë³´"):
                        st.write(f"**ëª¨ë¸:** {image_data['model']}")
                        st.write(f"**ìƒì„± ì‹œê°„:** {image_data['created_at'].strftime('%Y-%m-%d %H:%M:%S')}")
                        st.write(f"**í”„ë¡¬í”„íŠ¸:** {image_data['prompt']}")
                        
                        if image_data['url']:
                            st.markdown(f"[ì›ë³¸ ë„ë©´]({image_data['url']})")
                        
                        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                        img_bytes = download_image(image_data['image'], f"technical_drawing_{idx + 1}.png")
                        st.download_button(
                            label=f"ğŸ“¥ ë„ë©´ {idx + 1} ë‹¤ìš´ë¡œë“œ",
                            data=img_bytes,
                            file_name=f"technical_drawing_{idx + 1}.png",
                            mime="image/png",
                            use_container_width=True,
                            key=f"download_button_{idx}"
                        )
                    
                    # ê°œë³„ ì‚­ì œ ë²„íŠ¼
                    if st.button(f"ğŸ—‘ï¸ ë„ë©´ {idx + 1} ì‚­ì œ", key=f"delete_{idx}", use_container_width=True):
                        st.session_state.generated_images.pop(idx)
                        st.success(f"ë„ë©´ {idx + 1}ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤!")
                        st.rerun()
        
        # ì‚¬ìš© íŒ
        with st.expander("ğŸ’¡ ì‚¬ìš© íŒ"):
            st.markdown("""
            ### ì›¹ ê²€ìƒ‰ ê¸°ë°˜ ë„ë©´ ìƒì„±ì˜ ì¥ì :
            
            **1. ì •í™•ì„± í–¥ìƒ**
            - ìµœì‹  ê¸°ìˆ  í‘œì¤€ê³¼ ê·œê²© ì •ë³´ ë°˜ì˜
            - ì •í™•í•œ ê¸°í˜¸ì™€ í‘œê¸°ë²• ì‚¬ìš©
            
            **2. ì „ë¬¸ì„± ì¦ê°€**
            - ì›¹ ê²€ìƒ‰ì„ í†µí•œ ì „ë¬¸ ê¸°ìˆ  ì •ë³´ ì œê³µ
            - ì‚°ì—… í‘œì¤€ê³¼ ì•ˆì „ ê·œê²© ì¤€ìˆ˜
            
            **3. ì°¸ì¡° ì¶œì²˜ ì œê³µ**
            - ìƒì„±ëœ ë„ë©´ì˜ ê¸°ìˆ ì  ê·¼ê±° í™•ì¸ ê°€ëŠ¥
            - ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê¸°ìˆ  ìë£Œ ê¸°ë°˜ ìƒì„±
            
            ### ë” ì¢‹ì€ ê²°ê³¼ë¥¼ ìœ„í•œ íŒ:
            
            **1. êµ¬ì²´ì ì¸ ê²€ìƒ‰ ìœ í˜• ì„ íƒ**
            - ì „ê¸°íšŒë¡œë„: í‘œì¤€ ì „ê¸° ê¸°í˜¸ì™€ íšŒë¡œ êµ¬ì„± ìš”ì†Œ
            - ë°°ì„ ë„: ì „ì„  ê·œê²©, ì•ˆì „ ê·œê²©, ë°°ì¹˜ ì •ë³´
            - IoT ì‹œìŠ¤í…œ: í†µì‹  í”„ë¡œí† ì½œ, ì„¼ì„œ, í”Œë«í¼
            - ìë™í™” ì‹œìŠ¤í…œ: PLC, ì œì–´ ë¡œì§, ì•ˆì „ íšŒë¡œ
            - ì „ë ¥ ì‹œìŠ¤í…œ: ë¶„ì „ë°˜, ë³´í˜¸ ì¥ì¹˜, ì ‘ì§€
            - ì œì–´ ì‹œìŠ¤í…œ: í”¼ë“œë°± ë£¨í”„, ì¸í„°í˜ì´ìŠ¤
            
            **2. ê²€ìƒ‰ ê²°ê³¼ í™œìš©**
            - ì œê³µëœ ê¸°ìˆ  ì •ë³´ ê²€í† 
            - í–¥ìƒëœ í”„ë¡¬í”„íŠ¸ ì‚¬ìš© ê¶Œì¥
            
            **3. ë°˜ë³µ ê°œì„ **
            - ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ ìˆ˜ì •
            - ì—¬ëŸ¬ ë²ˆì˜ ì‹œë„ë¡œ ìµœì  ê²°ê³¼ ë„ì¶œ
            
            ### âš¡ ì „ê¸°íšŒë¡œë„ ìƒì„± íŒ:
            
            **í‘œì¤€ ê¸°í˜¸ì™€ ê·œì¹™:**
            - **ì €í•­**: ì§€ê·¸ì¬ê·¸ ì„  ë˜ëŠ” ì§ì‚¬ê°í˜• ê¸°í˜¸
            - **ì½˜ë´ì„œ**: ë‘ ê°œì˜ í‰í–‰ì„ 
            - **ì¸ë•í„°**: ë‚˜ì„ í˜• ê¸°í˜¸
            - **ë‹¤ì´ì˜¤ë“œ**: í™”ì‚´í‘œ ê¸°í˜¸
            - **íŠ¸ëœì§€ìŠ¤í„°**: ì‚¼ê°í˜•ê³¼ ì„  ì¡°í•©
            - **ì „ì›**: +, - ê¸°í˜¸ ë˜ëŠ” ë°°í„°ë¦¬ ê¸°í˜¸
            
            **íšŒë¡œë„ ì‘ì„± ê·œì¹™:**
            - **ê¹”ë”í•œ ì„ **: ì§ì„ ê³¼ ì§ê° ì—°ê²°
            - **í‘œì¤€ ê¸°í˜¸**: IEC, IEEE, ANSI í‘œì¤€ ì¤€ìˆ˜
            - **ê°’ í‘œì‹œ**: ì €í•­ê°’, ì „ì••ê°’ ëª…í™•íˆ í‘œì‹œ
            - **ë…¸ë“œ í‘œì‹œ**: ì—°ê²°ì  ëª…í™•íˆ í‘œì‹œ
            - **ë ˆì´ë¸”**: ê° êµ¬ì„± ìš”ì†Œì— ì‹ë³„ì ë¶€ì—¬
            
            **ì¶”ì²œ í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ:**
            - "LEDì™€ ì €í•­ì„ ì‚¬ìš©í•œ ê°„ë‹¨í•œ ì§ë ¬ íšŒë¡œ, 5V ì „ì›, 220ì˜´ ì €í•­"
            - "555 íƒ€ì´ë¨¸ ICë¥¼ ì‚¬ìš©í•œ ë°œì§„ íšŒë¡œ, LED ê¹œë¹¡ì„ íšŒë¡œ"
            - "ì˜¤í”¼ì•°í”„ë¥¼ ì‚¬ìš©í•œ ë°˜ì „ ì¦í­ê¸° íšŒë¡œ, 741 IC"
            
            ### ğŸ”Œ ë°°ì„ ë„ ìƒì„± íŒ:
            
            **ë°°ì„  êµ¬ì„± ìš”ì†Œ:**
            - **ì „ì„ **: AWG ê·œê²©, ìƒ‰ìƒ ì½”ë“œ
            - **ìŠ¤ìœ„ì¹˜**: ë‹¨ê·¹, 3ë°©í–¥, 4ë°©í–¥
            - **ì½˜ì„¼íŠ¸**: 120V, 240V, GFCI, AFCI
            - **ì¡°ëª…**: LED, í˜•ê´‘ë“±, í• ë¡œê²
            - **ì°¨ë‹¨ê¸°**: ë‹¨ê·¹, 2ê·¹, 3ê·¹
            
            **ì•ˆì „ ê·œê²©:**
            - **NEC ì½”ë“œ**: ë¯¸êµ­ ì „ê¸° ì•ˆì „ ê·œê²©
            - **IEC í‘œì¤€**: êµ­ì œ ì „ê¸° í‘œì¤€
            - **ì ‘ì§€**: ë³´í˜¸ ì ‘ì§€, ê¸°ëŠ¥ ì ‘ì§€
            - **ë³´í˜¸ ì¥ì¹˜**: í“¨ì¦ˆ, ì°¨ë‹¨ê¸°, ì„œì§€ ë³´í˜¸
            
            **ì¶”ì²œ í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ:**
            - "3ìƒ ì „ë ¥ ë¶„ì „ë°˜ ë°°ì„ ë„, 220V ì½˜ì„¼íŠ¸ 10ê°œ, ì¡°ëª… ìŠ¤ìœ„ì¹˜ 5ê°œ"
            - "ìŠ¤ë§ˆíŠ¸ í™ˆ ë°°ì„ ë„, WiFi ìŠ¤ìœ„ì¹˜, ìë™í™” ì½˜ì„¼íŠ¸"
            - "ê³µì¥ ì „ë ¥ ë¶„ë°° ì‹œìŠ¤í…œ, ëª¨í„° ì œì–´ íŒ¨ë„"
            
            ### ğŸŒ IoT ì‹œìŠ¤í…œ ìƒì„± íŒ:
            
            **IoT êµ¬ì„± ìš”ì†Œ:**
            - **ì„¼ì„œ**: ì˜¨ë„, ìŠµë„, ì••ë ¥, ëª¨ì…˜, ê°€ìŠ¤
            - **ì•¡ì¶”ì—ì´í„°**: ë¦´ë ˆì´, ëª¨í„°, LED, ë””ìŠ¤í”Œë ˆì´
            - **ê²Œì´íŠ¸ì›¨ì´**: WiFi, Bluetooth, Zigbee, LoRa
            - **í´ë¼ìš°ë“œ**: AWS IoT, Azure IoT, Google Cloud IoT
            - **í”Œë«í¼**: Home Assistant, Node-RED, ThingsBoard
            
            **í†µì‹  í”„ë¡œí† ì½œ:**
            - **MQTT**: ê²½ëŸ‰ ë©”ì‹œì§• í”„ë¡œí† ì½œ
            - **HTTP/HTTPS**: REST API í†µì‹ 
            - **CoAP**: ì œí•œëœ í™˜ê²½ìš© í”„ë¡œí† ì½œ
            - **Modbus**: ì‚°ì—…ìš© í†µì‹  í”„ë¡œí† ì½œ
            
            **ì¶”ì²œ í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ:**
            - "ìŠ¤ë§ˆíŠ¸ í™ˆ IoT ë„¤íŠ¸ì›Œí¬, ì˜¨ë„/ìŠµë„ ì„¼ì„œ, ìŠ¤ë§ˆíŠ¸ ì¡°ëª…"
            - "ê³µì¥ IoT ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ, ì„¼ì„œ ë„¤íŠ¸ì›Œí¬, ë°ì´í„° ìˆ˜ì§‘"
            - "ìŠ¤ë§ˆíŠ¸ ì‹œí‹° IoT ì¸í”„ë¼, í™˜ê²½ ëª¨ë‹ˆí„°ë§, êµí†µ ì œì–´"
            
            ### ğŸ¤– ìë™í™” ì œì–´ ì‹œìŠ¤í…œ íŒ:
            
            **ì œì–´ ì‹œìŠ¤í…œ êµ¬ì„±:**
            - **PLC**: í”„ë¡œê·¸ë˜ë¨¸ë¸” ë¡œì§ ì»¨íŠ¸ë¡¤ëŸ¬
            - **HMI**: íœ´ë¨¼ ë¨¸ì‹  ì¸í„°í˜ì´ìŠ¤
            - **SCADA**: ê°ì‹œ ì œì–´ ë° ë°ì´í„° ìˆ˜ì§‘
            - **ì„¼ì„œ**: ì˜¨ë„, ì••ë ¥, ë ˆë²¨, ìœ„ì¹˜
            - **ì•¡ì¶”ì—ì´í„°**: ë°¸ë¸Œ, ëª¨í„°, íˆí„°, íŒí”„
            
            **ì œì–´ ë¡œì§:**
            - **ë˜ë” ë‹¤ì´ì–´ê·¸ë¨**: PLC í”„ë¡œê·¸ë˜ë°
            - **í‘ì…˜ ë¸”ë¡**: ê³ ê¸‰ ì œì–´ ê¸°ëŠ¥
            - **ìˆœì°¨ ì œì–´**: ë‹¨ê³„ë³„ í”„ë¡œì„¸ìŠ¤ ì œì–´
            - **í”¼ë“œë°± ì œì–´**: PID ì œì–´ ì•Œê³ ë¦¬ì¦˜
            
            **ì¶”ì²œ í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ:**
            - "PLC ê¸°ë°˜ ìë™í™” ì œì–´ ì‹œìŠ¤í…œ, ì„¼ì„œ ì…ë ¥, ëª¨í„° ì œì–´"
            - "ìŠ¤ë§ˆíŠ¸ íŒ©í† ë¦¬ ìë™í™”, ë¡œë´‡ ì œì–´, í’ˆì§ˆ ê²€ì‚¬"
            - "ë¹Œë”© ìë™í™” ì‹œìŠ¤í…œ, HVAC ì œì–´, ë³´ì•ˆ ì‹œìŠ¤í…œ"
            """)
        
        # ëª¨ë¸ë³„ íŠ¹ì§•
        with st.expander("ğŸ¤– ëª¨ë¸ë³„ íŠ¹ì§•"):
            st.markdown("""
            ### OpenAI DALL-E 3
            - **ì¥ì :** ë§¤ìš° ë†’ì€ í’ˆì§ˆ, ì •í™•í•œ ê¸°í˜¸ í‘œì‹œ, ì„¸ë°€í•œ ë””í…Œì¼
            - **íŠ¹ì§•:** 1024x1024, 1792x1024, 1024x1792 í¬ê¸° ì§€ì›
            - **ì í•©í•œ ìš©ë„:** ê³ í’ˆì§ˆ ì „ê¸°íšŒë¡œë„, ìƒì„¸í•œ ë°°ì„ ë„, ì •ë°€í•œ ì‹œìŠ¤í…œ ë„ë©´
            
            ### OpenAI DALL-E 2
            - **ì¥ì :** ë¹ ë¥¸ ìƒì„±, ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ ì§€ì›
            - **íŠ¹ì§•:** 256x256, 512x512, 1024x1024 í¬ê¸° ì§€ì›
            - **ì í•©í•œ ìš©ë„:** ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘, ê¸°ë³¸ íšŒë¡œë„, ê°œë…ë„
            
            ### Anthropic Claude
            - **ì¥ì :** ì°½ì˜ì ì¸ í•´ì„, ë³µì¡í•œ ì‹œìŠ¤í…œ ì´í•´
            - **íŠ¹ì§•:** í…ìŠ¤íŠ¸ì™€ ë„ë©´ ìƒì„± í†µí•©
            - **ì í•©í•œ ìš©ë„:** ë³µì¡í•œ IoT ì‹œìŠ¤í…œ, í†µí•© ì œì–´ ì‹œìŠ¤í…œ, ê°œë…ì  ì•„í‚¤í…ì²˜
            
            ### Perplexity API (ì›¹ ê²€ìƒ‰)
            - **ì¥ì :** ì‹¤ì‹œê°„ ê¸°ìˆ  ì •ë³´ ìˆ˜ì§‘, ìµœì‹  í‘œì¤€ ìë£Œ ì œê³µ
            - **íŠ¹ì§•:** ë‹¤ì–‘í•œ ê¸°ìˆ  ì¶œì²˜ì˜ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´
            - **ì í•©í•œ ìš©ë„:** í‘œì¤€ ì¤€ìˆ˜ ë„ë©´, ìµœì‹  ê¸°ìˆ  ë°˜ì˜, ì •í™•í•œ ê¸°í˜¸ ì‚¬ìš©
            """)

if __name__ == "__main__":
    main() 