import streamlit as st
import os
from openai import OpenAI
from langchain_anthropic import ChatAnthropic
import threading
from concurrent.futures import ThreadPoolExecutor
import time
import base64

st.set_page_config(page_title="ë‹¤ì¤‘ ë²ˆì—­ê¸°", page_icon="ğŸŒ", layout="wide")

def get_ai_response(prompt, model_name, system_prompt=""):
    """AI ëª¨ë¸ë¡œë¶€í„° ì‘ë‹µì„ ë°›ëŠ” í•¨ìˆ˜"""
    try:
        if model_name.startswith('claude'):
            client = ChatAnthropic(
                model=model_name, 
                api_key=os.getenv('ANTHROPIC_API_KEY'), 
                temperature=0.7, 
                max_tokens=8192
            )
            response = client.invoke([
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ])
            return response.content if hasattr(response, 'content') else str(response)
        else:
            openai_key = os.getenv('OPENAI_API_KEY')
            if not openai_key or openai_key.strip() == '' or openai_key == 'NA':
                raise ValueError("OpenAI API í‚¤ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            
            client = OpenAI(api_key=openai_key)
            response = client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=8192,
                temperature=0.7
            )
            return response.choices[0].message.content
    except Exception as e:
        return f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

def text_to_speech(text, voice_type):
    """í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜"""
    try:
        # OpenAI API í‚¤ ê²€ì¦
        openai_key = os.getenv('OPENAI_API_KEY')
        if not openai_key or openai_key.strip() == '' or openai_key == 'NA':
            return None
            
        client = OpenAI(api_key=openai_key)
        
        # ìŒì„± ì„¤ì •
        voice_settings = {
            "ë‚¨ì„± (ê¹Šì€ ëª©ì†Œë¦¬)": "onyx",
            "ë‚¨ì„± (ì¤‘ê°„ í†¤)": "echo", 
            "ì—¬ì„± (ë°ì€ ëª©ì†Œë¦¬)": "nova",
            "ì—¬ì„± (ì°¨ë¶„í•œ ëª©ì†Œë¦¬)": "shimmer",
            "ì¤‘ì„±ì ì¸ ëª©ì†Œë¦¬": "alloy"
        }
        
        selected_voice = voice_settings.get(voice_type, "alloy")
        
        response = client.audio.speech.create(
            model="tts-1",
            voice=selected_voice,
            input=text
        )
        
        audio_data = response.content
        audio_base64 = base64.b64encode(audio_data).decode('utf-8')
        audio_html = f'''
            <audio controls>
                <source src="data:audio/mp3;base64,{audio_base64}" type="audio/mp3">
                Your browser does not support the audio element.
            </audio>
        '''
        return audio_html
    except Exception as e:
        return None

def translate_or_answer(model_name, source_text, prompt, source_language, target_language, is_question=False):
    """í…ìŠ¤íŠ¸ë¥¼ ë²ˆì—­í•˜ê±°ë‚˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” í•¨ìˆ˜"""
    try:
        # ì–¸ì–´ ì´ë¦„ ë§¤í•‘
        language_names = {
            "í•œêµ­ì–´": "Korean",
            "ì˜ì–´": "English", 
            "ì¤‘êµ­ì–´": "Chinese",
            "ì¼ë³¸ì–´": "Japanese",
            "í”„ë‘ìŠ¤ì–´": "French",
            "ë…ì¼ì–´": "German",
            "ìŠ¤í˜ì¸ì–´": "Spanish",
            "ì´íƒˆë¦¬ì•„ì–´": "Italian",
            "ëŸ¬ì‹œì•„ì–´": "Russian",
            "í¬ë¥´íˆ¬ê°ˆì–´": "Portuguese"
        }
        
        # ì›ë¬¸ì´ ì—†ê³  ì§ˆë¬¸ì¸ ê²½ìš° - ì™„ì „í•œ LLM ê¸°ëŠ¥
        if is_question:
            # ì–¸ì–´ ì§€ì •ì´ í•œêµ­ì–´ê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ì–¸ì–´ ìš”ì²­
            if target_language != "í•œêµ­ì–´":
                system_prompt = f"You are a helpful AI assistant. Please respond in {language_names[target_language]} language."
                user_message = f"Please answer the following question or request in {language_names[target_language]}:\n\n{prompt}"
            else:
                # í•œêµ­ì–´ì¸ ê²½ìš° ì¼ë°˜ì ì¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ë¡œ ë™ì‘
                system_prompt = "You are a helpful AI assistant."
                user_message = prompt
            
        # ë²ˆì—­ì¸ ê²½ìš°
        else:
            # ì›ë¬¸ ì–¸ì–´ì™€ ëª©í‘œ ì–¸ì–´ê°€ ê°™ê³  í”„ë¡¬í”„íŠ¸ê°€ ìˆëŠ” ê²½ìš°
            if source_language == target_language and prompt and prompt.strip():
                system_prompt = f"You are a text processing specialist. Always respond in {language_names[target_language]}."
                user_message = f"Process the following {language_names[source_language]} text according to these instructions:\n\n[Instructions]\n{prompt.strip()}\n\nText:\n{source_text}\n\nReturn the processed text in {language_names[target_language]} following the given instructions."
                
            # ì›ë¬¸ ì–¸ì–´ì™€ ëª©í‘œ ì–¸ì–´ê°€ ê°™ê³  í”„ë¡¬í”„íŠ¸ê°€ ì—†ëŠ” ê²½ìš°
            elif source_language == target_language:
                return source_text  # ì›ë¬¸ ê·¸ëŒ€ë¡œ ë°˜í™˜
                
            # ì‹¤ì œ ë²ˆì—­ì´ í•„ìš”í•œ ê²½ìš°
            else:
                system_prompt = f"You are a professional translator. Always translate to {language_names[target_language]}."
                user_message = f"Translate the following text from {language_names[source_language]} to {language_names[target_language]}. Keep the original meaning and nuance"
                
                if prompt and prompt.strip():
                    user_message += f"\n\n[Important: Please follow these additional instructions]\n{prompt.strip()}"
                
                user_message += f":\n\n{source_text}"
        
        return get_ai_response(user_message, model_name, system_prompt)
        
    except Exception as e:
        return f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

def translate_to_multiple_languages(model_name, source_text, prompt, source_language, target_languages, is_question=False):
    """ì—¬ëŸ¬ ì–¸ì–´ë¡œ ë™ì‹œ ë²ˆì—­/ë‹µë³€í•˜ëŠ” í•¨ìˆ˜"""
    results = {}
    
    def translate_single(target_lang):
        result = translate_or_answer(model_name, source_text, prompt, source_language, target_lang, is_question)
        return target_lang, result
    
    # ThreadPoolExecutorë¥¼ ì‚¬ìš©í•˜ì—¬ ë™ì‹œì— ë²ˆì—­ ìš”ì²­
    with ThreadPoolExecutor(max_workers=len(target_languages)) as executor:
        futures = [executor.submit(translate_single, lang) for lang in target_languages]
        
        for future in futures:
            lang, result = future.result()
            results[lang] = result
    
    return results

def main():
    st.title("ğŸŒ ë‹¤ì¤‘ ë²ˆì—­ê¸°")
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'selected_model' not in st.session_state:
        st.session_state.selected_model = 'claude-3-7-sonnet-latest'
    
    # ì‚¬ì´ë“œë°”ì— ëª¨ë¸ ì„ íƒê³¼ ì„¤ëª… ì¶”ê°€
    with st.sidebar:
        st.markdown("### ğŸ§  AI ëª¨ë¸ ì„ íƒ")
        
        # ëª¨ë¸ ì„ íƒ
        available_models = []
        has_anthropic_key = os.environ.get('ANTHROPIC_API_KEY') is not None
        if has_anthropic_key:
            available_models.extend([
                'claude-3-7-sonnet-latest',
                'claude-3-5-sonnet-latest', 
                'claude-3-5-haiku-latest',
            ])
        has_openai_key = os.environ.get('OPENAI_API_KEY') is not None
        if has_openai_key:
            available_models.extend(['gpt-4o', 'gpt-4o-mini'])
        
        if not available_models:
            st.sidebar.error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            available_models = ['claude-3-7-sonnet-latest']  # ê¸°ë³¸ê°’
        
        selected_model = st.selectbox(
            'ğŸ§  AI ëª¨ë¸ ì„ íƒ',
            options=available_models,
            index=available_models.index(st.session_state.selected_model) if st.session_state.selected_model in available_models else 0,
            help='ClaudeëŠ” ANTHROPIC_API_KEY, OpenAIëŠ” OPENAI_API_KEY í•„ìš”'
        )
        
        if selected_model != st.session_state.selected_model:
            st.session_state.selected_model = selected_model
        
        st.markdown("---")
        
        st.markdown("""
        ### ğŸ’¡ ì‚¬ìš© ë°©ë²•
        
        **ë²ˆì—­ ëª¨ë“œ:**
        1. ì›ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”
        2. ì›ë¬¸ ì–¸ì–´ë¥¼ ì„ íƒí•˜ì„¸ìš”
        3. ë²ˆì—­í•  ì–¸ì–´ë“¤ì„ ì„ íƒí•˜ì„¸ìš”
        4. í•„ìš”ì‹œ ì¶”ê°€ ì§€ì‹œì‚¬í•­ì„ ì…ë ¥í•˜ì„¸ìš” (ì„ íƒì‚¬í•­)
        5. 'ë²ˆì—­í•˜ê¸°' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”
        
        **ì§ˆë¬¸ ë‹µë³€ ëª¨ë“œ:**
        1. ì›ë¬¸ì„ ë¹„ì›Œë‘ì„¸ìš”
        2. ì§ˆë¬¸/ìš”ì²­ì‚¬í•­ì„ ì…ë ¥í•˜ì„¸ìš”
        3. ë‹µë³€ë°›ì„ ì–¸ì–´ë“¤ì„ ì„ íƒí•˜ì„¸ìš”
        4. 'ì§ˆë¬¸í•˜ê¸°' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”
        
        ### ğŸ¯ íŠ¹ì§•
        - 10ê°œ ì–¸ì–´ ì§€ì›
        - Claude & OpenAI ëª¨ë¸ ì§€ì›
        - ë™ì‹œ ë‹¤ì¤‘ ë²ˆì—­
        - ì™„ì „í•œ LLM ê¸°ëŠ¥
        - ìŒì„± ìƒì„± ê¸°ëŠ¥
        - ì„ íƒì  ì»¤ìŠ¤í…€ ì§€ì‹œì‚¬í•­
        
        ### ğŸŒ ì§€ì› ì–¸ì–´
        - í•œêµ­ì–´, ì˜ì–´, ì¤‘êµ­ì–´, ì¼ë³¸ì–´
        - í”„ë‘ìŠ¤ì–´, ë…ì¼ì–´, ìŠ¤í˜ì¸ì–´
        - ì´íƒˆë¦¬ì•„ì–´, ëŸ¬ì‹œì•„ì–´, í¬ë¥´íˆ¬ê°ˆì–´
        """)
    
    # ë©”ì¸ ì˜ì—­
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.subheader("ì…ë ¥")
        
        # ì›ë¬¸ ì…ë ¥
        source_text = st.text_area(
            "ì›ë¬¸ í…ìŠ¤íŠ¸ (ë²ˆì—­ ëª¨ë“œ)",
            height=150,
            placeholder="ë²ˆì—­í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”. ë¹„ì›Œë‘ë©´ ì§ˆë¬¸ ë‹µë³€ ëª¨ë“œê°€ ë©ë‹ˆë‹¤.",
            help="ì›ë¬¸ì„ ì…ë ¥í•˜ë©´ ë²ˆì—­ ëª¨ë“œ, ë¹„ì›Œë‘ë©´ ì§ˆë¬¸ ë‹µë³€ ëª¨ë“œ"
        )
        
        # í”„ë¡¬í”„íŠ¸/ì§ˆë¬¸ ì…ë ¥
        prompt_input = st.text_area(
            "í”„ë¡¬í”„íŠ¸/ì§ˆë¬¸ (ì„ íƒì‚¬í•­)",
            height=100,
            placeholder="ë²ˆì—­ ì§€ì‹œì‚¬í•­ ë˜ëŠ” ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...",
            help="ë²ˆì—­ ëª¨ë“œ: íŠ¹ë³„í•œ ë²ˆì—­ ì§€ì‹œì‚¬í•­ (ì„ íƒì‚¬í•­)\nì§ˆë¬¸ ëª¨ë“œ: ë‹µë³€ë°›ê³  ì‹¶ì€ ì§ˆë¬¸"
        )
        
        # ëª¨ë“œ ìë™ ê°ì§€
        is_question_mode = not source_text.strip()
        mode_display = "ğŸ¤– ì§ˆë¬¸ ë‹µë³€ ëª¨ë“œ" if is_question_mode else "ğŸ”„ ë²ˆì—­ ëª¨ë“œ"
        st.info(f"í˜„ì¬ ëª¨ë“œ: {mode_display}")
        
        # ì–¸ì–´ ì„ íƒ
        available_languages = [
            "í•œêµ­ì–´", "ì˜ì–´", "ì¤‘êµ­ì–´", "ì¼ë³¸ì–´", "í”„ë‘ìŠ¤ì–´", 
            "ë…ì¼ì–´", "ìŠ¤í˜ì¸ì–´", "ì´íƒˆë¦¬ì•„ì–´", "ëŸ¬ì‹œì•„ì–´", "í¬ë¥´íˆ¬ê°ˆì–´"
        ]
        
        if not is_question_mode:
            source_language = st.selectbox(
                "ì›ë¬¸ ì–¸ì–´",
                available_languages,
                help="ì›ë¬¸ì˜ ì–¸ì–´ë¥¼ ì„ íƒí•˜ì„¸ìš”"
            )
        else:
            source_language = "í•œêµ­ì–´"  # ì§ˆë¬¸ ëª¨ë“œì—ì„œëŠ” ê¸°ë³¸ê°’
        
        target_languages = st.multiselect(
            "ë²ˆì—­í•  ì–¸ì–´ë“¤" if not is_question_mode else "ë‹µë³€ë°›ì„ ì–¸ì–´ë“¤",
            available_languages,
            default=["ì˜ì–´"] if not is_question_mode else ["í•œêµ­ì–´"],
            help="ì—¬ëŸ¬ ì–¸ì–´ë¥¼ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
        )
        
        # ìŒì„± ìƒì„± ì˜µì…˜
        st.markdown("### ğŸ™ï¸ ìŒì„± ìƒì„± ì˜µì…˜")
        enable_tts = st.checkbox("ìŒì„± íŒŒì¼ ìƒì„±", value=False, help="ê²°ê³¼ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤ (OpenAI API í•„ìš”)")
        
        if enable_tts:
            voice_type = st.selectbox(
                "ìŒì„± íƒ€ì…",
                [
                    "ë‚¨ì„± (ê¹Šì€ ëª©ì†Œë¦¬)",
                    "ë‚¨ì„± (ì¤‘ê°„ í†¤)",
                    "ì—¬ì„± (ë°ì€ ëª©ì†Œë¦¬)",
                    "ì—¬ì„± (ì°¨ë¶„í•œ ëª©ì†Œë¦¬)",
                    "ì¤‘ì„±ì ì¸ ëª©ì†Œë¦¬"
                ],
                help="OpenAI TTSë¥¼ ì‚¬ìš©í•œ ìŒì„± ìƒì„±"
            )
        else:
            voice_type = None
    
    with col2:
        st.subheader("ê²°ê³¼")
        
        # ë²„íŠ¼
        button_text = "ì§ˆë¬¸í•˜ê¸°" if is_question_mode else "ë²ˆì—­í•˜ê¸°"
        if st.button(button_text, type="primary"):
            # ì§ˆë¬¸ ëª¨ë“œì—ì„œëŠ” í”„ë¡¬í”„íŠ¸ê°€ í•„ìˆ˜
            if is_question_mode and not prompt_input.strip():
                st.warning("ì§ˆë¬¸ ë‹µë³€ ëª¨ë“œì—ì„œëŠ” ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                return
            
            # ë²ˆì—­ ëª¨ë“œì—ì„œëŠ” ì›ë¬¸ì´ í•„ìˆ˜    
            if not is_question_mode and not source_text.strip():
                st.warning("ë²ˆì—­ ëª¨ë“œì—ì„œëŠ” ì›ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                return
                
            if not target_languages:
                st.warning("ë²ˆì—­í•  ì–¸ì–´ë¥¼ ìµœì†Œ í•˜ë‚˜ ì„ íƒí•´ì£¼ì„¸ìš”.")
                return
                
            # ì§„í–‰ ìƒí™© í‘œì‹œ
            progress_text = "ì§ˆë¬¸ì— ë‹µë³€í•˜ê³  ìˆìŠµë‹ˆë‹¤..." if is_question_mode else "ë²ˆì—­í•˜ê³  ìˆìŠµë‹ˆë‹¤..."
            with st.spinner(progress_text):
                start_time = time.time()
                
                # ë²ˆì—­/ë‹µë³€ ìˆ˜í–‰
                results = translate_to_multiple_languages(
                    selected_model, source_text, prompt_input, source_language, target_languages, is_question_mode
                )
                
                end_time = time.time()
                processing_time = round(end_time - start_time, 2)
                
                # ê²°ê³¼ í‘œì‹œ
                if results:
                    st.success(f"ì™„ë£Œ! (ì²˜ë¦¬ ì‹œê°„: {processing_time}ì´ˆ)")
                    
                    # ê° ì–¸ì–´ë³„ ê²°ê³¼ë¥¼ íƒ­ìœ¼ë¡œ í‘œì‹œ
                    if len(target_languages) > 1:
                        tabs = st.tabs([f"ğŸŒ {lang}" for lang in target_languages])
                        for i, lang in enumerate(target_languages):
                            with tabs[i]:
                                result_text = results.get(lang, "ì˜¤ë¥˜ ë°œìƒ")
                                st.text_area(
                                    f"{lang} ê²°ê³¼",
                                    value=result_text,
                                    height=200,
                                    disabled=True
                                )
                                
                                # ìŒì„± ìƒì„±
                                if enable_tts and voice_type and result_text and not result_text.startswith("ì˜¤ë¥˜"):
                                    with st.spinner(f"{lang} ìŒì„± ìƒì„± ì¤‘..."):
                                        audio_html = text_to_speech(result_text, voice_type)
                                        if audio_html:
                                            st.markdown(f"### ğŸ™ï¸ {lang} ìŒì„±")
                                            st.markdown(audio_html, unsafe_allow_html=True)
                                        else:
                                            st.warning("ìŒì„± ìƒì„± ì‹¤íŒ¨ (OpenAI API í‚¤ í™•ì¸ í•„ìš”)")
                    else:
                        # ì–¸ì–´ê°€ í•˜ë‚˜ë©´ ë°”ë¡œ í‘œì‹œ
                        lang = target_languages[0]
                        result_text = results.get(lang, "ì˜¤ë¥˜ ë°œìƒ")
                        st.text_area(
                            f"{lang} ê²°ê³¼",
                            value=result_text,
                            height=200,
                            disabled=True
                        )
                        
                        # ìŒì„± ìƒì„±
                        if enable_tts and voice_type and result_text and not result_text.startswith("ì˜¤ë¥˜"):
                            with st.spinner(f"{lang} ìŒì„± ìƒì„± ì¤‘..."):
                                audio_html = text_to_speech(result_text, voice_type)
                                if audio_html:
                                    st.markdown(f"### ğŸ™ï¸ {lang} ìŒì„±")
                                    st.markdown(audio_html, unsafe_allow_html=True)
                                else:
                                    st.warning("ìŒì„± ìƒì„± ì‹¤íŒ¨ (OpenAI API í‚¤ í™•ì¸ í•„ìš”)")
                    
                    # í†µê³„ ì •ë³´
                    with st.expander("ğŸ“Š ì²˜ë¦¬ ì •ë³´"):
                        col_stat1, col_stat2, col_stat3, col_stat4 = st.columns(4)
                        with col_stat1:
                            st.metric("ì‚¬ìš© ëª¨ë¸", selected_model)
                        with col_stat2:
                            st.metric("ì²˜ë¦¬ ì–¸ì–´ ìˆ˜", len(target_languages))
                        with col_stat3:
                            st.metric("ì²˜ë¦¬ ì‹œê°„", f"{processing_time}ì´ˆ")
                        with col_stat4:
                            if not is_question_mode and source_text:
                                st.metric("ì›ë¬¸ ê¸¸ì´", f"{len(source_text)}ì")
                            else:
                                st.metric("í”„ë¡¬í”„íŠ¸ ê¸¸ì´", f"{len(prompt_input)}ì")

if __name__ == "__main__":
    main() 