import streamlit as st
import pandas as pd
from datetime import datetime
import mysql.connector
import os
from dotenv import load_dotenv
from openai import OpenAI
import requests
import json
import base64

load_dotenv()

def connect_to_db():
    """MySQL DB ì—°ê²°"""
    return mysql.connector.connect(
        user=os.getenv('SQL_USER'),
        password=os.getenv('SQL_PASSWORD'),
        host=os.getenv('SQL_HOST'),
        database=os.getenv('SQL_DATABASE_NEWBIZ'),
        charset='utf8mb4',
        collation='utf8mb4_unicode_ci'
    )

def main():
    st.title("ğŸ“š ë…ì„œ í† ë¡  ì¡°íšŒ")
    
    # OpenAI API í‚¤ ì„¤ì •
    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
    if not OPENAI_API_KEY:
        st.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.stop()
    
    # AI ëª¨ë¸ ì„ íƒ (ê¸°ë³¸ê°’: GPT-4)
    MODEL_NAME = os.getenv('MODEL_NAME', 'gpt-4o-mini')
    ai_models = {
        "GPT-4": MODEL_NAME,
        "GPT-3.5": "gpt-3.5-turbo"
    }
    
    # ê³ ê¸‰ ì„¤ì • ì„¹ì…˜
    with st.expander("ê³ ê¸‰ ì„¤ì •"):
        use_local_llm = st.checkbox("ë¡œì»¬ LLM ì‚¬ìš©", value=False)
        
        if use_local_llm:
            local_models = {
                "Deepseek 14B": "deepseek-r1:14b",
                "Deepseek 32B": "deepseek-r1:32b",
                "Llama 3.1": "llama3.1:latest",
                "Phi-4": "phi4:latest",
                "Mistral": "mistral:latest"
            }
            selected_model = st.selectbox(
                "ë¡œì»¬ LLM ëª¨ë¸ ì„ íƒ",
                list(local_models.keys())
            )
            model_key = f"Local - {selected_model}"
            model_name = local_models[selected_model]
        else:
            selected_model = st.selectbox(
                "OpenAI ëª¨ë¸ ì„ íƒ",
                list(ai_models.keys()),
                index=0
            )
            model_key = selected_model
            model_name = ai_models[selected_model]
    
    # í•„í„° ì˜µì…˜
    col1, col2 = st.columns(2)
    
    with col1:
        titles = get_book_titles()
        if "í¼ìŠ¤ë„ MBA" not in titles:
            titles = ["í¼ìŠ¤ë„ MBA"] + titles
        
        selected_title = st.selectbox(
            "ì±… ì„ íƒ",
            titles,
            index=titles.index("í¼ìŠ¤ë„ MBA") if "í¼ìŠ¤ë„ MBA" in titles else 0
        )
    
    with col2:
        type_mapping = {
            "ìš”ì•½": "summary",
            "ì ìš©": "application"
        }
        material_type = st.selectbox(
            "ìë£Œ ìœ í˜•",
            list(type_mapping.keys())
        )
    
    # ì ìš© ìë£Œì¸ ê²½ìš° ë¶„ì„ í‚¤ì›Œë“œ ì„ íƒ
    analysis_keyword = None
    if material_type == "ì ìš©":
        keywords = ["ê°€ì¹˜ ì°½ì¡°", "ë§ˆì¼€íŒ…", "ì„¸ì¼ì¦ˆ", "ê°€ì¹˜ ì „ë‹¬", "ì¬ë¬´", "ê¸°íƒ€"]
        selected_keyword = st.selectbox("ë¶„ì„ í‚¤ì›Œë“œ", keywords)
        
        if selected_keyword == "ê¸°íƒ€":
            analysis_keyword = st.text_input("í‚¤ì›Œë“œ ì§ì ‘ ì…ë ¥")
        else:
            analysis_keyword = selected_keyword
    
    # íŒŒì¼ ëª©ë¡ ì¡°íšŒ
    files = get_files(selected_title, type_mapping[material_type])
    
    if files:
        selected_file = st.selectbox(
            "íŒŒì¼ ì„ íƒ",
            files,
            format_func=lambda x: f"{x['file_name']} ({x['created_at'].strftime('%Y-%m-%d')})"
        )
        
        if selected_file:
            st.write(f"### {selected_file['file_name']}")
            st.markdown(selected_file['content'])
            st.write("---")
            st.write(f"*ë“±ë¡ì¼: {selected_file['created_at'].strftime('%Y-%m-%d')}*")
            
            # AI ë¶„ì„/ì˜ê²¬ ë²„íŠ¼
            if material_type == "ì ìš©" and analysis_keyword:
                # AI ë¶„ì„ ê²°ê³¼ í‘œì‹œ ì»¨í…Œì´ë„ˆ ìƒì„±
                analysis_container = st.container()
                
                if st.button("AI ë¶„ì„"):
                    with st.spinner("AIê°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                        analysis = analyze_content(
                            selected_file['content'],
                            analysis_keyword,
                            model_key,
                            model_name
                        )
                        st.session_state.ai_analysis = analysis
                
                # AI ë¶„ì„ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í‘œì‹œ
                if 'ai_analysis' in st.session_state:
                    with analysis_container:
                        st.write("### AI ë¶„ì„ ê²°ê³¼")
                        st.write(st.session_state.ai_analysis)
                        
                        # ìŒì„± ì¬ìƒ ë²„íŠ¼
                        col1, col2 = st.columns([1, 3])
                        with col1:
                            if st.button("ğŸ”Š ìŒì„±ìœ¼ë¡œ ë“£ê¸°"):
                                with st.spinner("ìŒì„±ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                                    # AI ë¶„ì„ ê²°ê³¼ë§Œ ìŒì„±ìœ¼ë¡œ ë³€í™˜
                                    audio_html = text_to_speech(st.session_state.ai_analysis)
                                    if audio_html:
                                        st.markdown(audio_html, unsafe_allow_html=True)
            
            elif material_type == "ìš”ì•½":
                # AI ì˜ê²¬ í‘œì‹œ ì»¨í…Œì´ë„ˆ ìƒì„±
                opinion_container = st.container()
                
                # AI ì˜ê²¬ ìƒì„± ë²„íŠ¼
                if st.button("ğŸ¤– AI ì˜ê²¬ ìƒì„±"):
                    with st.spinner("AIê°€ ì˜ê²¬ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                        st.session_state.ai_opinion = generate_business_opinion(selected_file['content'])
                
                # AI ì˜ê²¬ì´ ìˆìœ¼ë©´ í‘œì‹œ
                if 'ai_opinion' in st.session_state:
                    with opinion_container:
                        st.write("### ğŸ’¡ AI ì˜ê²¬")
                        st.write(st.session_state.ai_opinion)
                        
                        # ìŒì„± ì¬ìƒ ë²„íŠ¼
                        col1, col2 = st.columns([1, 3])
                        with col1:
                            if st.button("ğŸ”Š ìŒì„±ìœ¼ë¡œ ë“£ê¸°"):
                                with st.spinner("ìŒì„±ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                                    combined_text = f"""
                                    ìš”ì•½ ë‚´ìš©ì…ë‹ˆë‹¤.
                                    {selected_file['content']}
                                    
                                    AI ì˜ê²¬ì…ë‹ˆë‹¤.
                                    {st.session_state.ai_opinion}
                                    """
                                    audio_html = text_to_speech(combined_text)
                                    if audio_html:
                                        st.markdown(audio_html, unsafe_allow_html=True)
    else:
        st.info(f"{selected_title}ì˜ {material_type} ìë£Œê°€ ì—†ìŠµë‹ˆë‹¤.")

def get_files(book_title, material_type):
    """íŒŒì¼ ëª©ë¡ ì¡°íšŒ"""
    conn = connect_to_db()
    cursor = conn.cursor(dictionary=True)
    
    try:
        cursor.execute("""
            SELECT *
            FROM reading_materials
            WHERE book_title = %s
            AND type = %s
            ORDER BY created_at DESC
        """, (book_title, material_type))
        
        return cursor.fetchall()
    finally:
        cursor.close()
        conn.close()

def get_book_titles():
    """ì €ì¥ëœ ì±… ì œëª© ëª©ë¡ ì¡°íšŒ"""
    conn = connect_to_db()
    cursor = conn.cursor()
    
    try:
        cursor.execute("""
            SELECT DISTINCT book_title
            FROM reading_materials
            ORDER BY book_title
        """)
        return [row[0] for row in cursor.fetchall()]
    finally:
        cursor.close()
        conn.close()

def analyze_content(content, keyword, model_key, model_name):
    """AIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‚´ìš© ë¶„ì„"""
    base_prompt = f"""
    ë‹¤ìŒ ì‚¬ì—…ê³„íšì„œë¥¼ '{keyword}' ê´€ì ì—ì„œë§Œ ì§‘ì¤‘ì ìœ¼ë¡œ ë¶„ì„í•´ ì£¼ì„¸ìš”.
    ë‹¤ë¥¸ ê´€ì ì€ ì œì™¸í•˜ê³  ì˜¤ì§ '{keyword}' ì¸¡ë©´ì—ì„œë§Œ ê²€í† í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.

    ë¶„ì„í•  í…ìŠ¤íŠ¸:
    {content}
    
    ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”:

    [í•µì‹¬ ìš”ì•½]
    - '{keyword}' ê´€ì ì—ì„œë§Œ ë³¸ í•µì‹¬ ë‚´ìš©ì„ 2-3ì¤„ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”
    - '{keyword}' ì¸¡ë©´ì˜ ê°€ì¥ ì¤‘ìš”í•œ ì‹œì‚¬ì  1-2ê°€ì§€ë¥¼ ì œì‹œí•´ ì£¼ì„¸ìš”

    [ì£¼ìš” ë¶„ì„]
    1. '{keyword}' ê´€ë ¨ ê°•ì  (2ê°€ì§€)
        - ê° ê°•ì ì´ '{keyword}' ì¸¡ë©´ì—ì„œ ê°€ì§€ëŠ” êµ¬ì²´ì  ê·¼ê±°ì™€ íš¨ê³¼
    
    2. '{keyword}' ì¸¡ë©´ì˜ ê°œì„ ì  (2ê°€ì§€)
        - ê° ê°œì„ ì ì´ '{keyword}' ê´€ì ì—ì„œ ê°€ì§€ëŠ” ë¬¸ì œì™€ í•´ê²° ë°©ì•ˆ

    [ì‹¤í–‰ ì œì•ˆ]
    1. '{keyword}' ì¤‘ì‹¬ì˜ ë‹¨ê¸° ê³¼ì œ (1-3ê°œì›”)
        - '{keyword}' ê°•í™”ë¥¼ ìœ„í•œ ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ 2ê°€ì§€ ë°©ì•ˆ
        - ê°ê°ì´ '{keyword}' ì¸¡ë©´ì—ì„œ ê°€ì ¸ì˜¬ ê¸°ëŒ€íš¨ê³¼
    
    2. '{keyword}' ì¤‘ì‹¬ì˜ ì¤‘ê¸° ê³¼ì œ (3-6ê°œì›”)
        - '{keyword}' ì—­ëŸ‰ ê°•í™”ë¥¼ ìœ„í•œ 2ê°€ì§€ ì „ëµ ë°©ì•ˆ
        - '{keyword}' ê´€ì ì˜ ì‹¤í–‰ ë‹¨ê³„ì™€ ì„±ê³¼ ì§€í‘œ

    * ëª¨ë“  ë‚´ìš©ì„ '{keyword}' ê´€ì ì—ì„œë§Œ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì‹œë˜, ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•´ ì£¼ì„¸ìš”.
    * ë‹¤ë¥¸ ê´€ì ì´ë‚˜ ì£¼ì œëŠ” ì œì™¸í•˜ê³ , ì˜¤ì§ '{keyword}'ì—ë§Œ ì§‘ì¤‘í•´ ì£¼ì„¸ìš”.
    """

    if "Local" in model_key:
        prompt = f"""You are a business consultant analyzing a business plan specifically focusing on '{keyword}'.
        Please provide your analysis in Korean, strictly following this format:

        [í‚¤ì›Œë“œ ë°˜ì˜ë„] 
        '{keyword}'ì— ëŒ€í•´ 'ìƒ', 'ì¤‘', 'í•˜' ì¤‘ í•˜ë‚˜ë§Œ ì„ íƒ

        [í‰ê°€ ê·¼ê±°]
        '{keyword}'ì™€ ì§ì ‘ ê´€ë ¨ëœ êµ¬ì²´ì  ê·¼ê±°ë§Œ 2-3ì¤„ë¡œ ì‘ì„±

        [ì „ì²´ ë…¼í‰]
        '{keyword}' ê´€ì ì—ì„œë§Œ ë‹¤ìŒ ë‚´ìš©ì„ 3-4ì¤„ë¡œ ì‘ì„±:
        - ê°•ì ê³¼ ì°¨ë³„í™” ìš”ì†Œ
        - ì‹¤í˜„ ê°€ëŠ¥ì„±
        - ì‹œì¥ ê²½ìŸë ¥

        [ë³´ì™„ í•„ìš”ì‚¬í•­]
        '{keyword}'ì— ê´€ë ¨ëœ ë‹¤ìŒ ì„¸ ê°€ì§€ë¥¼ ê°ê° í•œ ì¤„ë¡œ ì‘ì„±:
        - êµ¬ì²´ì ì¸ ì‹¤í–‰ ë°©ì•ˆ
        - ìœ„í—˜ ìš”ì†Œ ëŒ€ì‘ ë°©ì•ˆ
        - ì‹œì¥ ëŒ€ì‘ ì „ëµ

        Review guidelines for '{keyword}':
        {keyword_guide.get(keyword, "í‚¤ì›Œë“œì™€ ê´€ë ¨ëœ ëª¨ë“  ì¸¡ë©´ì„ ê²€í† ")}

        {base_prompt}

        Important:
        1. Focus ONLY on aspects related to '{keyword}'
        2. Provide ALL responses in Korean
        3. Follow the exact format specified
        4. Make practical and specific suggestions
        """
    else:
        prompt = base_prompt

    try:
        if "Local" in model_key:
            return analyze_with_local_llm(prompt, model_name)
        else:
            return analyze_with_openai(prompt, model_name)
    except Exception as e:
        st.error(f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def analyze_with_openai(prompt, model):
    """OpenAI APIë¥¼ ì‚¬ìš©í•œ ë¶„ì„"""
    try:
        client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ê²½ì˜ ì»¨ì„¤í„´íŠ¸ë¡œì„œ ì‚¬ì—…ê³„íšì„œë¥¼ ë¶„ì„í•˜ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ ì œê³µí•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=1000
        )
        
        if hasattr(response.choices[0].message, 'content'):
            return response.choices[0].message.content
        else:
            st.error("API ì‘ë‹µì— contentê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
    except Exception as e:
        st.error(f"OpenAI API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def analyze_with_local_llm(prompt, model="mistral:latest"):
    """ë¡œì»¬ LLMì„ ì‚¬ìš©í•œ ë¶„ì„"""
    url = "http://localhost:11434/api/generate"
    
    data = {
        "model": model,
        "prompt": prompt,
        "temperature": 0.3,
        "max_tokens": 1000
    }
    
    try:
        response = requests.post(url, json=data, stream=True)
        
        # ì „ì²´ ì‘ë‹µ í…ìŠ¤íŠ¸ë¥¼ ì €ì¥í•  ë³€ìˆ˜
        full_response = ""
        
        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
        for line in response.iter_lines():
            if line:
                # ê° ë¼ì¸ì„ JSONìœ¼ë¡œ íŒŒì‹±
                json_response = json.loads(line)
                if 'response' in json_response:
                    # ì‘ë‹µ í…ìŠ¤íŠ¸ ëˆ„ì 
                    full_response += json_response['response']
                    
                # ì™„ë£Œ ì—¬ë¶€ í™•ì¸
                if json_response.get('done', False):
                    break
        
        return full_response
        
    except Exception as e:
        st.error(f"ë¡œì»¬ LLM í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def generate_business_opinion(summary_text):
    """ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì ì—ì„œì˜ AI ì˜ê²¬ ìƒì„±"""
    client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
    
    # ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ë ¨ í‚¤ì›Œë“œ
    business_keywords = [
        "ì „ëµ", "ì„±ê³¼", "íš¨ìœ¨", "ìƒì‚°ì„±", "í˜ì‹ ", "ì„±ì¥", "ë§¤ì¶œ", "ë¹„ìš©",
        "ê³ ê°", "ì‹œì¥", "ê²½ìŸ", "ê°€ì¹˜", "ë¦¬ë”ì‹­", "ê´€ë¦¬", "ìš´ì˜", "í”„ë¡œì„¸ìŠ¤"
    ]
    
    # ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì¥ ì„ íƒ
    sentences = [s.strip() for s in summary_text.split('.') if len(s.strip()) > 10]
    best_sentence = max(sentences, 
                       key=lambda x: sum(1 for keyword in business_keywords if keyword in x),
                       default=None)
    
    if not best_sentence:
        return "ìš”ì•½ ë‚´ìš©ì—ì„œ ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ë ¨ ì£¼ì œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # ë¬¸ì¥ì—ì„œ í•µì‹¬ ì£¼ì œ ì¶”ì¶œ
    prompt_for_topic = f"""
    ë‹¤ìŒ ë¬¸ì¥ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ë ¨ í•µì‹¬ ì£¼ì œ í•˜ë‚˜ë§Œ 5ë‹¨ì–´ ì´ë‚´ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”:
    "{best_sentence}"
    
    ì˜ˆì‹œ í˜•ì‹: "ê³ ê° ê°€ì¹˜ ì°½ì¶œ", "íš¨ìœ¨ì  ë¦¬ë”ì‹­", "ì‹œì¥ í™•ì¥ ì „ëµ" ë“±
    """
    
    try:
        # í•µì‹¬ ì£¼ì œ ì¶”ì¶œ
        topic_response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ ì£¼ì œë¥¼ ì •í™•í•˜ê²Œ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt_for_topic}
            ],
            temperature=0.3,
            max_tokens=20
        )
        
        core_topic = topic_response.choices[0].message.content.strip().strip('"\'')
        
        # ì¶”ì¶œëœ ì£¼ì œì— ëŒ€í•œ ì˜ê²¬ ìƒì„±
        opinion_prompt = f"""
        ë‹¤ìŒì€ ë…ì„œ í† ë¡ ì—ì„œ ë‚˜ì˜¨ ì¤‘ìš”í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ì£¼ì œì…ë‹ˆë‹¤:
        
        ì£¼ì œ: "{core_topic}"
        
        ê´€ë ¨ ë¬¸ì¥: "{best_sentence}"
        
        ì´ ì£¼ì œì— ëŒ€í•´ ë¹„ì¦ˆë‹ˆìŠ¤ ì „ë¬¸ê°€ì˜ ì…ì¥ì—ì„œ ì˜ê²¬ì„ ì œì‹œí•´ì£¼ì„¸ìš”:
        - "ì˜¤ëŠ˜ ë…ì„œ í† ë¡ ì—ì„œ ë‹¤ë£¬ '{core_topic}'ì— ëŒ€í•´ ë§ì”€ë“œë¦¬ê² ìŠµë‹ˆë‹¤."ë¡œ ì‹œì‘í•˜ì—¬
        - ì´ ì£¼ì œê°€ ë¹„ì¦ˆë‹ˆìŠ¤ì— ì–´ë–¤ ì˜ë¯¸ê°€ ìˆëŠ”ì§€
        - ì–´ë–»ê²Œ ì‹¤ì œë¡œ ì ìš©í•´ë³¼ ìˆ˜ ìˆëŠ”ì§€
        - êµ¬ì²´ì ì¸ ì‹¤í–‰ ë°©ì•ˆê¹Œì§€ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”
        
        300-500ì ë‚´ì™¸ë¡œ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
        """
        
        opinion_response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì‹¤ë¬´ ê²½í—˜ì´ í’ë¶€í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ í•œ ê°€ì§€ ì£¼ì œì— ëŒ€í•´ì„œë§Œ ê¹Šì´ ìˆëŠ” í†µì°°ê³¼ ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ ì œê³µí•©ë‹ˆë‹¤."},
                {"role": "user", "content": opinion_prompt}
            ],
            temperature=0.7,
            max_tokens=1000
        )
        
        return opinion_response.choices[0].message.content
    except Exception as e:
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ì‘ë‹µ
        return f"ì˜¤ëŠ˜ ë…ì„œ í† ë¡ ì—ì„œ ë‹¤ë£¬ '{best_sentence}'ì— ê´€í•œ ì£¼ì œëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ì— ì¤‘ìš”í•œ ì‹œì‚¬ì ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ë¥¼ ì‹¤ì œ ì—…ë¬´ì— ì ìš©í•˜ë ¤ë©´ êµ¬ì²´ì ì¸ ì‹¤í–‰ ê³„íšê³¼ ë‹¨ê³„ë³„ ì ‘ê·¼ì´ í•„ìš”í•©ë‹ˆë‹¤."

def text_to_speech(text):
    """OpenAI TTS APIë¥¼ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜"""
    try:
        client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        
        # ìŒì„± ìƒì„± ìš”ì²­
        response = client.audio.speech.create(
            model="tts-1",  # ë˜ëŠ” "tts-1-hd"
            voice="alloy",  # 'alloy', 'echo', 'fable', 'onyx', 'nova', 'shimmer' ì¤‘ ì„ íƒ
            input=text
        )
        
        # ìŒì„± ë°ì´í„°ë¥¼ ë°”ì´íŠ¸ë¡œ ê°€ì ¸ì˜¤ê¸°
        audio_data = response.content
        
        # ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ base64ë¡œ ì¸ì½”ë”©
        audio_base64 = base64.b64encode(audio_data).decode('utf-8')
        
        # HTML audio íƒœê·¸ë¡œ í‘œì‹œ
        audio_html = f"""
            <audio controls>
                <source src="data:audio/mp3;base64,{audio_base64}" type="audio/mp3">
                Your browser does not support the audio element.
            </audio>
        """
        
        return audio_html
    except Exception as e:
        st.error(f"ìŒì„± ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

if __name__ == "__main__":
    main() 
    