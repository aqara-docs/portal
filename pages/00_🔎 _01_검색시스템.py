import streamlit as st
import os
import mysql.connector
from dotenv import load_dotenv
from openai import OpenAI
import anthropic
from langchain_openai import OpenAI as LangOpenAI
from langchain_anthropic import ChatAnthropic
import pandas as pd
import time

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
# Streamlit UI
st.set_page_config(page_title="ğŸ” DB RAG ê²€ìƒ‰ ì‹œìŠ¤í…œ", layout="wide")
st.title("ğŸ” MySQL DB RAG ê²€ìƒ‰ ì±—ë´‡")
# ì¸ì¦ ê¸°ëŠ¥ (ê°„ë‹¨í•œ ë¹„ë°€ë²ˆí˜¸ ë³´í˜¸)
if 'authenticated' not in st.session_state:
    st.session_state.authenticated = False
if not st.session_state.authenticated:
    password = st.text_input("ê´€ë¦¬ì ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password")
    if password == os.getenv('ADMIN_PASSWORD', 'mds0118!'):
        st.session_state.authenticated = True
        st.rerun()
    else:
        if password:
            st.error("ê´€ë¦¬ì ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤")
        st.stop()

# DB ì—°ê²° í•¨ìˆ˜ (00_ğŸ’¾_01_DBìƒì„±.py ì°¸ê³ )
def connect_to_db():
    return mysql.connector.connect(
        user=os.getenv('SQL_USER'),
        password=os.getenv('SQL_PASSWORD'),
        host=os.getenv('SQL_HOST'),
        database=os.getenv('SQL_DATABASE_NEWBIZ'),
        charset='utf8mb4',
        collation='utf8mb4_unicode_ci'
    )

def get_table_names():
    conn = connect_to_db()
    cursor = conn.cursor()
    cursor.execute("SHOW TABLES")
    tables = [row[0] for row in cursor.fetchall()]
    cursor.close()
    conn.close()
    return tables

def get_table_columns(table_name):
    conn = connect_to_db()
    cursor = conn.cursor()
    cursor.execute(f"DESCRIBE {table_name}")
    columns = [row[0] for row in cursor.fetchall()]
    cursor.close()
    conn.close()
    return columns

# --- ê²€ìƒ‰ ëª¨ë“œë³„ ë©€í‹°ì»¬ëŸ¼ ê²€ìƒ‰ í•¨ìˆ˜ ---
def search_table_multicolumn_mode(table, query, mode="OR", limit=10):
    conn = connect_to_db()
    cursor = conn.cursor(dictionary=True)
    columns = get_table_columns(table)
    keywords = [w for w in query.split() if w]
    if not keywords:
        keywords = [query]
    where_clauses = []
    params = []
    if mode == "OR":
        for col in columns:
            for kw in keywords:
                where_clauses.append(f"`{col}` LIKE %s")
                params.append(f"%{kw}%")
        where_sql = " OR ".join(where_clauses)
    elif mode == "AND":
        for kw in keywords:
            sub = []
            for col in columns:
                sub.append(f"`{col}` LIKE %s")
                params.append(f"%{kw}%")
            where_clauses.append("(" + " OR ".join(sub) + ")")
        where_sql = " AND ".join(where_clauses)
    elif mode == "EXACT":
        for col in columns:
            where_clauses.append(f"`{col}` = %s")
            params.append(query)
        where_sql = " OR ".join(where_clauses)
    else:
        where_sql = "1=0"
    sql = f"SELECT * FROM `{table}` WHERE {where_sql} LIMIT %s"
    params.append(limit)
    cursor.execute(sql, params)
    results = cursor.fetchall()
    cursor.close()
    conn.close()
    return results

def search_all_tables_multicolumn_mode(query, mode="OR", limit=5):
    results = []
    tables = get_table_names()
    for t in tables:
        try:
            partial = search_table_multicolumn_mode(t, query, mode, limit)
            if partial:
                for row in partial:
                    results.append({'table': t, **row})
        except Exception as e:
            continue
    return results

# --- LLM ë‹µë³€ ìƒì„± í•¨ìˆ˜ (DB ê²°ê³¼ë¥¼ contextë¡œ, ê°œì„ ) ---
def generate_llm_answer_rag(user_query, db_results, model_name, sql):
    max_results = 3
    max_val_len = 100
    if not db_results:
        context = f"[DB ê²€ìƒ‰ ê²°ê³¼: '{user_query}'ë¡œ ì „ì²´ í…Œì´ë¸”/ì»¬ëŸ¼ì—ì„œ ê²€ìƒ‰í–ˆìœ¼ë‚˜ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.]"
    else:
        context = f"[DB ê²€ìƒ‰ ê²°ê³¼: '{user_query}'ë¡œ ì „ì²´ í…Œì´ë¸”/ì»¬ëŸ¼ì—ì„œ ê²€ìƒ‰í•œ ê²°ê³¼ {len(db_results)}ê±´]\n"
        from collections import defaultdict
        table_counts = defaultdict(int)
        shown = 0
        for row in db_results:
            t = row.get('table', 'unknown')
            if table_counts[t] >= 5:
                continue
            row_str = f"[í…Œì´ë¸”: {t}] " + ", ".join([f"{k}: {str(v)[:max_val_len]}" for k, v in row.items() if k != 'table'])
            context += f"{shown+1}. {row_str}\n"
            table_counts[t] += 1
            shown += 1
        if len(db_results) > shown:
            context += f"... (ì´í•˜ {len(db_results)-shown}ê±´ ìƒëµ)\n"
    prompt = f"""
ì•„ë˜ëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ DBì—ì„œ '{user_query}'ë¡œ ê²€ìƒ‰í•œ ê²°ê³¼ì…ë‹ˆë‹¤.

- ë°˜ë“œì‹œ ì•„ë˜ DB ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìµœëŒ€í•œ í™œìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
- DB ê²°ê³¼ê°€ ë¶€ì¡±í•˜ë©´, ë¶€ì¡±í•œ ë¶€ë¶„ë§Œ ì¼ë°˜ ì§€ì‹ìœ¼ë¡œ ë³´ì™„í•˜ì„¸ìš”.
- DB ê²°ê³¼ë¥¼ ìš”ì•½/ë¶„ì„/í™œìš©í•´ì„œ ì‹¤ì œë¡œ ì „ëµë³´ê³ ì„œì˜ ê° í•­ëª©(ëª©í‘œ, í˜„í™©, ì „ëµ, ì‹¤í–‰ê³„íš ë“±)ì— êµ¬ì²´ì ìœ¼ë¡œ ë°˜ì˜í•˜ì„¸ìš”.
- DB ê²°ê³¼ê°€ ì „í˜€ ì—†ìœ¼ë©´, 'DBì— ê´€ë ¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤'ë¼ê³  ëª…í™•íˆ ë‹µë³€í•˜ì„¸ìš”.

[ì‚¬ìš©ì ì§ˆë¬¸]
{user_query}

[DB ê²€ìƒ‰ ê²°ê³¼]
{context}

[ì „ëµë³´ê³ ì„œ ì˜ˆì‹œ í¬ë§·]
1. ëª©í‘œ ë° ë°°ê²½:
2. í˜„í™© ë¶„ì„:
3. ì „ëµ ì œì•ˆ:
4. ì‹¤í–‰ ê³„íš:
5. ê¸°ëŒ€ íš¨ê³¼ ë° ê²°ë¡ :

[ë‹µë³€]
"""
    if model_name.startswith('claude'):
        client = ChatAnthropic(model=model_name, api_key=os.getenv('ANTHROPIC_API_KEY'), temperature=0.3, max_tokens=1200)
        response = client.invoke([
            {"role": "user", "content": prompt}
        ])
        return response.content if hasattr(response, 'content') else str(response)
    else:
        client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        response = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "user", "content": prompt}],
            max_tokens=1200,
            temperature=0.3
        )
        return response.choices[0].message.content

def summarize_db_reference(search_results, max_tables=3, max_rows_per_table=1, max_cols=3):
    from collections import defaultdict
    table_rows = defaultdict(list)
    for row in search_results:
        t = row.get('table', 'unknown')
        table_rows[t].append(row)
    ref_lines = []
    for i, (t, rows) in enumerate(table_rows.items()):
        if i >= max_tables:
            ref_lines.append(f"... (ì´í•˜ {len(table_rows)-max_tables}ê°œ í…Œì´ë¸” ìƒëµ)")
            break
        ref_lines.append(f"- í…Œì´ë¸”: {t}")
        if rows:
            # ëŒ€í‘œ row 1ê°œ, ì£¼ìš” ì»¬ëŸ¼ 3ê°œë§Œ í‘œì‹œ
            row = rows[0]
            cols = [k for k in row.keys() if k != 'table'][:max_cols]
            col_str = ", ".join([f"{k}={row[k]}" for k in cols])
            ref_lines.append(f"  - ì˜ˆì‹œ ë°ì´í„°: {col_str}")
    return "\n".join(ref_lines)



# ëª¨ë¸ ì„ íƒ
available_models = []
has_anthropic_key = os.environ.get('ANTHROPIC_API_KEY') is not None
if has_anthropic_key:
    available_models.extend([
        'claude-3-7-sonnet-latest',
        'claude-3-5-sonnet-latest',
        'claude-3-5-haiku-latest',
    ])
has_openai_key = os.environ.get('OPENAI_API_KEY') is not None
if has_openai_key:
    available_models.extend(['gpt-4o', 'gpt-4o-mini'])
if not available_models:
    available_models = ['claude-3-7-sonnet-latest']

# --- ë””í´íŠ¸ ëª¨ë¸: gpt-4o-miniê°€ ìˆìœ¼ë©´ ê·¸ê±¸ë¡œ, ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ëª¨ë¸ë¡œ ---
if 'selected_model' not in st.session_state:
    if 'gpt-4o-mini' in available_models:
        st.session_state.selected_model = 'gpt-4o-mini'
    else:
        st.session_state.selected_model = available_models[0]

st.session_state.selected_model = st.selectbox(
    'AI ëª¨ë¸ ì„ íƒ',
    options=available_models,
    index=available_models.index(st.session_state.selected_model) if st.session_state.selected_model in available_models else 0,
    help='Claude(Anthropic)ëŠ” ANTHROPIC_API_KEY, OpenAIëŠ” OPENAI_API_KEY í•„ìš”'
)

# --- ê²€ìƒ‰ ëª¨ë“œ ì„ íƒ ---
search_mode = st.radio(
    "ê²€ìƒ‰ ë°©ì‹ ì„ íƒ",
    options=["OR", "AND", "EXACT"],
    index=0,
    horizontal=True,
    help="ì—¬ëŸ¬ í‚¤ì›Œë“œ ì¤‘ í•˜ë‚˜ë¼ë„ í¬í•¨(OR), ëª¨ë‘ í¬í•¨(AND), ì™„ì „ ì¼ì¹˜(EXACT)"
)

# í…Œì´ë¸”/ì»¬ëŸ¼ ì„ íƒ
with st.sidebar:
    st.header('ğŸ”— DB í…Œì´ë¸”/ì»¬ëŸ¼ ì„ íƒ')
    tables = get_table_names()
    table_options = ['ì „ì²´'] + tables if tables else ['ì „ì²´']
    table = st.selectbox('í…Œì´ë¸” ì„ íƒ', table_options)
    if table == 'ì „ì²´':
        columns = ['ì „ì²´']
    else:
        columns = ['ì „ì²´'] + get_table_columns(table) if table else ['ì „ì²´']
    column = st.selectbox('ê²€ìƒ‰ ì»¬ëŸ¼ ì„ íƒ', columns) if columns else None
    st.markdown('---')
    st.caption('DBì—ì„œ ì›í•˜ëŠ” í…Œì´ë¸”/ì»¬ëŸ¼ì„ ì„ íƒ í›„, ì•„ë˜ ì±—ë´‡ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.')

# ì±—ë´‡ UI
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []

# --- ê²°ê³¼/ì§„í–‰ìƒí™© í‘œì‹œìš© ì»¨í…Œì´ë„ˆ ---
result_area = st.empty()

user_input = st.chat_input('ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: íŠ¹ì • ê³ ê°ì˜ ì£¼ë¬¸ ë‚´ì—­ì„ ì•Œë ¤ì¤˜)')

if user_input and tables:
    with result_area.container():
        if table == 'ì „ì²´' and (column == 'ì „ì²´' or column is None):
            st.info(f'ğŸ” ì „ì²´ í…Œì´ë¸”/ì „ì²´ ì»¬ëŸ¼ì—ì„œ [{search_mode}] ë°©ì‹ìœ¼ë¡œ ë¨¼ì € ê²€ìƒ‰ í›„, LLMì´ ìš”ì•½í•©ë‹ˆë‹¤.')
            search_results = search_all_tables_multicolumn_mode(user_input, search_mode, limit=10)
            st.write('ğŸ” [DB ê²€ìƒ‰ ê²°ê³¼]', search_results)
            if not search_results:
                st.warning('DBì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ë” ê°„ë‹¨íˆ í•˜ê±°ë‚˜, DBì— ì‹¤ì œë¡œ ìˆëŠ” ë‹¨ì–´ë¡œ ê²€ìƒ‰í•´ ë³´ì„¸ìš”.')
            with st.spinner('AIê°€ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...'):
                progress_bar = st.progress(0)
                for percent in range(0, 100, 5):
                    time.sleep(0.01)
                    progress_bar.progress(percent + 1)
                answer = generate_llm_answer_rag(user_input, search_results, st.session_state.selected_model, f'[{search_mode} ê²€ìƒ‰]')
                progress_bar.progress(100)
                progress_bar.empty()
                placeholder = st.empty()
                display_text = ""
                for char in answer:
                    display_text += char
                    placeholder.markdown(display_text)
                    time.sleep(0.01)
                # --- DB ë ˆí¼ëŸ°ìŠ¤ í‘œê¸° ---
                reference_text = summarize_db_reference(search_results)
                if reference_text:
                    st.markdown("---")
                    st.markdown("**[ì°¸ê³ í•œ DB ë ˆí¼ëŸ°ìŠ¤]**")
                    st.markdown(reference_text)
                st.session_state.chat_history.append({'user': user_input, 'bot': answer, 'search': search_results, 'sql': f'[{search_mode} ê²€ìƒ‰]'})
        else:
            st.info(f'ğŸ” {table} í…Œì´ë¸”ì—ì„œ [{search_mode}] ë°©ì‹ìœ¼ë¡œ ë¨¼ì € ê²€ìƒ‰ í›„, LLMì´ ìš”ì•½í•©ë‹ˆë‹¤.')
            search_results = search_table_multicolumn_mode(table, user_input, search_mode, limit=10)
            st.write('ğŸ” [DB ê²€ìƒ‰ ê²°ê³¼]', search_results)
            if not search_results:
                st.warning('DBì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ë” ê°„ë‹¨íˆ í•˜ê±°ë‚˜, DBì— ì‹¤ì œë¡œ ìˆëŠ” ë‹¨ì–´ë¡œ ê²€ìƒ‰í•´ ë³´ì„¸ìš”.')
            with st.spinner('AIê°€ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...'):
                progress_bar = st.progress(0)
                for percent in range(0, 100, 5):
                    time.sleep(0.01)
                    progress_bar.progress(percent + 1)
                answer = generate_llm_answer_rag(user_input, search_results, st.session_state.selected_model, f'[{search_mode} ê²€ìƒ‰]')
                progress_bar.progress(100)
                progress_bar.empty()
                placeholder = st.empty()
                display_text = ""
                for char in answer:
                    display_text += char
                    placeholder.markdown(display_text)
                    time.sleep(0.01)
                # --- DB ë ˆí¼ëŸ°ìŠ¤ í‘œê¸° ---
                reference_text = summarize_db_reference(search_results)
                if reference_text:
                    st.markdown("---")
                    st.markdown("**[ì°¸ê³ í•œ DB ë ˆí¼ëŸ°ìŠ¤]**")
                    st.markdown(reference_text)
                st.session_state.chat_history.append({'user': user_input, 'bot': answer, 'search': search_results, 'sql': f'[{search_mode} ê²€ìƒ‰]'})

# --- ëŒ€í™” ê¸°ë¡ í‘œì‹œ (ìµœì‹  ëŒ€í™”ê°€ ì•„ë˜ìª½ì— ì˜¤ë„ë¡, ChatGPT ìŠ¤íƒ€ì¼) ---
for chat in st.session_state.chat_history:
    with st.chat_message('user'):
        st.markdown(chat['user'])
    with st.chat_message('assistant'):
        st.markdown(chat['bot'])
        if chat.get('sql'):
            st.caption(f"[ê²€ìƒ‰ ë°©ì‹]: {chat['sql']}")
        if chat['search']:
            with st.expander('ğŸ” DB ê²€ìƒ‰ ê²°ê³¼ í¼ì¹˜ê¸°'):
                df = pd.DataFrame(chat['search'])
                st.dataframe(df)

if not tables:
    st.warning('DBì— í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤. DBë¥¼ ë¨¼ì € ìƒì„±í•´ ì£¼ì„¸ìš”.')
else:
    st.info('DBì—ì„œ ì›í•˜ëŠ” í…Œì´ë¸”/ì»¬ëŸ¼ì„ ì„ íƒí•˜ì§€ ì•Šìœ¼ë©´, ê¸°ë³¸ì ìœ¼ë¡œ ì „ì²´ í…Œì´ë¸”/ì „ì²´ ì»¬ëŸ¼ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤. ì±—ë´‡ì— ìì—°ì–´ë¡œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´, DB ê²€ìƒ‰ ê²°ê³¼ì™€ LLMì„ í™œìš©í•´ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤. (RAG ë°©ì‹)') 