import streamlit as st
import os
import mysql.connector
from dotenv import load_dotenv
from openai import OpenAI
import anthropic
from langchain_openai import OpenAI as LangOpenAI
from langchain_anthropic import ChatAnthropic
import pandas as pd
import time

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ì¸ì¦ ê¸°ëŠ¥ (ê°„ë‹¨í•œ ë¹„ë°€ë²ˆí˜¸ ë³´í˜¸)
if 'authenticated' not in st.session_state:
    st.session_state.authenticated = False
if not st.session_state.authenticated:
    password = st.text_input("ê´€ë¦¬ì ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password")
    if password == os.getenv('ADMIN_PASSWORD', 'mds0118!'):
        st.session_state.authenticated = True
        st.rerun()
    else:
        if password:
            st.error("ê´€ë¦¬ì ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤")
        st.stop()

# DB ì—°ê²° í•¨ìˆ˜ (00_ğŸ’¾_01_DBìƒì„±.py ì°¸ê³ )
def connect_to_db():
    return mysql.connector.connect(
        user=os.getenv('SQL_USER'),
        password=os.getenv('SQL_PASSWORD'),
        host=os.getenv('SQL_HOST'),
        database=os.getenv('SQL_DATABASE_NEWBIZ'),
        charset='utf8mb4',
        collation='utf8mb4_unicode_ci'
    )

def get_table_names():
    conn = connect_to_db()
    cursor = conn.cursor()
    cursor.execute("SHOW TABLES")
    tables = [row[0] for row in cursor.fetchall()]
    cursor.close()
    conn.close()
    return tables

def get_table_columns(table_name):
    conn = connect_to_db()
    cursor = conn.cursor()
    cursor.execute(f"DESCRIBE {table_name}")
    columns = [row[0] for row in cursor.fetchall()]
    cursor.close()
    conn.close()
    return columns

def search_table(table, column, query, limit=10):
    conn = connect_to_db()
    cursor = conn.cursor(dictionary=True)
    sql = f"SELECT * FROM `{table}` WHERE `{column}` LIKE %s LIMIT %s"
    cursor.execute(sql, (f"%{query}%", limit))
    results = cursor.fetchall()
    cursor.close()
    conn.close()
    return results

# --- DB ìŠ¤í‚¤ë§ˆ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ---
def get_schema_info():
    tables = get_table_names()
    schema = {}
    for t in tables:
        schema[t] = get_table_columns(t)
    return schema

# --- LLMì„ ì´ìš©í•œ ìì—°ì–´â†’SQL ë³€í™˜ ---
def generate_sql_from_question(question, schema_info, table=None):
    # schema_info: {table: [col1, col2, ...], ...}
    schema_str = "\n".join([f"{t}: {', '.join(cols)}" for t, cols in schema_info.items()])
    if table and table != 'ì „ì²´':
        prompt = f"""
ì•„ë˜ëŠ” MySQL ë°ì´í„°ë² ì´ìŠ¤ì˜ í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ì •ë³´ì…ë‹ˆë‹¤.
{table}: {', '.join(schema_info[table])}

ì‚¬ìš©ì ì§ˆë¬¸: {question}

ìœ„ í…Œì´ë¸”ì„ í™œìš©í•˜ì—¬ ì ì ˆí•œ SELECT ì¿¼ë¦¬(SQL)ë¥¼ í•œ ì¤„ë¡œ ìƒì„±í•´ ì£¼ì„¸ìš”. (ì˜ˆ: SELECT * FROM {table} WHERE ...)
ë°˜ë“œì‹œ LIMIT 10ì„ ë¶™ì´ì„¸ìš”. INSERT/UPDATE/DELETEëŠ” ê¸ˆì§€. ì¿¼ë¦¬ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
"""
    else:
        prompt = f"""
ì•„ë˜ëŠ” MySQL ë°ì´í„°ë² ì´ìŠ¤ì˜ í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ì •ë³´ì…ë‹ˆë‹¤.
{schema_str}

ì‚¬ìš©ì ì§ˆë¬¸: {question}

ì ì ˆí•œ í…Œì´ë¸”ì„ ì„ íƒí•˜ì—¬ SELECT ì¿¼ë¦¬(SQL)ë¥¼ í•œ ì¤„ë¡œ ìƒì„±í•´ ì£¼ì„¸ìš”. (ì˜ˆ: SELECT * FROM ... WHERE ...)
ë°˜ë“œì‹œ LIMIT 10ì„ ë¶™ì´ì„¸ìš”. INSERT/UPDATE/DELETEëŠ” ê¸ˆì§€. ì¿¼ë¦¬ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
"""
    # OpenAIë¡œ SQL ìƒì„± (ClaudeëŠ” SQL ìƒì„± ì‹ ë¢°ë„ê°€ ë‚®ìŒ)
    client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
    response = client.chat.completions.create(
        model='gpt-4o',
        messages=[{"role": "user", "content": prompt}],
        max_tokens=256,
        temperature=0.0
    )
    # --- SQL ì¶”ì¶œ: ë§ˆí¬ë‹¤ìš´ íƒœê·¸ ì œê±° ë° ì¿¼ë¦¬ë§Œ ì¶”ì¶œ ---
    sql_raw = response.choices[0].message.content.strip()
    # Remove markdown code block if present
    if sql_raw.startswith('```'):
        sql_raw = sql_raw.split('\n', 1)[-1]  # remove first line (```sql or ```)
    sql = sql_raw.replace('```', '').strip()
    # ì¿¼ë¦¬ë§Œ ì¶”ì¶œ (ì—¬ëŸ¬ ì¤„ì¼ ê²½ìš° ì²« ë²ˆì§¸ ì„¸ë¯¸ì½œë¡ ê¹Œì§€)
    sql = sql.split(';')[0]
    return sql

# --- SQL ì‹¤í–‰ í•¨ìˆ˜ (SELECTë§Œ í—ˆìš©) ---
def run_sql_query(sql):
    conn = connect_to_db()
    cursor = conn.cursor(dictionary=True)
    try:
        cursor.execute(sql)
        results = cursor.fetchall()
    except Exception as e:
        results = []
        st.error(f'SQL ì‹¤í–‰ ì˜¤ë¥˜: {e}')
    cursor.close()
    conn.close()
    return results

# --- LLM ë‹µë³€ ìƒì„± í•¨ìˆ˜ (DB ê²°ê³¼ë¥¼ contextë¡œ) ---
def generate_llm_answer_rag(user_query, db_results, model_name, sql):
    max_results = 3
    max_val_len = 100
    if not db_results:
        context = f"[DB ê²€ìƒ‰ ê²°ê³¼: SQL=\n{sql}\n\nê²°ê³¼ ì—†ìŒ]"
    else:
        context = f"[DB ê²€ìƒ‰ ê²°ê³¼: SQL=\n{sql}\n\n{len(db_results)}ê±´]\n"
        for i, row in enumerate(db_results[:max_results], 1):
            row_str = ", ".join([f"{k}: {str(v)[:max_val_len]}" for k, v in row.items()])
            context += f"{i}. {row_str}\n"
        if len(db_results) > max_results:
            context += f"... (ì´í•˜ {len(db_results)-max_results}ê±´ ìƒëµ)\n"
    prompt = f"""
ì•„ë˜ëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤. ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ìµœëŒ€í•œ êµ¬ì²´ì ì´ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ ì£¼ì„¸ìš”. ë§Œì•½ ê²€ìƒ‰ ê²°ê³¼ê°€ ë¶€ì¡±í•˜ë‹¤ë©´, ì¼ë°˜ì ì¸ ì§€ì‹ë„ í™œìš©í•´ ë‹µë³€í•´ ì£¼ì„¸ìš”.\n\n[ì‚¬ìš©ì ì§ˆë¬¸]\n{user_query}\n\n{context}\n\n[ë‹µë³€]"""
    if model_name.startswith('claude'):
        client = ChatAnthropic(model=model_name, api_key=os.getenv('ANTHROPIC_API_KEY'), temperature=0.3, max_tokens=1200)
        response = client.invoke([
            {"role": "user", "content": prompt}
        ])
        return response.content if hasattr(response, 'content') else str(response)
    else:
        client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        response = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "user", "content": prompt}],
            max_tokens=1200,
            temperature=0.3
        )
        return response.choices[0].message.content

# Streamlit UI
st.set_page_config(page_title="ğŸ” DB RAG ê²€ìƒ‰ ì‹œìŠ¤í…œ", layout="wide")
st.title("ğŸ” MySQL DB RAG ê²€ìƒ‰ ì±—ë´‡")

# ëª¨ë¸ ì„ íƒ
available_models = []
has_anthropic_key = os.environ.get('ANTHROPIC_API_KEY') is not None
if has_anthropic_key:
    available_models.extend([
        'claude-3-7-sonnet-latest',
        'claude-3-5-sonnet-latest',
        'claude-3-5-haiku-latest',
    ])
has_openai_key = os.environ.get('OPENAI_API_KEY') is not None
if has_openai_key:
    available_models.extend(['gpt-4o', 'gpt-4o-mini'])
if not available_models:
    available_models = ['claude-3-7-sonnet-latest']

# --- ë””í´íŠ¸ ëª¨ë¸: gpt-4o-miniê°€ ìˆìœ¼ë©´ ê·¸ê±¸ë¡œ, ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ëª¨ë¸ë¡œ ---
if 'selected_model' not in st.session_state:
    if 'gpt-4o-mini' in available_models:
        st.session_state.selected_model = 'gpt-4o-mini'
    else:
        st.session_state.selected_model = available_models[0]

st.session_state.selected_model = st.selectbox(
    'AI ëª¨ë¸ ì„ íƒ',
    options=available_models,
    index=available_models.index(st.session_state.selected_model) if st.session_state.selected_model in available_models else 0,
    help='Claude(Anthropic)ëŠ” ANTHROPIC_API_KEY, OpenAIëŠ” OPENAI_API_KEY í•„ìš”'
)

# í…Œì´ë¸”/ì»¬ëŸ¼ ì„ íƒ
with st.sidebar:
    st.header('ğŸ”— DB í…Œì´ë¸”/ì»¬ëŸ¼ ì„ íƒ')
    tables = get_table_names()
    table_options = ['ì „ì²´'] + tables if tables else ['ì „ì²´']
    table = st.selectbox('í…Œì´ë¸” ì„ íƒ', table_options)
    if table == 'ì „ì²´':
        columns = ['ì „ì²´']
    else:
        columns = ['ì „ì²´'] + get_table_columns(table) if table else ['ì „ì²´']
    column = st.selectbox('ê²€ìƒ‰ ì»¬ëŸ¼ ì„ íƒ', columns) if columns else None
    st.markdown('---')
    st.caption('DBì—ì„œ ì›í•˜ëŠ” í…Œì´ë¸”/ì»¬ëŸ¼ì„ ì„ íƒ í›„, ì•„ë˜ ì±—ë´‡ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.')

# --- ë©€í‹°ì»¬ëŸ¼ OR-LIKE ê²€ìƒ‰ í•¨ìˆ˜ ---
def search_table_multicolumn(table, query, limit=10):
    conn = connect_to_db()
    cursor = conn.cursor(dictionary=True)
    columns = get_table_columns(table)
    # í‚¤ì›Œë“œ ì¶”ì¶œ (ë„ì–´ì“°ê¸° ê¸°ì¤€, 2ê¸€ì ì´ìƒ)
    keywords = [w for w in query.split() if len(w) > 1]
    if not keywords:
        keywords = [query]
    like_clauses = []
    params = []
    for col in columns:
        for kw in keywords:
            like_clauses.append(f"`{col}` LIKE %s")
            params.append(f"%{kw}%")
    sql = f"SELECT * FROM `{table}` WHERE {' OR '.join(like_clauses)} LIMIT %s"
    params.append(limit)
    cursor.execute(sql, params)
    results = cursor.fetchall()
    cursor.close()
    conn.close()
    return results

# ì „ì²´ í…Œì´ë¸”/ì „ì²´ ì»¬ëŸ¼ ê²€ìƒ‰

def search_all_tables_multicolumn(query, limit=5):
    results = []
    tables = get_table_names()
    for t in tables:
        try:
            partial = search_table_multicolumn(t, query, limit)
            if partial:
                for row in partial:
                    results.append({'table': t, **row})
        except Exception as e:
            continue
    return results

# ì±—ë´‡ UI
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []

user_input = st.chat_input('ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: íŠ¹ì • ê³ ê°ì˜ ì£¼ë¬¸ ë‚´ì—­ì„ ì•Œë ¤ì¤˜)')

if user_input and tables:
    # --- ë¶„ê¸°: ì „ì²´/íŠ¹ì • í…Œì´ë¸”/ì»¬ëŸ¼ ---
    if table == 'ì „ì²´' and (column == 'ì „ì²´' or column is None):
        # 1. ì „ì²´ í…Œì´ë¸”/ì „ì²´ ì»¬ëŸ¼: í‚¤ì›Œë“œ ê¸°ë°˜ ë©€í‹°í…Œì´ë¸” ê²€ìƒ‰ â†’ LLM ìš”ì•½ (ì§„ì§œ RAG)
        st.info('ğŸ” ì „ì²´ í…Œì´ë¸”/ì „ì²´ ì»¬ëŸ¼ì—ì„œ í‚¤ì›Œë“œë¡œ ë¨¼ì € ê²€ìƒ‰ í›„, LLMì´ ìš”ì•½í•©ë‹ˆë‹¤.')
        search_results = search_all_tables_multicolumn(user_input, limit=10)
        st.write('ğŸ” [DB ê²€ìƒ‰ ê²°ê³¼]', search_results)
        if not search_results:
            st.warning('DBì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ë” ê°„ë‹¨íˆ í•˜ê±°ë‚˜, DBì— ì‹¤ì œë¡œ ìˆëŠ” ë‹¨ì–´ë¡œ ê²€ìƒ‰í•´ ë³´ì„¸ìš”.')
        with st.spinner('AIê°€ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...'):
            progress_bar = st.progress(0)
            for percent in range(0, 100, 5):
                time.sleep(0.01)
                progress_bar.progress(percent + 1)
            answer = generate_llm_answer_rag(user_input, search_results, st.session_state.selected_model, '[í‚¤ì›Œë“œ ê¸°ë°˜ ì „ì²´ í…Œì´ë¸” ê²€ìƒ‰]')
            progress_bar.progress(100)
            progress_bar.empty()
            # ChatGPT ìŠ¤íƒ€ì¼ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥
            placeholder = st.empty()
            display_text = ""
            for char in answer:
                display_text += char
                placeholder.markdown(display_text)
                time.sleep(0.01)
            st.session_state.chat_history.append({'user': user_input, 'bot': answer, 'search': search_results, 'sql': '[í‚¤ì›Œë“œ ê¸°ë°˜ ì „ì²´ í…Œì´ë¸” ê²€ìƒ‰]'})
    else:
        # 2. íŠ¹ì • í…Œì´ë¸”/ì»¬ëŸ¼: LLMì´ SQL ìƒì„± â†’ ì‹¤í–‰ â†’ ê²°ê³¼ë¥¼ LLMì— ì „ë‹¬
        with st.spinner('AIê°€ SQL ì¿¼ë¦¬ë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...'):
            schema_info = get_schema_info()
            try:
                sql = generate_sql_from_question(user_input, schema_info, table if table != 'ì „ì²´' else None)
            except Exception as e:
                st.error(f'LLM SQL ìƒì„± ì‹¤íŒ¨: {e}')
                sql = None
        st.write('ğŸ“ [LLMì´ ìƒì„±í•œ SQL]', sql)
        db_results = []
        if sql:
            db_results = run_sql_query(sql)
        st.write('ğŸ” [DB ê²€ìƒ‰ ê²°ê³¼]', db_results)
        if not db_results:
            st.warning('DBì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ë” ê°„ë‹¨íˆ í•˜ê±°ë‚˜, DBì— ì‹¤ì œë¡œ ìˆëŠ” ë‹¨ì–´ë¡œ ê²€ìƒ‰í•´ ë³´ì„¸ìš”.')
        with st.spinner('AIê°€ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...'):
            progress_bar = st.progress(0)
            for percent in range(0, 100, 5):
                time.sleep(0.01)
                progress_bar.progress(percent + 1)
            answer = generate_llm_answer_rag(user_input, db_results, st.session_state.selected_model, sql or '(SQL ìƒì„± ì‹¤íŒ¨)')
            progress_bar.progress(100)
            progress_bar.empty()
            # ChatGPT ìŠ¤íƒ€ì¼ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥
            placeholder = st.empty()
            display_text = ""
            for char in answer:
                display_text += char
                placeholder.markdown(display_text)
                time.sleep(0.01)
            st.session_state.chat_history.append({'user': user_input, 'bot': answer, 'search': db_results, 'sql': sql})

# --- ëŒ€í™” ê¸°ë¡ í‘œì‹œ (ìµœì‹  ëŒ€í™”ê°€ ì•„ë˜ìª½ì— ì˜¤ë„ë¡, ChatGPT ìŠ¤íƒ€ì¼) ---
for chat in st.session_state.chat_history:
    with st.chat_message('user'):
        st.markdown(chat['user'])
    with st.chat_message('assistant'):
        st.markdown(chat['bot'])
        if chat.get('sql'):
            st.caption(f"[LLMì´ ìƒì„±í•œ SQL]: {chat['sql']}")
        if chat['search']:
            with st.expander('ğŸ” DB ê²€ìƒ‰ ê²°ê³¼ í¼ì¹˜ê¸°'):
                df = pd.DataFrame(chat['search'])
                st.dataframe(df)

if not tables:
    st.warning('DBì— í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤. DBë¥¼ ë¨¼ì € ìƒì„±í•´ ì£¼ì„¸ìš”.')
else:
    st.info('DBì—ì„œ ì›í•˜ëŠ” í…Œì´ë¸”/ì»¬ëŸ¼ì„ ì„ íƒí•˜ì§€ ì•Šìœ¼ë©´, ê¸°ë³¸ì ìœ¼ë¡œ ì „ì²´ í…Œì´ë¸”/ì „ì²´ ì»¬ëŸ¼ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤. ì±—ë´‡ì— ìì—°ì–´ë¡œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´, DB ê²€ìƒ‰ ê²°ê³¼ì™€ LLMì„ í™œìš©í•´ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤. (RAG ë°©ì‹)') 