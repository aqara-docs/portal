import streamlit as st
import os
import mysql.connector
from dotenv import load_dotenv
from openai import OpenAI
import anthropic
from langchain_openai import OpenAI as LangOpenAI
from langchain_anthropic import ChatAnthropic
import pandas as pd
import time
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import json
from datetime import datetime

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="MySQL DB RAG ê²€ìƒ‰ ì±—ë´‡", layout="wide")

st.title("ğŸ” MySQL DB RAG ê²€ìƒ‰ ì±—ë´‡ ğŸ”")

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
@st.cache_resource
def get_embedding_model():
    return SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')

# í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
def get_text_embedding(text, model):
    if not text or pd.isna(text):
        return np.zeros(384)  # ëª¨ë¸ì˜ ì„ë² ë”© ì°¨ì›
    return model.encode(str(text))

# í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚°
def calculate_similarity(query_embedding, text_embedding):
    return cosine_similarity([query_embedding], [text_embedding])[0][0]

# DB ì—°ê²° í•¨ìˆ˜ (00_ğŸ’¾_01_DBìƒì„±.py ì°¸ê³ )
def connect_to_db():
    return mysql.connector.connect(
        user=os.getenv('SQL_USER'),
        password=os.getenv('SQL_PASSWORD'),
        host=os.getenv('SQL_HOST'),
        database=os.getenv('SQL_DATABASE_NEWBIZ'),
        charset='utf8mb4',
        collation='utf8mb4_unicode_ci'
    )

def get_table_names():
    conn = connect_to_db()
    cursor = conn.cursor()
    cursor.execute("SHOW TABLES")
    tables = [row[0] for row in cursor.fetchall()]
    cursor.close()
    conn.close()
    return tables

def get_table_columns(table):
    """í…Œì´ë¸”ì˜ ì»¬ëŸ¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
    conn = connect_to_db()
    cursor = conn.cursor()
    try:
        cursor.execute(f"DESCRIBE {table}")
        columns = [row[0] for row in cursor.fetchall()]
        return columns
    except Exception as e:
        print(f"Error getting columns for table {table}: {str(e)}")
        return []
    finally:
        cursor.close()
        conn.close()

# --- ê²€ìƒ‰ ëª¨ë“œë³„ ë©€í‹°ì»¬ëŸ¼ ê²€ìƒ‰ í•¨ìˆ˜ ---
def search_table_multicolumn_mode(table, query, mode="OR", limit=10):
    conn = connect_to_db()
    cursor = conn.cursor(dictionary=True)
    columns = get_table_columns(table)
    keywords = [w for w in query.split() if w]
    if not keywords:
        keywords = [query]
    where_clauses = []
    params = []
    if mode == "OR":
        for col in columns:
            for kw in keywords:
                where_clauses.append(f"`{col}` LIKE %s")
                params.append(f"%{kw}%")
        where_sql = " OR ".join(where_clauses)
    elif mode == "AND":
        for kw in keywords:
            sub = []
            for col in columns:
                sub.append(f"`{col}` LIKE %s")
                params.append(f"%{kw}%")
            where_clauses.append("(" + " OR ".join(sub) + ")")
        where_sql = " AND ".join(where_clauses)
    elif mode == "EXACT":
        for col in columns:
            where_clauses.append(f"`{col}` = %s")
            params.append(query)
        where_sql = " OR ".join(where_clauses)
    else:
        where_sql = "1=0"
    sql = f"SELECT * FROM `{table}` WHERE {where_sql} LIMIT %s"
    params.append(limit)
    cursor.execute(sql, params)
    results = cursor.fetchall()
    cursor.close()
    conn.close()
    return results

def search_all_tables_multicolumn_mode(query, mode="OR", limit=5):
    results = []
    tables = get_table_names()
    for t in tables:
        try:
            partial = search_table_multicolumn_mode(t, query, mode, limit)
            if partial:
                for row in partial:
                    results.append({'table': t, **row})
        except Exception as e:
            continue
    return results

def get_table_schema_definitions():
    """í…Œì´ë¸”ë³„ ìŠ¤í‚¤ë§ˆ ì •ì˜ ë° ì¹¼ëŸ¼ íŠ¹ì„± ì •ì˜"""
    return {
        'meeting_records': {
            'weight': 1.0,
            'columns': {
                'title': {
                    'type': 'text',
                    'importance': 1.0,
                    'search_weight': 1.0,
                    'description': 'íšŒì˜ ì œëª©',
                    'preprocessing': lambda x: x.strip() if x else x
                },
                'summary': {
                    'type': 'text',
                    'importance': 0.9,
                    'search_weight': 0.9,
                    'description': 'íšŒì˜ ìš”ì•½',
                    'preprocessing': lambda x: x.strip() if x else x
                },
                'content': {
                    'type': 'long_text',
                    'importance': 0.8,
                    'search_weight': 0.7,
                    'description': 'íšŒì˜ ìƒì„¸ ë‚´ìš©',
                    'preprocessing': lambda x: x.strip() if x else x
                },
                'decisions': {
                    'type': 'text',
                    'importance': 0.9,
                    'search_weight': 0.9,
                    'description': 'ì˜ì‚¬ê²°ì • ì‚¬í•­',
                    'preprocessing': lambda x: x.strip() if x else x
                },
                'action_items': {
                    'type': 'text',
                    'importance': 0.9,
                    'search_weight': 0.8,
                    'description': 'ì•¡ì…˜ ì•„ì´í…œ',
                    'preprocessing': lambda x: x.strip() if x else x
                },
                'participants': {
                    'type': 'text',
                    'importance': 0.7,
                    'search_weight': 0.6,
                    'description': 'ì°¸ì„ì',
                    'preprocessing': lambda x: x.strip() if x else x
                },
                'meeting_date': {
                    'type': 'date',
                    'importance': 0.8,
                    'search_weight': 0.0,
                    'description': 'íšŒì˜ ë‚ ì§œ',
                    'preprocessing': None
                }
            }
        },
        'analyses': {
            'weight': 0.9,
            'columns': {
                'title': {
                    'type': 'text',
                    'importance': 1.0,
                    'search_weight': 1.0,
                    'description': 'ë¶„ì„ ì œëª©',
                    'preprocessing': lambda x: x.strip() if x else x
                },
                'content': {
                    'type': 'long_text',
                    'importance': 0.9,
                    'search_weight': 0.8,
                    'description': 'ë¶„ì„ ë‚´ìš©',
                    'preprocessing': lambda x: x.strip() if x else x
                },
                'summary': {
                    'type': 'text',
                    'importance': 0.9,
                    'search_weight': 0.9,
                    'description': 'ë¶„ì„ ìš”ì•½',
                    'preprocessing': lambda x: x.strip() if x else x
                },
                'conclusions': {
                    'type': 'text',
                    'importance': 0.9,
                    'search_weight': 0.9,
                    'description': 'ë¶„ì„ ê²°ë¡ ',
                    'preprocessing': lambda x: x.strip() if x else x
                },
                'created_at': {
                    'type': 'date',
                    'importance': 0.7,
                    'search_weight': 0.0,
                    'description': 'ì‘ì„±ì¼',
                    'preprocessing': None
                }
            }
        },
        'book_discussions': {
            'weight': 0.8,
            'columns': {
                'title': {
                    'type': 'text',
                    'importance': 1.0,
                    'search_weight': 1.0,
                    'description': 'ë„ì„œ/í† ë¡  ì œëª©',
                    'preprocessing': lambda x: x.strip() if x else x
                },
                'content': {
                    'type': 'long_text',
                    'importance': 0.9,
                    'search_weight': 0.8,
                    'description': 'í† ë¡  ë‚´ìš©',
                    'preprocessing': lambda x: x.strip() if x else x
                },
                'summary': {
                    'type': 'text',
                    'importance': 0.9,
                    'search_weight': 0.9,
                    'description': 'í† ë¡  ìš”ì•½',
                    'preprocessing': lambda x: x.strip() if x else x
                },
                'key_insights': {
                    'type': 'text',
                    'importance': 0.9,
                    'search_weight': 0.9,
                    'description': 'ì£¼ìš” ì¸ì‚¬ì´íŠ¸',
                    'preprocessing': lambda x: x.strip() if x else x
                },
                'discussion_date': {
                    'type': 'date',
                    'importance': 0.7,
                    'search_weight': 0.0,
                    'description': 'í† ë¡ ì¼',
                    'preprocessing': None
                }
            }
        },
        'action_items': {
            'weight': 0.9,
            'columns': {
                'title': {
                    'type': 'text',
                    'importance': 1.0,
                    'search_weight': 1.0,
                    'description': 'ì•¡ì…˜ ì•„ì´í…œ ì œëª©',
                    'preprocessing': lambda x: x.strip() if x else x
                },
                'description': {
                    'type': 'text',
                    'importance': 0.9,
                    'search_weight': 0.9,
                    'description': 'ìƒì„¸ ì„¤ëª…',
                    'preprocessing': lambda x: x.strip() if x else x
                },
                'status': {
                    'type': 'category',
                    'importance': 0.8,
                    'search_weight': 0.7,
                    'description': 'ì§„í–‰ ìƒíƒœ',
                    'preprocessing': lambda x: x.lower() if x else x
                },
                'assignee': {
                    'type': 'text',
                    'importance': 0.8,
                    'search_weight': 0.7,
                    'description': 'ë‹´ë‹¹ì',
                    'preprocessing': lambda x: x.strip() if x else x
                },
                'due_date': {
                    'type': 'date',
                    'importance': 0.8,
                    'search_weight': 0.0,
                    'description': 'ë§ˆê°ì¼',
                    'preprocessing': None
                }
            }
        }
    }

def get_column_definition(table, column):
    """í…Œì´ë¸”ì˜ íŠ¹ì • ì¹¼ëŸ¼ ì •ì˜ ê°€ì ¸ì˜¤ê¸°"""
    schema_defs = get_table_schema_definitions()
    table_def = schema_defs.get(table, {'columns': {}})
    return table_def['columns'].get(column, {
        'type': 'unknown',
        'importance': 0.5,
        'search_weight': 0.5,
        'description': 'ì•Œ ìˆ˜ ì—†ëŠ” ì¹¼ëŸ¼',
        'preprocessing': lambda x: str(x) if x is not None else None
    })

def preprocess_value(table, column, value):
    """ì¹¼ëŸ¼ íŠ¹ì„±ì— ë”°ë¥¸ ê°’ ì „ì²˜ë¦¬"""
    if value is None:
        return None
        
    col_def = get_column_definition(table, column)
    if col_def['preprocessing']:
        return col_def['preprocessing'](value)
    return value

def search_table_hybrid_mode(table, query, embedding_model, mode="OR", limit=None, semantic_weight=0.5):
    """í‚¤ì›Œë“œ ê²€ìƒ‰ê³¼ ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ì„ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰"""
    conn = connect_to_db()
    cursor = conn.cursor(dictionary=True)
    
    try:
        # 1. í…Œì´ë¸” êµ¬ì¡° íŒŒì•…
        cursor.execute(f"DESCRIBE {table}")
        columns = [row['Field'] for row in cursor.fetchall()]
        
        # 2. ê²€ìƒ‰í•  ì»¬ëŸ¼ ê²°ì • ë° ê°€ì¤‘ì¹˜ ê³„ì‚°
        column_weights = {}
        for col in columns:
            col_def = get_column_definition(table, col)
            if col_def['type'] in ['text', 'long_text', 'category']:
                column_weights[col] = col_def['search_weight']
        
        if not column_weights:
            return []
        
        # 3. ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±
        where_clauses = []
        params = []
        
        for col, weight in column_weights.items():
            if mode == "OR":
                where_clauses.extend([f"({col} LIKE %s)" for _ in query.split()])
                params.extend([f"%{kw}%" for kw in query.split()])
            elif mode == "AND":
                where_clauses.append("(" + " OR ".join([f"{col} LIKE %s" for _ in query.split()]) + ")")
                params.extend([f"%{kw}%" for kw in query.split()])
            else:  # EXACT
                where_clauses.append(f"({col} LIKE %s)")
                params.append(f"%{query}%")
        
        # 4. ë‚ ì§œ ì •ë ¬ì„ ìœ„í•œ ì»¬ëŸ¼ ì°¾ê¸°
        date_columns = []
        for col in columns:
            col_def = get_column_definition(table, col)
            if col_def['type'] == 'date':
                date_columns.append(col)
        
        order_by = f"ORDER BY {date_columns[0] if date_columns else '1'} DESC"
        
        # 5. SQL ì‹¤í–‰ - ëª¨ë“  ê²°ê³¼ë¥¼ ê°€ì ¸ì˜´
        sql = f"""
        SELECT * 
        FROM {table}
        WHERE {" OR ".join(where_clauses) if mode == "OR" else " AND ".join(where_clauses)}
        {order_by}
        """
        
        cursor.execute(sql, params)
        results = cursor.fetchall()
        
        # 6. ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ ë° ê²°ê³¼ ìŠ¤ì½”ì–´ë§
        if results:
            query_embedding = get_text_embedding(query, embedding_model)
            scored_results = []
            
            for row in results:
                # ê° ì¹¼ëŸ¼ì˜ íŠ¹ì„±ì„ ê³ ë ¤í•œ í…ìŠ¤íŠ¸ ê²°í•©
                text_parts = []
                for col, value in row.items():
                    col_def = get_column_definition(table, col)
                    if col_def['type'] in ['text', 'long_text']:
                        processed_value = preprocess_value(table, col, value)
                        if processed_value:
                            text_parts.append(processed_value)
                
                text_content = " ".join(text_parts)
                
                if text_content.strip():
                    # ì˜ë¯¸ë¡ ì  ìœ ì‚¬ë„ ê³„ì‚°
                    text_embedding = get_text_embedding(text_content, embedding_model)
                    semantic_score = calculate_similarity(query_embedding, text_embedding)
                    
                    # í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚° (ì¹¼ëŸ¼ ê°€ì¤‘ì¹˜ ì ìš©)
                    keyword_score = 0
                    for col, value in row.items():
                        if value and col in column_weights:
                            processed_value = preprocess_value(table, col, value)
                            if processed_value and any(kw.lower() in processed_value.lower() for kw in query.split()):
                                keyword_score += column_weights[col]
                    
                    # ìµœì¢… ì ìˆ˜ ê³„ì‚°
                    schema_defs = get_table_schema_definitions()
                    table_weight = schema_defs.get(table, {'weight': 0.7})['weight']
                    
                    final_score = table_weight * (
                        semantic_weight * semantic_score + 
                        (1 - semantic_weight) * keyword_score
                    )
                    
                    scored_results.append((final_score, row))
            
            # ì ìˆ˜ì— ë”°ë¼ ì •ë ¬
            scored_results.sort(reverse=True, key=lambda x: x[0])
            
            # ê° ê²°ê³¼ì— ì ìˆ˜ í¬í•¨
            results = []
            for score, row in scored_results:
                results.append({**row, '_score': score})
            
            return results
        
        return []
        
    except Exception as e:
        print(f"Error searching table {table}: {str(e)}")
        return []
    finally:
        cursor.close()
        conn.close()

def search_all_tables_hybrid_mode(query, embedding_model, mode="OR", limit=None, semantic_weight=0.5):
    """ëª¨ë“  í…Œì´ë¸”ì— ëŒ€í•´ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìˆ˜í–‰"""
    all_results = []
    tables = get_table_names()
    table_importance = get_table_schema_definitions()
    
    # ê° í…Œì´ë¸” ê²€ìƒ‰ (limit ì œí•œ ì—†ì´)
    for table in tables:
        try:
            results = search_table_hybrid_mode(table, query, embedding_model, mode, None, semantic_weight)
            if results:
                # í…Œì´ë¸” ë©”íƒ€ë°ì´í„° ì¶”ê°€
                for row in results:
                    score = row.pop('_score', 0)  # ì ìˆ˜ë¥¼ ì„ì‹œë¡œ ì œê±°
                    all_results.append({
                        'table': table,
                        'importance': table_importance.get(table, {'weight': 0.7})['weight'],
                        '_score': score,  # ì ìˆ˜ ì €ì¥
                        **row
                    })
        except Exception as e:
            continue
    
    # ì „ì²´ ê²°ê³¼ë¥¼ ì ìˆ˜ì— ë”°ë¼ ì •ë ¬
    all_results.sort(key=lambda x: x['_score'], reverse=True)
    
    # ì ìˆ˜ í•„ë“œ ì œê±°
    for row in all_results:
        row.pop('_score', None)
    
    # limit ì ìš©
    return all_results[:limit] if limit else all_results

class ConversationManager:
    def __init__(self):
        self.initialize_session_state()
    
    def initialize_session_state(self):
        """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
        if 'conversation_history' not in st.session_state:
            st.session_state.conversation_history = []
        if 'last_search_results' not in st.session_state:
            st.session_state.last_search_results = None
        if 'context_summary' not in st.session_state:
            st.session_state.context_summary = ""
    
    def add_to_history(self, role, content, search_results=None):
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ìƒˆ ë©”ì‹œì§€ ì¶”ê°€"""
        timestamp = datetime.now().isoformat()
        entry = {
            'timestamp': timestamp,
            'role': role,
            'content': content,
            'search_results': search_results if search_results else None
        }
        st.session_state.conversation_history.append(entry)
        
        # ë§ˆì§€ë§‰ ê²€ìƒ‰ ê²°ê³¼ ì—…ë°ì´íŠ¸
        if search_results:
            st.session_state.last_search_results = search_results
    
    def get_recent_context(self, num_messages=5):
        """ìµœê·¼ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
        history = st.session_state.conversation_history[-num_messages:] if st.session_state.conversation_history else []
        context = []
        
        for entry in history:
            context.append(f"{entry['role']}: {entry['content']}")
            if entry['search_results']:
                context.append(f"[ê²€ìƒ‰ ê²°ê³¼: {len(entry['search_results'])}ê±´]")
        
        return "\n".join(context)
    
    def get_last_search_results(self):
        """ë§ˆì§€ë§‰ ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°"""
        return st.session_state.last_search_results
    
    def update_context_summary(self, summary):
        """ì»¨í…ìŠ¤íŠ¸ ìš”ì•½ ì—…ë°ì´íŠ¸"""
        st.session_state.context_summary = summary
    
    def get_context_summary(self):
        """í˜„ì¬ ì»¨í…ìŠ¤íŠ¸ ìš”ì•½ ê°€ì ¸ì˜¤ê¸°"""
        return st.session_state.context_summary

def generate_llm_answer_rag(user_query, db_results, model_name, sql, conversation_manager=None):
    max_results_per_table = 3  # í…Œì´ë¸”ë‹¹ ìµœëŒ€ ê²°ê³¼ ìˆ˜
    max_val_len = 100  # ê° í•„ë“œ ê°’ì˜ ìµœëŒ€ ê¸¸ì´
    max_recent_messages = 3  # ìµœê·¼ ëŒ€í™” íˆìŠ¤í† ë¦¬ ìˆ˜
    
    # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    if not db_results:
        context = f"[DB ê²€ìƒ‰ ê²°ê³¼: '{user_query}'ë¡œ ì „ì²´ í…Œì´ë¸”/ì»¬ëŸ¼ì—ì„œ ê²€ìƒ‰í–ˆìœ¼ë‚˜ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.]"
    else:
        context = f"[DB ê²€ìƒ‰ ê²°ê³¼: '{user_query}'ë¡œ ê²€ìƒ‰í•œ ê²°ê³¼ {len(db_results)}ê±´]\n\n"
        
        # í…Œì´ë¸”ë³„ ê²°ê³¼ ê·¸ë£¹í™”
        table_results = {}
        for row in db_results:
            table = row.get('table', 'unknown')
            if table not in table_results:
                table_results[table] = []
            if len(table_results[table]) < max_results_per_table:  # í…Œì´ë¸”ë‹¹ ìµœëŒ€ ê²°ê³¼ ìˆ˜ ì œí•œ
                table_results[table].append(row)
        
        # ê° í…Œì´ë¸”ì˜ ê²°ê³¼ë¥¼ ì²˜ë¦¬
        for table, rows in table_results.items():
            context += f"[í…Œì´ë¸”: {table}]\n"
            
            for row in rows:
                # ë‚ ì§œ ì •ë³´ ì°¾ê¸°
                date_value = None
                for key, value in row.items():
                    if any(date_type in key.lower() for date_type in ['date', 'time', 'created', 'updated']):
                        date_value = value
                        break
                
                if date_value:
                    context += f"ë‚ ì§œ: {date_value}\n"
                
                # ì£¼ìš” í•„ë“œ í‘œì‹œ (ì¤‘ìš”ë„ ìˆœ)
                important_fields = [
                    'title', 'summary', 'content', 'description', 'decisions', 
                    'action_items', 'conclusions', 'key_insights'
                ]
                
                field_count = 0  # í‘œì‹œëœ í•„ë“œ ìˆ˜ ì¶”ì 
                for field in important_fields:
                    if field in row and row[field] and not pd.isna(row[field]):
                        value = str(row[field])[:max_val_len]
                        if len(value) == max_val_len:
                            value += "..."
                        context += f"{field}: {value}\n"
                        field_count += 1
                        if field_count >= 5:  # ìµœëŒ€ 5ê°œ í•„ë“œë§Œ í‘œì‹œ
                            break
                
                context += "\n"
    
    # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€ (ìµœê·¼ 3ê°œ ë©”ì‹œì§€ë§Œ)
    conversation_context = ""
    if conversation_manager:
        recent_context = conversation_manager.get_recent_context(max_recent_messages)
        context_summary = conversation_manager.get_context_summary()
        if context_summary:
            conversation_context = f"\n[ì´ì „ ëŒ€í™” ìš”ì•½]\n{context_summary}\n"
        if recent_context:
            conversation_context += f"\n[ìµœê·¼ ëŒ€í™” ë‚´ìš©]\n{recent_context}\n"
    
    prompt = f"""
ì•„ë˜ëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ì•„ì¹´ë¼ë¼ì´í”„ì˜ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ '{user_query}'ë¡œ ê²€ìƒ‰í•œ ê²°ê³¼ì…ë‹ˆë‹¤.
{conversation_context}

[ì¤‘ìš” ì§€ì¹¨]
1. DBì˜ ëª¨ë“  ê´€ë ¨ ì •ë³´ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
2. ì´ì „ ëŒ€í™” ë‚´ìš©ê³¼ ì—°ê²°í•˜ì—¬ ë§¥ë½ì„ ìœ ì§€í•˜ì„¸ìš”.
3. íšŒì˜ë¡, ë¶„ì„ ìë£Œ, í† ë¡  ë‚´ìš© ë“±ì„ ì‹œê°„ ìˆœì„œëŒ€ë¡œ ì—°ê²°í•˜ì—¬ ë§¥ë½ì„ ì œê³µí•˜ì„¸ìš”.
4. ì˜ì‚¬ê²°ì • ì‚¬í•­ê³¼ ì•¡ì…˜ ì•„ì´í…œì€ ë‚ ì§œì™€ í•¨ê»˜ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œí•˜ì„¸ìš”.
5. ì—¬ëŸ¬ ìë£Œì˜ ì—°ê´€ì„±ì„ íŒŒì•…í•˜ì—¬ ì¢…í•©ì ì¸ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•˜ì„¸ìš”.
6. DBì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ê³ , ì •ë³´ê°€ ë¶€ì¡±í•œ ë¶€ë¶„ì„ ëª…í™•íˆ í‘œì‹œí•˜ì„¸ìš”.

[ì‚¬ìš©ì ì§ˆë¬¸]
{user_query}

[DB ê²€ìƒ‰ ê²°ê³¼]
{context}

[ë‹µë³€ í˜•ì‹]
1. ì¢…í•© ìš”ì•½:
   - ê²€ìƒ‰ëœ ì •ë³´ì˜ ì „ì²´ì ì¸ ë§¥ë½ê³¼ ì˜ë¯¸
   - ì‹œê°„ìˆœ íë¦„ì— ë”°ë¥¸ ë³€í™”/ë°œì „ ì‚¬í•­
   - ì´ì „ ëŒ€í™”ì™€ì˜ ì—°ê´€ì„±

2. ì£¼ìš” ë‚´ìš© ë¶„ì„:
   - íšŒì˜/ë¬¸ì„œë³„ í•µì‹¬ í¬ì¸íŠ¸
   - ì˜ì‚¬ê²°ì • ì‚¬í•­ ë° ë°°ê²½
   - ì£¼ìš” ë…¼ì˜ ì‚¬í•­ê³¼ ê²°ë¡ 

3. ì‹¤í–‰ í˜„í™©:
   - ì•¡ì…˜ ì•„ì´í…œ ë° ì§„í–‰ ìƒíƒœ
   - í›„ì† ì¡°ì¹˜ ì‚¬í•­
   - ë‹´ë‹¹ì/ì±…ì„ì ì •ë³´

4. ì—°ê´€ ì •ë³´:
   - ê´€ë ¨ íšŒì˜/ë¬¸ì„œ ê°„ ì—°ê²°ì 
   - ë³´ì™„ì  ì •ë³´ë“¤ì˜ í†µí•©ì  ì˜ë¯¸
   - ì´ì „ ëŒ€í™”ì—ì„œ ì–¸ê¸‰ëœ ê´€ë ¨ ë‚´ìš©

5. ê²°ë¡  ë° ì œì–¸:
   - ì¢…í•©ì  ì¸ì‚¬ì´íŠ¸
   - ë¶€ì¡±í•œ ì •ë³´ ì˜ì—­
   - í–¥í›„ í•„ìš”í•œ ì•¡ì…˜ ì œì•ˆ

[ë‹µë³€]
"""
    
    if st.session_state.selected_ai_api == 'Anthropic (Claude)':
        client = ChatAnthropic(model=model_name, api_key=os.getenv('ANTHROPIC_API_KEY'), temperature=0.3, max_tokens=1500)
        response = client.invoke([
            {"role": "user", "content": prompt}
        ])
        answer = response.content if hasattr(response, 'content') else str(response)
    else:  # OpenAI (GPT)
        client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        response = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "user", "content": prompt}],
            max_tokens=1500,
            temperature=0.3
        )
        answer = response.choices[0].message.content
    
    # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
    if conversation_manager:
        conversation_manager.add_to_history('assistant', answer, db_results)
    
    return answer

def summarize_db_reference(search_results, max_tables=3, max_rows_per_table=1, max_cols=3):
    from collections import defaultdict
    table_rows = defaultdict(list)
    for row in search_results:
        t = row.get('table', 'unknown')
        table_rows[t].append(row)
    ref_lines = []
    for i, (t, rows) in enumerate(table_rows.items()):
        if i >= max_tables:
            ref_lines.append(f"... (ì´í•˜ {len(table_rows)-max_tables}ê°œ í…Œì´ë¸” ìƒëµ)")
            break
        ref_lines.append(f"- í…Œì´ë¸”: {t}")
        if rows:
            # ëŒ€í‘œ row 1ê°œ, ì£¼ìš” ì»¬ëŸ¼ 3ê°œë§Œ í‘œì‹œ
            row = rows[0]
            cols = [k for k in row.keys() if k != 'table'][:max_cols]
            col_str = ", ".join([f"{k}={row[k]}" for k in cols])
            ref_lines.append(f"  - ì˜ˆì‹œ ë°ì´í„°: {col_str}")
    return "\n".join(ref_lines)

def main():
    # ì¸ì¦ ê¸°ëŠ¥ (ê°„ë‹¨í•œ ë¹„ë°€ë²ˆí˜¸ ë³´í˜¸)
    if 'authenticated' not in st.session_state:
        st.session_state.authenticated = False
    if not st.session_state.authenticated:
        password = st.text_input("ê´€ë¦¬ì ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password")
        if password == os.getenv('ADMIN_PASSWORD', 'mds0118!'):
            st.session_state.authenticated = True
            st.rerun()
        else:
            if password:
                st.error("ê´€ë¦¬ì ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤")
            st.stop()
    
    # ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.title("MySQL DB RAG ê²€ìƒ‰ ì±—ë´‡")
        
        # AI API/ëª¨ë¸ ì„ íƒ
        has_anthropic_key = os.environ.get('ANTHROPIC_API_KEY') is not None
        has_openai_key = os.environ.get('OPENAI_API_KEY') is not None
        available_models = []
        if has_anthropic_key:
            available_models.extend([
                'claude-3-7-sonnet-latest',
                'claude-3-5-sonnet-latest',
                'claude-3-5-haiku-latest',
            ])
        if has_openai_key:
            available_models.extend(['gpt-4o', 'gpt-4o-mini'])
        if not available_models:
            available_models = ['claude-3-7-sonnet-latest']

        col_api, col_model = st.columns([1,2])
        with col_api:
            selected_ai_api = st.selectbox(
                'AI API ì„ íƒ',
                options=['Anthropic (Claude)', 'OpenAI (GPT)'],
                index=0 if st.session_state.get('selected_ai_api', 'Anthropic (Claude)') == 'Anthropic (Claude)' else 1,
                key='api_selector'
            )
            st.session_state.selected_ai_api = selected_ai_api
        with col_model:
            filtered_models = [m for m in available_models if (('claude' in m and selected_ai_api=='Anthropic (Claude)') or ('gpt' in m and selected_ai_api=='OpenAI (GPT)'))]
            if not filtered_models:
                filtered_models = ['claude-3-7-sonnet-latest']
            selected_model = st.selectbox(
                'AI ëª¨ë¸ ì„ íƒ',
                options=filtered_models,
                index=filtered_models.index(st.session_state.get('selected_model', filtered_models[0])) if st.session_state.get('selected_model') in filtered_models else 0,
                key='model_selector'
            )
            st.session_state.selected_model = selected_model
        
        # ê²€ìƒ‰ ëª¨ë“œ ì„ íƒ
        st.subheader("ê²€ìƒ‰ ë°©ì‹ ì„ íƒ")
        search_mode = st.radio(
            "",
            ["OR", "AND", "EXACT"],
            help="OR: í‚¤ì›Œë“œ ì¤‘ í•˜ë‚˜ë¼ë„ í¬í•¨\nAND: ëª¨ë“  í‚¤ì›Œë“œ í¬í•¨\nEXACT: ì •í™•í•œ ë¬¸êµ¬ ë§¤ì¹­"
        )
        
        # ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ ì„¤ì •
        search_limit = st.slider(
            "ê²€ìƒ‰ ê²°ê³¼ ìˆ˜",
            min_value=5,
            max_value=100,
            value=20,
            step=5,
            help="í•œ ë²ˆì— í‘œì‹œí•  ê²€ìƒ‰ ê²°ê³¼ì˜ ìµœëŒ€ ê°œìˆ˜"
        )
        
        # ìƒì„¸ ê²°ê³¼ í‘œì‹œ ì—¬ë¶€
        show_details = st.checkbox("ê²€ìƒ‰ ê²°ê³¼ ìƒì„¸ í‘œì‹œ", value=False)
        
        # í…Œì´ë¸” ì„ íƒ
        st.subheader("ê²€ìƒ‰ ëŒ€ìƒ í…Œì´ë¸”")
        tables = get_table_names()
        selected_tables = st.multiselect(
            "í…Œì´ë¸” ì„ íƒ (ë¯¸ì„ íƒì‹œ ì „ì²´ ê²€ìƒ‰)",
            tables
        )
        
        if selected_tables:
            st.subheader("ê²€ìƒ‰ ëŒ€ìƒ ì»¬ëŸ¼")
            for table in selected_tables:
                st.write(f"**{table}**")
                columns = get_table_columns(table)
                selected_columns = st.multiselect(
                    f"{table} ì»¬ëŸ¼ ì„ íƒ (ë¯¸ì„ íƒì‹œ ì „ì²´ ê²€ìƒ‰)",
                    columns,
                    key=f"cols_{table}"
                )
    
    # ë©”ì¸ ì˜ì—­
    # ì´ˆê¸° ì•ˆë‚´ ë©”ì‹œì§€
    st.info('DBì—ì„œ ì›í•˜ëŠ” í…Œì´ë¸”/ì»¬ëŸ¼ì„ ì„ íƒí•˜ì§€ ì•Šìœ¼ë©´, ê¸°ë³¸ì ìœ¼ë¡œ ì „ì²´ í…Œì´ë¸”/ì „ì²´ ì»¬ëŸ¼ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤. ì±—ë´‡ì— ìì—°ì–´ë¡œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´, DB ê²€ìƒ‰ ê²°ê³¼ì™€ LLMì„ í™œìš©í•´ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤. (RAG ë°©ì‹)')
    
    # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
    embedding_model = get_embedding_model()
    
    # ëŒ€í™” ê¸°ë¡ í‘œì‹œ (ìµœì‹  ëŒ€í™”ê°€ ì•„ë˜ìª½ì— ì˜¤ë„ë¡)
    for chat in st.session_state.chat_history:
        with st.chat_message('user'):
            st.markdown(chat['user'])
        with st.chat_message('assistant'):
            st.markdown(chat['bot'])
            if chat.get('sql'):
                st.caption(f"[ê²€ìƒ‰ ë°©ì‹]: {chat['sql']}")
            if chat.get('search'):
                with st.expander('ğŸ” DB ê²€ìƒ‰ ê²°ê³¼ í¼ì¹˜ê¸°'):
                    df = pd.DataFrame(chat['search'])
                    if len(df) > 0:
                        # í…Œì´ë¸”ë³„ë¡œ ê²°ê³¼ ê·¸ë£¹í™”
                        grouped = df.groupby('table')
                        for table_name, group in grouped:
                            st.write(f"**{table_name}** ({len(group)}ê±´)")
                            display_df = group.copy()
                            if 'table' in display_df.columns:
                                display_df = display_df.drop('table', axis=1)
                            st.dataframe(
                                display_df,
                                hide_index=True,
                                use_container_width=True
                            )
    
    # ì‚¬ìš©ì ì…ë ¥ ì˜ì—­
    with st.container():
        user_query = st.text_area(
            "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”",
            height=100,
            help="ì˜ˆì‹œ ì§ˆë¬¸:\n- ìµœê·¼ íšŒì˜ì—ì„œ ë…¼ì˜ëœ ì£¼ìš” ì˜ì‚¬ê²°ì • ì‚¬í•­ì€?\n- íŠ¹ì • í”„ë¡œì íŠ¸ì˜ ì§„í–‰ ìƒí™©ì„ ì•Œë ¤ì£¼ì„¸ìš”\n- ì´ë²ˆ ë‹¬ ì£¼ìš” ì•¡ì…˜ ì•„ì´í…œì€?"
        )
        
        # ì‹¤í–‰ ë²„íŠ¼ì„ ì¤‘ì•™ì— ë°°ì¹˜
        col1, col2, col3 = st.columns([1,1,1])
        with col2:
            submit_button = st.button(
                "ğŸ” ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„±",
                type="primary",
                use_container_width=True
            )
    
    if submit_button and user_query:
        # ConversationManager ì´ˆê¸°í™”
        conversation_manager = ConversationManager()
        
        # ì´ì „ ëŒ€í™” ê¸°ë¡ ë¡œë“œ
        for chat in st.session_state.chat_history:
            conversation_manager.add_to_history('user', chat['user'])
            conversation_manager.add_to_history('assistant', chat['bot'])
        
        # í˜„ì¬ ì‚¬ìš©ì ì…ë ¥ì„ ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        conversation_manager.add_to_history('user', user_query)
        
        # ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„±
        with st.spinner('ê²€ìƒ‰ ì¤‘...'):
            results = search_all_tables_hybrid_mode(
                query=user_query,
                embedding_model=embedding_model,
                mode=search_mode,
                limit=search_limit
            )
            
            if results:
                # ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
                df = pd.DataFrame(results)
                # í…Œì´ë¸”ë³„ ê²°ê³¼ ìˆ˜ í‘œì‹œ
                table_counts = df['table'].value_counts()
                st.write("ğŸ” **ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½**")
                for table, count in table_counts.items():
                    st.write(f"- {table}: {count}ê±´")
                
                # í…Œì´ë¸”ë³„ë¡œ ê²°ê³¼ í‘œì‹œ
                grouped = df.groupby('table')
                for table_name, group in grouped:
                    with st.expander(f"í…Œì´ë¸”: {table_name} ({len(group)}ê±´)"):
                        display_df = group.copy()
                        if 'table' in display_df.columns:
                            display_df = display_df.drop('table', axis=1)
                        st.dataframe(
                            display_df,
                            hide_index=True,
                            use_container_width=True
                        )
            else:
                st.warning('ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.')
        
        with st.spinner('ë‹µë³€ ìƒì„± ì¤‘...'):
            answer = generate_llm_answer_rag(
                user_query,
                results,
                st.session_state.selected_model,
                f"[{search_mode} ê²€ìƒ‰]",
                conversation_manager
            )
            
            # ìƒˆë¡œìš´ ëŒ€í™”ë¥¼ ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€
            st.session_state.chat_history.append({
                'user': user_query,
                'bot': answer,
                'search': results,
                'sql': f"[{search_mode} ê²€ìƒ‰]"
            })
            
            # í™”ë©´ ìƒˆë¡œê³ ì¹¨
            st.rerun()

if __name__ == "__main__":
    main() 