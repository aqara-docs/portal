import streamlit as st
import pandas as pd
import mysql.connector
import os
from dotenv import load_dotenv
from openai import OpenAI
import json
import time
import requests
import re
from datetime import datetime
import hashlib
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import pickle
import io
import openai
from numpy.linalg import norm

# pandas ê²½ê³  ì„¤ì •
pd.set_option('future.no_silent_downcasting', True)
pd.set_option('mode.chained_assignment', None)

load_dotenv()

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸ¤– ì•„ì¹´ë¼ë¼ì´í”„ ì‚¬ë‚´ ì±—ë´‡",
    page_icon="ğŸ¤–",
    layout="wide"
)

# ===== LLM í´ë¼ì´ì–¸íŠ¸ ê´€ë¦¬ =====

class LLMClient:
    """ë‹¤ì–‘í•œ LLM í´ë¼ì´ì–¸íŠ¸ë¥¼ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.clients = {}
        self.models = {}
        self.setup_clients()
    
    def setup_clients(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ LLM í´ë¼ì´ì–¸íŠ¸ë“¤ì„ ì„¤ì •"""
        # OpenAI í´ë¼ì´ì–¸íŠ¸ (ê¸°ë³¸)
        openai_key = os.getenv('OPENAI_API_KEY')
        if openai_key:
            try:
                self.clients['openai'] = OpenAI(api_key=openai_key)
                self.models['openai'] = [
                    'gpt-4-turbo-preview',
                    'gpt-4',
                    'gpt-3.5-turbo',
                    'gpt-3.5-turbo-16k'
                ]
            except Exception as e:
                st.warning(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ì‹¤íŒ¨: {e}")
        
        # Ollama í´ë¼ì´ì–¸íŠ¸ (ë¡œì»¬ LLM) - ì„ íƒì 
        try:
            import requests
            # Ollama ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸ (ì§§ì€ íƒ€ì„ì•„ì›ƒ)
            response = requests.get("http://localhost:11434/api/tags", timeout=2)
            if response.status_code == 200:
                self.clients['ollama'] = requests
                self.models['ollama'] = [
                    'mistral:latest',
                    'llama3.1:latest',
                    'llama3.1:8b',
                    'phi4:latest',
                    'llama3.3:latest',
                    'llama2:latest',
                    'gemma2:latest',
                    'gemma:latest',
                    'llama3.2:latest',
                    'deepseek-r1:32b',
                    'deepseek-r1:70b',
                    'deepseek-r1:14b',
                    'nomic-embed-text:latest'
                ]
        except Exception as e:
            # Ollama ì—°ê²° ì‹¤íŒ¨ ì‹œ ì¡°ìš©íˆ ë¬´ì‹œ (ê²½ê³  ë©”ì‹œì§€ ì œê±°)
            pass
        
        # Perplexity í´ë¼ì´ì–¸íŠ¸
        perplexity_key = os.getenv('PERPLEXITY_API_KEY')
        if perplexity_key:
            try:
                self.clients['perplexity'] = OpenAI(
                    api_key=perplexity_key,
                    base_url="https://api.perplexity.ai"
                )
                self.models['perplexity'] = [
                    'sonar-pro',
                    'sonar-small-online',
                    'llama-3.1-sonar-small-128k-online',
                    'llama-3.1-sonar-medium-128k-online',
                    'llama-3.1-sonar-large-128k-online'
                ]
            except Exception as e:
                st.warning(f"Perplexity í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ì‹¤íŒ¨: {e}")
        
        # Anthropic í´ë¼ì´ì–¸íŠ¸ (Claude)
        anthropic_key = os.getenv('ANTHROPIC_API_KEY')
        if anthropic_key:
            try:
                import anthropic
                self.clients['anthropic'] = anthropic.Anthropic(api_key=anthropic_key)
                self.models['anthropic'] = [
                    'claude-3-opus-20240229',
                    'claude-3-sonnet-20240229',
                    'claude-3-haiku-20240307'
                ]
            except Exception as e:
                st.warning(f"Anthropic í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ì‹¤íŒ¨: {e}")
        
        # Google Gemini í´ë¼ì´ì–¸íŠ¸
        google_key = os.getenv('GOOGLE_API_KEY')
        if google_key:
            try:
                import google.generativeai as genai
                genai.configure(api_key=google_key)
                self.clients['google'] = genai
                self.models['google'] = [
                    'gemini-pro',
                    'gemini-pro-vision'
                ]
            except Exception as e:
                st.warning(f"Google Gemini í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ì‹¤íŒ¨: {e}")
    
    def get_available_providers(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ LLM ì œê³µì ëª©ë¡ ë°˜í™˜"""
        return list(self.clients.keys())
    
    def get_models_for_provider(self, provider):
        """íŠ¹ì • ì œê³µìì˜ ëª¨ë¸ ëª©ë¡ ë°˜í™˜"""
        return self.models.get(provider, [])
    
    def generate_response(self, provider, model, messages, temperature=0.7, max_tokens=2000):
        """ì„ íƒëœ LLMìœ¼ë¡œ ì‘ë‹µ ìƒì„±"""
        try:
            if provider == 'ollama':
                return self._generate_ollama_response(model, messages, temperature, max_tokens)
            elif provider == 'openai':
                return self._generate_openai_response(model, messages, temperature, max_tokens)
            elif provider == 'perplexity':
                return self._generate_perplexity_response(model, messages, temperature, max_tokens)
            elif provider == 'anthropic':
                return self._generate_anthropic_response(model, messages, temperature, max_tokens)
            elif provider == 'google':
                return self._generate_google_response(model, messages, temperature, max_tokens)
            else:
                return None, f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì œê³µì: {provider}"
        except Exception as e:
            return None, f"ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {str(e)}"
    
    def _generate_ollama_response(self, model, messages, temperature, max_tokens):
        """Ollama ì‘ë‹µ ìƒì„±"""
        try:
            # Ollama API í˜•ì‹ì— ë§ê²Œ ë©”ì‹œì§€ ë³€í™˜
            ollama_messages = []
            for msg in messages:
                if msg['role'] == 'system':
                    # ì‹œìŠ¤í…œ ë©”ì‹œì§€ëŠ” í”„ë¡¬í”„íŠ¸ì— í¬í•¨
                    continue
                elif msg['role'] == 'user':
                    ollama_messages.append({
                        'role': 'user',
                        'content': msg['content']
                    })
                elif msg['role'] == 'assistant':
                    ollama_messages.append({
                        'role': 'assistant',
                        'content': msg['content']
                    })
            
            # ì‹œìŠ¤í…œ ë©”ì‹œì§€ê°€ ìˆìœ¼ë©´ ì²« ë²ˆì§¸ ì‚¬ìš©ì ë©”ì‹œì§€ì— í¬í•¨
            system_content = ""
            for msg in messages:
                if msg['role'] == 'system':
                    system_content = msg['content']
                    break
            
            if system_content and ollama_messages:
                ollama_messages[0]['content'] = f"{system_content}\n\n{ollama_messages[0]['content']}"
            
            # Ollama API í˜¸ì¶œ
            response = self.clients['ollama'].post(
                "http://localhost:11434/api/chat",
                json={
                    "model": model,
                    "messages": ollama_messages,
                    "stream": False,
                    "options": {
                        "temperature": temperature,
                        "num_predict": max_tokens
                    }
                },
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                return result['message']['content'], None
            else:
                return None, f"Ollama API ì˜¤ë¥˜: {response.status_code}"
                
        except Exception as e:
            return None, f"Ollama ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {str(e)}"
    
    def _generate_openai_response(self, model, messages, temperature, max_tokens):
        """OpenAI ì‘ë‹µ ìƒì„±"""
        response = self.clients['openai'].chat.completions.create(
            model=model,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens
        )
        return response.choices[0].message.content, None
    
    def _generate_perplexity_response(self, model, messages, temperature, max_tokens):
        """Perplexity ì‘ë‹µ ìƒì„±"""
        response = self.clients['perplexity'].chat.completions.create(
            model=model,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens
        )
        return response.choices[0].message.content, None
    
    def _generate_anthropic_response(self, model, messages, temperature, max_tokens):
        """Anthropic ì‘ë‹µ ìƒì„±"""
        # Anthropicì€ ë‹¤ë¥¸ ë©”ì‹œì§€ í˜•ì‹ì„ ì‚¬ìš©
        system_message = ""
        user_messages = []
        
        for msg in messages:
            if msg['role'] == 'system':
                system_message = msg['content']
            else:
                user_messages.append(msg['content'])
        
        user_content = "\n\n".join(user_messages)
        
        response = self.clients['anthropic'].messages.create(
            model=model,
            max_tokens=max_tokens,
            temperature=temperature,
            system=system_message,
            messages=[{"role": "user", "content": user_content}]
        )
        return response.content[0].text, None
    
    def _generate_google_response(self, model, messages, temperature, max_tokens):
        """Google Gemini ì‘ë‹µ ìƒì„±"""
        # GeminiëŠ” ë‹¤ë¥¸ ë©”ì‹œì§€ í˜•ì‹ì„ ì‚¬ìš©
        user_content = ""
        for msg in messages:
            if msg['role'] == 'user':
                user_content += msg['content'] + "\n\n"
        
        model_instance = self.clients['google'].GenerativeModel(model)
        response = model_instance.generate_content(
            user_content,
            generation_config=self.clients['google'].types.GenerationConfig(
                temperature=temperature,
                max_output_tokens=max_tokens
            )
        )
        return response.text, None

# ===== RAG ì‹œìŠ¤í…œ =====

class RAGSystem:
    """Embedding ê¸°ë°˜ RAG ì‹œìŠ¤í…œ (OpenAI)"""
    def __init__(self):
        self.document_embeddings = None
        self.documents = []
        self.document_metadata = []
        self.is_loaded = False
        self.setup_database()

    def embed_text(self, text):
        client = openai.OpenAI()
        response = client.embeddings.create(
            input=[text],
            model="text-embedding-ada-002"
        )
        return np.array(response.data[0].embedding)

    def setup_database(self):
        """RAG ë¬¸ì„œ ë° íŒŒì¼ í…Œì´ë¸” ìƒì„± ë° ìë™ ë™ê¸°í™”"""
        try:
            conn = connect_to_db()
            cursor = conn.cursor()
            
            # RAG ë¬¸ì„œ í…Œì´ë¸” ìƒì„±
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS rag_documents (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    title VARCHAR(255) NOT NULL,
                    content TEXT NOT NULL,
                    document_type VARCHAR(100) DEFAULT 'general',
                    category VARCHAR(100) DEFAULT 'general',
                    tags TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                    is_active BOOLEAN DEFAULT TRUE,
                    INDEX idx_document_type (document_type),
                    INDEX idx_category (category),
                    INDEX idx_is_active (is_active)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """)

            # RAG íŒŒì¼ í…Œì´ë¸” ìƒì„± (PDF/ì—‘ì…€ ë“± ì—…ë¡œë“œ íŒŒì¼)
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS rag_files (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    filename VARCHAR(255),
                    filetype VARCHAR(255),
                    content LONGBLOB,
                    uploaded_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    is_active BOOLEAN DEFAULT TRUE
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """)
            
            # ì´ˆê¸° ë°ì´í„° ì‚½ì… (ì—†ëŠ” ê²½ìš°ì—ë§Œ)
            self.insert_initial_documents(cursor)
            
            conn.commit()
            cursor.close()
            conn.close()
            
            # ì•± ì‹œì‘ ì‹œ ìë™ ë™ê¸°í™”
            self.auto_sync_on_startup()
            
        except Exception as e:
            st.error(f"RAG ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ì˜¤ë¥˜: {str(e)}")
    
    def auto_sync_on_startup(self):
        """ì•± ì‹œì‘ ì‹œ ìë™ ë™ê¸°í™” (ë¹„ë™ê¸° ì²˜ë¦¬)"""
        try:
            # 1. íŒ€ë©”ì´íŠ¸ ë°ì´í„° ìë™ ë™ê¸°í™” (ì¡°ìš©íˆ)
            try:
                self.load_teammates_from_db()
            except:
                pass
            
            # 2. íŒŒì¼ ë°ì´í„° ìë™ ë™ê¸°í™” (ì¡°ìš©íˆ)
            try:
                self.load_files_from_db()
            except:
                pass
            
            # 3. RAG ì¸ë±ìŠ¤ ìë™ êµ¬ì¶•
            self.build_index()
            
        except Exception as e:
            # ì¡°ìš©íˆ ë¬´ì‹œ (ë¡œë”© ì†ë„ í–¥ìƒ)
            pass
    
    def insert_initial_documents(self, cursor):
        """ì´ˆê¸° ì•„ì¹´ë¼ë¼ì´í”„ ë¬¸ì„œ ì‚½ì… (ê¸°ë³¸ íšŒì‚¬ êµ¬ì¡°ë§Œ)"""
        try:
            # ê¸°ì¡´ ë¬¸ì„œ í™•ì¸
            cursor.execute("SELECT COUNT(*) FROM rag_documents")
            if cursor.fetchone()[0] > 0:
                return  # ì´ë¯¸ ë¬¸ì„œê°€ ìˆìœ¼ë©´ ìŠ¤í‚µ
            
            # ê¸°ë³¸ íšŒì‚¬ êµ¬ì¡° ë¬¸ì„œë§Œ ìœ ì§€ (ê°œì¸ ì •ë³´ëŠ” DBì—ì„œ ë™ì  ë¡œë“œ)
            initial_documents = [
                {
                    'title': 'ì•„ì¹´ë¼ë¼ì´í”„ ì—…ë¬´ í”„ë¡œì„¸ìŠ¤',
                    'content': """
                    ì•„ì¹´ë¼ë¼ì´í”„ ì—…ë¬´ í”„ë¡œì„¸ìŠ¤
                    1. ì‹ ê·œ í”„ë¡œì íŠ¸ ê¸°ì•ˆ
                       - í”„ë¡œì íŠ¸ ì œì•ˆì„œ ì‘ì„±
                       - ì˜ˆì‚° ì‚°ì • ë° ìŠ¹ì¸ ìš”ì²­
                       - íŒ€ êµ¬ì„± ë° ì—­í•  ë¶„ë‹´
                    
                    2. í”„ë¡œì íŠ¸ ì‹¤í–‰
                       - ì£¼ê°„ ì§„í–‰ìƒí™© ë³´ê³ 
                       - ì›”ê°„ ì„±ê³¼ í‰ê°€
                       - ì´ìŠˆ ë°œìƒ ì‹œ ì¦‰ì‹œ ë³´ê³ 
                    
                    3. í”„ë¡œì íŠ¸ ì™„ë£Œ
                       - ìµœì¢… ì„±ê³¼ ë³´ê³ ì„œ ì‘ì„±
                       - ì‚¬í›„ í‰ê°€ ë° ê°œì„ ì‚¬í•­ ë„ì¶œ
                       - ê²½í—˜ ì¶•ì  ë° ê³µìœ 
                    """,
                    'document_type': 'process',
                    'category': 'project_management'
                },
                {
                    'title': 'ì•„ì¹´ë¼ë¼ì´í”„ ì „ê²° ê·œì •',
                    'content': """
                    ì•„ì¹´ë¼ë¼ì´í”„ ì „ê²° ê·œì •
                    1. ì¼ë°˜ ì‚¬í•­
                       - 100ë§Œì› ì´í•˜: ë¶€ì„œì¥ ì „ê²°
                       - 100ë§Œì› ì´ˆê³¼ 500ë§Œì› ì´í•˜: ì´ì‚¬ ì „ê²°
                       - 500ë§Œì› ì´ˆê³¼: ì´ì‚¬íšŒ ìŠ¹ì¸ í•„ìš”
                    
                    2. ê¸´ê¸‰ ì‚¬í•­
                       - ê¸´ê¸‰í•œ ê²½ìš° ì‚¬í›„ ë³´ê³  ê°€ëŠ¥
                       - 3ì¼ ì´ë‚´ ì‚¬í›„ ìŠ¹ì¸ ì ˆì°¨ ì§„í–‰
                    
                    3. ì˜ˆì™¸ ì‚¬í•­
                       - íŠ¹ë³„ ì˜ˆì‚°ì€ ë³„ë„ ê·œì • ì ìš©
                       - ì™¸ë¶€ ì—…ì²´ ê³„ì•½ì€ ë²•ë¬´íŒ€ ê²€í†  í•„ìˆ˜
                    """,
                    'document_type': 'regulation',
                    'category': 'approval'
                },
                {
                    'title': 'ì•„ì¹´ë¼ë¼ì´í”„ ì¡°ì§ë„',
                    'content': """
                    ì•„ì¹´ë¼ë¼ì´í”„ ì¡°ì§ë„
                    
                    ê²½ì˜ì§„:
                    - CEO: ì „ì‚¬ ê²½ì˜ ì´ê´„
                    - CTO: ê¸°ìˆ  ê°œë°œ ì´ê´„
                    - CFO: ì¬ë¬´ íšŒê³„ ì´ê´„
                    
                    ì£¼ìš” ë¶€ì„œ:
                    - ê°œë°œíŒ€: ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ë° ê¸°ìˆ  ì§€ì›
                    - ë§ˆì¼€íŒ…íŒ€: ë§ˆì¼€íŒ… ì „ëµ ë° í™ë³´
                    - ì˜ì—…íŒ€: ê³ ê° ê´€ë¦¬ ë° ì˜ì—… í™œë™
                    - ì¸ì‚¬íŒ€: ì¸ì‚¬ ê´€ë¦¬ ë° ì±„ìš©
                    - ì¬ë¬´íŒ€: ì¬ë¬´ ê´€ë¦¬ ë° íšŒê³„
                    
                    â€» êµ¬ì²´ì ì¸ ë‹´ë‹¹ì ì •ë³´ëŠ” company_teammates í…Œì´ë¸”ì—ì„œ ë™ì  ì¡°íšŒ
                    """,
                    'document_type': 'organization',
                    'category': 'company_structure'
                }
            ]
            
            for doc in initial_documents:
                cursor.execute("""
                    INSERT INTO rag_documents (title, content, document_type, category)
                    VALUES (%s, %s, %s, %s)
                """, (doc['title'], doc['content'], doc['document_type'], doc['category']))
            
        except Exception as e:
            st.error(f"ì´ˆê¸° ë¬¸ì„œ ì‚½ì… ì˜¤ë¥˜: {str(e)}")
    
    def load_files_from_db(self):
        """rag_files í…Œì´ë¸”ì—ì„œ íŒŒì¼ ì •ë³´ë¥¼ RAG ë¬¸ì„œë¡œ ë³€í™˜"""
        try:
            # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
            conn = connect_to_db()
            cursor = conn.cursor(dictionary=True)
            
            # í™œì„± íŒŒì¼ ì¡°íšŒ
            cursor.execute("SELECT * FROM rag_files WHERE is_active = TRUE")
            files = cursor.fetchall()
            
            cursor.close()
            conn.close()

            if not files:
                return
            
            # RAG ë¬¸ì„œ ì €ì¥ì„ ìœ„í•œ ìƒˆ ì—°ê²°
            rag_conn = connect_to_db()
            rag_cursor = rag_conn.cursor()
            
            try:
                for file in files:
                    # ì´ë¯¸ RAG ë¬¸ì„œë¡œ ë³€í™˜ë˜ì—ˆëŠ”ì§€ í™•ì¸
                    rag_cursor.execute("""
                        SELECT COUNT(*) FROM rag_documents 
                        WHERE tags = %s AND document_type = 'file'
                    """, (file['filename'],))
                    
                    if rag_cursor.fetchone()[0] == 0:  # ì•„ì§ ë³€í™˜ë˜ì§€ ì•Šì€ íŒŒì¼ë§Œ
                        # íŒŒì¼ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
                        file_conn = connect_to_db()
                        file_cursor = file_conn.cursor(dictionary=True)
                        file_cursor.execute("SELECT content FROM rag_files WHERE id=%s", (file['id'],))
                        file_data = file_cursor.fetchone()
                        file_cursor.close()
                        file_conn.close()
                        
                        if file_data and file_data['content']:
                            file_bytes = file_data['content']
                            extracted_text = ""
                            
                            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
                            if file['filename'].lower().endswith(".pdf"):
                                try:
                                    import PyPDF2
                                    import io
                                    pdf_reader = PyPDF2.PdfReader(io.BytesIO(file_bytes))
                                    for page in pdf_reader.pages:
                                        extracted_text += page.extract_text() or ""
                                except Exception as e:
                                    continue
                            elif file['filename'].lower().endswith((".xlsx", ".xls")):
                                try:
                                    import pandas
                                    import io
                                    df = pandas.read_excel(io.BytesIO(file_bytes), dtype=str)
                                    extracted_parts = []
                                    
                                    # ëª¨ë“  í–‰ì„ ì²˜ë¦¬
                                    for idx, row in df.iterrows():
                                        valid_values = []
                                        for col in df.columns:
                                            val = row[col]
                                            # ë” ì•ˆì „í•œ ê°’ ê²€ì¦
                                            if (pandas.notna(val) and 
                                                str(val).strip() != 'nan' and 
                                                str(val).strip() != '' and
                                                str(val).strip() != 'None'):
                                                valid_values.append(str(val).strip())
                                        if valid_values:
                                            extracted_parts.append(' '.join(valid_values))
                                    
                                    extracted_text = '\n'.join(extracted_parts)
                                    
                                except Exception as e:
                                    continue
                            
                            # rag_documentsì— ì €ì¥
                            if extracted_text.strip():
                                rag_cursor.execute("""
                                    INSERT INTO rag_documents (title, content, document_type, category, tags, is_active)
                                    VALUES (%s, %s, %s, %s, %s, TRUE)
                                """, (f"íŒŒì¼:{file['filename']}", extracted_text, "file", "uploaded_file", file['filename']))
                
                rag_conn.commit()
                
            finally:
                rag_cursor.close()
                rag_conn.close()
                
        except Exception as e:
            # st.error(f"íŒŒì¼ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
            pass
    
    def load_teammates_from_db(self):
        """company_teammates í…Œì´ë¸”ì—ì„œ íŒ€ë©”ì´íŠ¸ ì •ë³´ë¥¼ RAG ë¬¸ì„œë¡œ ë³€í™˜"""
        try:
            # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
            conn = connect_to_db()
            cursor = conn.cursor(dictionary=True)
            
            # í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            cursor.execute("SHOW TABLES LIKE 'company_teammates'")
            table_exists = cursor.fetchone()
            if not table_exists:
                # st.warning("company_teammates í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                cursor.close()
                conn.close()
                return
            
            # íŒ€ë©”ì´íŠ¸ ë°ì´í„° ì¡°íšŒ
            cursor.execute("SELECT * FROM company_teammates")
            teammates = cursor.fetchall()
            
            cursor.close()
            conn.close()
            
            if not teammates:
                # st.warning("company_teammates í…Œì´ë¸”ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            # RAG ë¬¸ì„œ ì €ì¥ì„ ìœ„í•œ ìƒˆ ì—°ê²°
            rag_conn = connect_to_db()
            rag_cursor = rag_conn.cursor()
            
            try:
                added_count = 0
                for teammate in teammates:
                    # ìœ íš¨í•œ ë°ì´í„°ë§Œ ì¶”ì¶œ
                    valid_data = {}
                    for key, value in teammate.items():
                        if key not in ['created_at', 'updated_at', 'id'] and value and str(value).strip():
                            valid_data[key] = str(value).strip()
                    
                    if valid_data:
                        # ì œëª© ìƒì„± (ì„±ëª… ë˜ëŠ” ì´ë¦„ ìš°ì„ )
                        title = valid_data.get('ì„±ëª…', valid_data.get('ì´ë¦„', 'íŒ€ë©”ì´íŠ¸ ì •ë³´'))
                        
                        # ë‚´ìš© ìƒì„±
                        content_parts = []
                        for key, value in valid_data.items():
                            content_parts.append(f"{key}: {value}")
                        content = "\n".join(content_parts)
                        
                        # ì¤‘ë³µ í™•ì¸ ë° ì €ì¥ (ë” ì •í™•í•œ ì¤‘ë³µ ì²´í¬)
                        rag_cursor.execute("""
                            SELECT COUNT(*) FROM rag_documents 
                            WHERE title = %s AND document_type = 'teammate' AND tags = 'company_teammates'
                        """, (title,))
                        
                        if rag_cursor.fetchone()[0] == 0:
                            rag_cursor.execute("""
                                INSERT INTO rag_documents (title, content, document_type, category, tags, is_active)
                                VALUES (%s, %s, %s, %s, %s, TRUE)
                            """, (title, content, 'teammate', 'organization', 'company_teammates'))
                            added_count += 1
                        # ì´ë¦„+ë‹´ë‹¹ì—…ë¬´ ì¡°í•© ë¬¸ì„œ ì¶”ê°€ (ë‹¤ì–‘í•œ ì œëª©/ì´ë¦„ í˜•íƒœ)
                        name = valid_data.get('ì„±ëª…', valid_data.get('ì´ë¦„', None))
                        duty = valid_data.get('ë‹´ë‹¹ì—…ë¬´', None)
                        if name and duty:
                            name_variants = [name, f"{name}ë‹˜", f"{name} ë‹˜", f"{name}ì”¨", f"{name} íŒ€ì›"]
                            for suffix in ["ë‹´ë‹¹ì—…ë¬´", "ì—…ë¬´", "ë¬´ì—‡ì„ ë‹´ë‹¹í•˜ë‚˜ìš”", "í•˜ëŠ” ì¼", "ì—­í• "]:
                                for n in name_variants:
                                    duty_title = f"{n} {suffix}"
                                    duty_content = (
                                        f"{n}ì˜ ì—­í• /ì—…ë¬´ ì•ˆë‚´ì…ë‹ˆë‹¤. {n}ë‹˜ì˜ ë‹´ë‹¹ì—…ë¬´ëŠ” {duty}ì…ë‹ˆë‹¤. "
                                        f"{n}ì€(ëŠ”) íšŒì‚¬ì—ì„œ {duty}ë¥¼ ë‹´ë‹¹í•˜ê³  ìˆìŠµë‹ˆë‹¤. "
                                        f"ë¬¸ì˜: {n}."
                                    )
                                    rag_cursor.execute(
                                        """SELECT COUNT(*) FROM rag_documents 
                                        WHERE title = %s AND document_type = 'teammate' AND tags = 'company_teammates'""", (duty_title,))
                                    if rag_cursor.fetchone()[0] == 0:
                                        rag_cursor.execute(
                                            """INSERT INTO rag_documents (title, content, document_type, category, tags, is_active)
                                            VALUES (%s, %s, %s, %s, %s, TRUE)""", (duty_title, duty_content, 'teammate', 'organization', 'company_teammates'))
                                        added_count += 1
                
                rag_conn.commit()
                
                # ì„±ê³µ ë©”ì‹œì§€ ì œê±° (ë¡œë”© ì†ë„ í–¥ìƒ)
                # if added_count > 0:
                #     st.success(f"íŒ€ë©”ì´íŠ¸ ë°ì´í„° {added_count}ê°œê°€ RAG ì‹œìŠ¤í…œì— ìë™ ë™ê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
                # else:
                #     st.info("ìƒˆë¡œ ì¶”ê°€ëœ íŒ€ë©”ì´íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ì´ë¯¸ ë™ê¸°í™”ë¨)")
                
            finally:
                rag_cursor.close()
                rag_conn.close()
                
        except Exception as e:
            st.error(f"íŒ€ë©”ì´íŠ¸ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
            import traceback
            st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
    
    def load_documents_from_db(self):
        """DBì—ì„œ ë¬¸ì„œ ë¡œë“œ"""
        try:
            conn = connect_to_db()
            cursor = conn.cursor(dictionary=True)
            
            cursor.execute("""
                SELECT id, title, content, document_type, category, tags
                FROM rag_documents 
                WHERE is_active = TRUE
                ORDER BY created_at DESC
            """)
            
            documents = cursor.fetchall()
            cursor.close()
            conn.close()

            # ë¬¸ì„œ ë°ì´í„° ì •ë¦¬
            self.documents = []
            self.document_metadata = []
            
            for doc in documents:
                self.documents.append(doc['content'])
                self.document_metadata.append({
                    'id': doc['id'],
                    'title': doc['title'],
                    'type': doc['document_type'],
                    'category': doc['category'],
                    'tags': doc['tags']
                })
            
            return True
            
        except Exception as e:
            st.error(f"DB ë¬¸ì„œ ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
            return False
    
    def add_document(self, title, content, document_type='general', category='general', tags=None):
        """ìƒˆ ë¬¸ì„œ ì¶”ê°€"""
        try:
            conn = connect_to_db()
            cursor = conn.cursor()
            
            cursor.execute("""
                INSERT INTO rag_documents (title, content, document_type, category, tags)
                VALUES (%s, %s, %s, %s, %s)
            """, (title, content, document_type, category, tags))
            
            conn.commit()
            cursor.close()
            conn.close()
            
            # ì¸ë±ìŠ¤ ì¬êµ¬ì¶• í•„ìš”
            self.is_loaded = False
            
            return True
            
        except Exception as e:
            st.error(f"ë¬¸ì„œ ì¶”ê°€ ì˜¤ë¥˜: {str(e)}")
            return False
    
    def update_document(self, doc_id, title, content, document_type=None, category=None, tags=None):
        """ë¬¸ì„œ ìˆ˜ì •"""
        try:
            conn = connect_to_db()
            cursor = conn.cursor()
            
            update_fields = ["title = %s", "content = %s"]
            params = [title, content]
            
            if document_type:
                update_fields.append("document_type = %s")
                params.append(document_type)
            if category:
                update_fields.append("category = %s")
                params.append(category)
            if tags:
                update_fields.append("tags = %s")
                params.append(tags)
            
            params.append(doc_id)
            
            cursor.execute(f"""
                UPDATE rag_documents 
                SET {', '.join(update_fields)}
                WHERE id = %s
            """, params)
            
            conn.commit()
            cursor.close()
            conn.close()

            # ì¸ë±ìŠ¤ ì¬êµ¬ì¶• í•„ìš”
            self.is_loaded = False
            
            return True
            
        except Exception as e:
            st.error(f"ë¬¸ì„œ ìˆ˜ì • ì˜¤ë¥˜: {str(e)}")
            return False
    
    def delete_document(self, doc_id):
        """ë¬¸ì„œ ì‚­ì œ (ì†Œí”„íŠ¸ ì‚­ì œ)"""
        try:
            conn = connect_to_db()
            cursor = conn.cursor()
            
            cursor.execute("""
                UPDATE rag_documents 
                SET is_active = FALSE 
                WHERE id = %s
            """, (doc_id,))
            
            conn.commit()
            cursor.close()
            conn.close()

            # ì¸ë±ìŠ¤ ì¬êµ¬ì¶• í•„ìš”
            self.is_loaded = False
            
            return True
            
        except Exception as e:
            st.error(f"ë¬¸ì„œ ì‚­ì œ ì˜¤ë¥˜: {str(e)}")
            return False
    
    def get_all_documents(self):
        """ëª¨ë“  í™œì„± ë¬¸ì„œ ì¡°íšŒ"""
        try:
            conn = connect_to_db()
            cursor = conn.cursor(dictionary=True)
            
            cursor.execute("""
                SELECT id, title, content, document_type, category, tags, created_at
                FROM rag_documents 
                WHERE is_active = TRUE
                ORDER BY created_at DESC
            """)
            
            documents = cursor.fetchall()
            cursor.close()
            conn.close()
            
            return documents
            
        except Exception as e:
            st.error(f"ë¬¸ì„œ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return []
        
    def build_index(self):
        if not self.load_documents_from_db():
            return False
        if not self.documents:
            # st.warning("ê²€ìƒ‰í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
        try:
            # ë¬¸ì„œ ì„ë² ë”©
            self.document_embeddings = []
            for doc in self.documents:
                emb = self.embed_text(doc)
                self.document_embeddings.append(emb)
            self.document_embeddings = np.vstack(self.document_embeddings)
            self.is_loaded = True
            return True
        except Exception as e:
            st.error(f"ì„ë² ë”© ì¸ë±ìŠ¤ êµ¬ì¶• ì‹¤íŒ¨: {str(e)}")
            return False
    
    def search_similar_documents(self, query, top_k=5, min_similarity=0.0, document_type=None, category=None):
        if not self.is_loaded or not self.documents:
            return []
        try:
            # 1. ì„ë² ë”© ê¸°ë°˜ ê²€ìƒ‰
            query_emb = self.embed_text(query)
            sims = np.dot(self.document_embeddings, query_emb) / (norm(self.document_embeddings, axis=1) * norm(query_emb) + 1e-8)
            top_indices = sims.argsort()[-top_k:][::-1]
            
            # 2. í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ (ë‹¨ìˆœí•œ ì´ë¦„ ê²€ìƒ‰ì„ ìœ„í•´)
            keyword_results = []
            query_lower = query.lower()
            
            for idx, doc in enumerate(self.documents):
                metadata = self.document_metadata[idx]
                doc_lower = doc.lower()
                title_lower = metadata.get('title', '').lower()
                
                # í‚¤ì›Œë“œ ë§¤ì¹­ (ì´ë¦„, ì§ê¸‰ ë“±)
                if (query_lower in doc_lower or 
                    query_lower in title_lower or
                    any(keyword in doc_lower for keyword in query_lower.split())):
                    keyword_results.append({
                        'content': doc,
                        'metadata': metadata,
                        'similarity': 0.5  # í‚¤ì›Œë“œ ë§¤ì¹­ ì‹œ ê¸°ë³¸ ìœ ì‚¬ë„
                    })
            
            # 3. ê²°ê³¼ í†µí•©
            results = []
            seen_ids = set()
            
            # ì„ë² ë”© ê²°ê³¼ ì¶”ê°€
            for idx in top_indices:
                metadata = self.document_metadata[idx]
                if document_type and metadata.get('type') != document_type:
                    continue
                if category and metadata.get('category') != category:
                    continue
                if sims[idx] < 0.01:
                    continue
                
                doc_id = metadata.get('id', idx)
                if doc_id not in seen_ids:
                    results.append({
                        'content': self.documents[idx],
                        'metadata': metadata,
                        'similarity': float(sims[idx])
                    })
                    seen_ids.add(doc_id)
            
            # í‚¤ì›Œë“œ ê²°ê³¼ ì¶”ê°€ (ì¤‘ë³µ ì œê±°)
            for result in keyword_results:
                doc_id = result['metadata'].get('id', hash(result['content']))
                if doc_id not in seen_ids:
                    results.append(result)
                    seen_ids.add(doc_id)
            
            # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬
            results.sort(key=lambda x: x['similarity'], reverse=True)
            
            return results[:top_k]
        
        except Exception as e:
            st.error(f"ë¬¸ì„œ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def save_index(self, filepath):
        """ì¸ë±ìŠ¤ ì €ì¥"""
        if not self.is_loaded:
            return False
        
        try:
            with open(filepath, 'wb') as f:
                pickle.dump({
                    'document_embeddings': self.document_embeddings,
                    'documents': self.documents,
                    'document_metadata': self.document_metadata
                }, f)
            return True
        except Exception as e:
            st.error(f"ì¸ë±ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def load_index(self, filepath):
        """ì¸ë±ìŠ¤ ë¡œë“œ"""
        try:
            with open(filepath, 'rb') as f:
                data = pickle.load(f)
                self.document_embeddings = data['document_embeddings']
                self.documents = data['documents']
                self.document_metadata = data['document_metadata']
                self.is_loaded = True
            return True
        except Exception as e:
            st.error(f"ì¸ë±ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def sync_external_data_sources(self):
        """ì™¸ë¶€ ë°ì´í„° ì†ŒìŠ¤ì™€ ë™ê¸°í™” (íŒŒì¼, DB ë“±)"""
        try:
            # 1. íŒ€ë©”ì´íŠ¸ ë°ì´í„° ë™ê¸°í™”
            self.load_teammates_from_db()
            
            # 2. íŒŒì¼ ë°ì´í„° ë™ê¸°í™”
            self.load_files_from_db()
            
            # 3. ì¸ë±ìŠ¤ ì¬êµ¬ì¶•
            self.build_index()
            
            return True
        except Exception as e:
            st.error(f"ì™¸ë¶€ ë°ì´í„° ì†ŒìŠ¤ ë™ê¸°í™” ì˜¤ë¥˜: {str(e)}")
            return False
    
    def add_dynamic_document(self, title, content, document_type='general', category='general', tags=None, source='manual'):
        """ë™ì ìœ¼ë¡œ ë¬¸ì„œ ì¶”ê°€ (ì†ŒìŠ¤ ì¶”ì  í¬í•¨)"""
        try:
            conn = connect_to_db()
            cursor = conn.cursor()
            
            cursor.execute("""
                INSERT INTO rag_documents (title, content, document_type, category, tags)
                VALUES (%s, %s, %s, %s, %s)
            """, (title, content, document_type, category, tags))
            
            conn.commit()
            cursor.close()
            conn.close()
            
            # ì¸ë±ìŠ¤ ì¬êµ¬ì¶• í•„ìš”
            self.is_loaded = False
            
            return True
            
        except Exception as e:
            st.error(f"ë™ì  ë¬¸ì„œ ì¶”ê°€ ì˜¤ë¥˜: {str(e)}")
            return False
    
    def search_with_context(self, query, context_type=None, top_k=5):
        """ì»¨í…ìŠ¤íŠ¸ë¥¼ ê³ ë ¤í•œ ê²€ìƒ‰"""
        if not self.is_loaded:
            self.build_index()
        
        # ê¸°ë³¸ ê²€ìƒ‰
        results = self.search_similar_documents(query, top_k=top_k)
        
        # ì»¨í…ìŠ¤íŠ¸ í•„í„°ë§
        if context_type:
            filtered_results = []
            for result in results:
                metadata = result['metadata']
                if metadata.get('type') == context_type:
                    filtered_results.append(result)
            return filtered_results
        
        return results

# ===== ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í•¨ìˆ˜ =====

def connect_to_db():
    """MySQL DB ì—°ê²°"""
    return mysql.connector.connect(
        user=os.getenv('SQL_USER'),
        password=os.getenv('SQL_PASSWORD'),
        host=os.getenv('SQL_HOST'),
        database=os.getenv('SQL_DATABASE_NEWBIZ'),
        charset='utf8mb4',
        collation='utf8mb4_unicode_ci'
    )

# ===== ì•„ì¹´ë¼ë¼ì´í”„ ì „ìš© ë°ì´í„° ë¡œë” =====

def load_aqaralife_documents():
    """ì•„ì¹´ë¼ë¼ì´í”„ ê´€ë ¨ ë¬¸ì„œë“¤ì„ ë¡œë“œ (ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)"""
    # ì´ í•¨ìˆ˜ëŠ” ì´ì œ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. DBì—ì„œ ë™ì ìœ¼ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.
    return []

# ===== ì±—ë´‡ ì‹œìŠ¤í…œ =====

class AqaralifeChatbot:
    """ì•„ì¹´ë¼ë¼ì´í”„ ì‚¬ë‚´ ì±—ë´‡"""
    
    def __init__(self):
        self.llm_client = LLMClient()
        self.rag_system = RAGSystem()
        self.conversation_history = []
        self.setup_rag()
    
    def setup_rag(self):
        """RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        # DB ê¸°ë°˜ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ì¡°ìš©íˆ)
        try:
            self.rag_system.build_index()
        except:
            pass
    
    def generate_response(self, user_query, provider='openai', model=None, temperature=0.7):
        """ì‚¬ìš©ì ì¿¼ë¦¬ì— ëŒ€í•œ ì‘ë‹µ ìƒì„±"""
        try:
            # 1. RAGë¥¼ í†µí•œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
            relevant_docs = self.rag_system.search_similar_documents(user_query, top_k=8, min_similarity=0.0)
            
            # í—ˆêµ¬ ë‹µë³€ ë°©ì§€: ê´€ë ¨ ë¬¸ì„œê°€ ì—†ìœ¼ë©´ LLM í˜¸ì¶œ ì—†ì´ ì•ˆë‚´
            if not relevant_docs:
                return "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í™•ì¸ í›„ ë‹µë³€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.", None
            
            # 2. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context = self._build_context(relevant_docs)
            
            # 3. í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = self._build_prompt(user_query, context)
            
            # 4. LLM ì‘ë‹µ ìƒì„±
            if model is None:
                models = self.llm_client.get_models_for_provider(provider)
                model = models[0] if models else None
            
            if not model:
                return "ì§€ì›í•˜ëŠ” ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.", None
            
            response, error = self.llm_client.generate_response(
                provider, model, prompt, temperature
            )
            
            if error:
                return f"ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {error}", None
            
            # 5. ëŒ€í™” ê¸°ë¡ ì—…ë°ì´íŠ¸
            self.conversation_history.append({
                'user': user_query,
                'assistant': response,
                'timestamp': datetime.now(),
                'provider': provider,
                'model': model
            })
            
            return response, relevant_docs
            
        except Exception as e:
            return f"ì±—ë´‡ ì˜¤ë¥˜: {str(e)}", None
    
    def _build_context(self, relevant_docs):
        """ê´€ë ¨ ë¬¸ì„œë¡œë¶€í„° ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±"""
        if not relevant_docs:
            return "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        context_parts = []
        for i, doc in enumerate(relevant_docs, 1):
            title = doc['metadata'].get('title', f'ë¬¸ì„œ {i}')
            context_parts.append(f"ë¬¸ì„œ {i} - {title} (ìœ ì‚¬ë„: {doc['similarity']:.2f}):\n{doc['content']}")
        
        return "\n\n".join(context_parts)
    
    def _build_prompt(self, user_query, context):
        """í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        system_prompt = """ë‹¹ì‹ ì€ ì•„ì¹´ë¼ë¼ì´í”„ì˜ ì‚¬ë‚´ ì±—ë´‡ì…ë‹ˆë‹¤. 
ë‹¤ìŒ ê·œì¹™ì„ ì—„ê²©íˆ ë”°ë¼ ì‘ë‹µí•´ì£¼ì„¸ìš”:

**í•µì‹¬ ì›ì¹™:**
1. **ì˜¤ì§ ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ì—ë§Œ ê·¼ê±°í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”**
2. **ë¬¸ì„œì— ì—†ëŠ” ì •ë³´ëŠ” ì ˆëŒ€ ë§Œë“¤ì–´ë‚´ì§€ ë§ˆì„¸ìš”**
3. **í™•ì‹¤í•˜ì§€ ì•Šì€ ì •ë³´ëŠ” "í™•ì¸ í›„ ë‹µë³€ë“œë¦¬ê² ìŠµë‹ˆë‹¤"ë¼ê³  ì•ˆë‚´í•˜ì„¸ìš”**

**ì‘ë‹µ ê·œì¹™:**
1. ì•„ì¹´ë¼ë¼ì´í”„ì˜ ì—…ë¬´ í”„ë¡œì„¸ìŠ¤, ì „ê²° ê·œì •, ì¡°ì§ë„, íŒ€ë©”ì´íŠ¸ ì •ë³´ì— ëŒ€í•œ ì§ˆë¬¸ì— ì •í™•íˆ ë‹µë³€
2. ë‹´ë‹¹ì ê²€ìƒ‰ ì‹œ ì •í™•í•œ ë¶€ì„œì™€ ì—°ë½ì²˜ ì œê³µ (ë¬¸ì„œì— ìˆëŠ” ì •ë³´ë§Œ)
3. ì „ê²° ê·œì • ê´€ë ¨ ì§ˆë¬¸ ì‹œ ì •í™•í•œ ê¸ˆì•¡ ê¸°ì¤€ê³¼ ì ˆì°¨ ì•ˆë‚´
4. ì—…ë¬´ í”„ë¡œì„¸ìŠ¤ ì§ˆë¬¸ ì‹œ êµ¬ì²´ì ì¸ ë‹¨ê³„ì™€ ë‹´ë‹¹ì ì•ˆë‚´
5. íŒ€ë©”ì´íŠ¸ ì •ë³´ ê²€ìƒ‰ ì‹œ í•´ë‹¹ ì¸ì›ì˜ ìƒì„¸ ì •ë³´ì™€ ì—°ë½ì²˜ ì œê³µ
6. ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ í†¤ìœ¼ë¡œ ì‘ë‹µ
7. **ë¬¸ì„œì— ì—†ëŠ” ì •ë³´ëŠ” "í•´ë‹¹ ì •ë³´ê°€ ë¬¸ì„œì— ì—†ìŠµë‹ˆë‹¤" ë˜ëŠ” "í™•ì¸ í›„ ë‹µë³€ë“œë¦¬ê² ìŠµë‹ˆë‹¤"ë¼ê³  ì•ˆë‚´**
8. **ì ˆëŒ€ í—ˆêµ¬ì˜ ì •ë³´ë¥¼ ë§Œë“¤ì–´ë‚´ì§€ ë§ˆì„¸ìš”**
9. **ì•„ë˜ ë¬¸ì„œ ë‚´ìš©ì— ê·¼ê±°í•´ì„œë§Œ ë‹µë³€í•˜ì„¸ìš”**
10. **ë¬¸ì„œì— ì—†ëŠ” ì •ë³´ëŠ” ë‹µí•˜ì§€ ë§ˆì„¸ìš”**
11. **ê°€ì¥ ìœ ì‚¬í•œ ë‚´ìš©ì„ ì°¸ê³ í•´ì„œ ë‹µë³€í•˜ë˜, í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ ì†”ì§íˆ ëª¨ë¥¸ë‹¤ê³  ë‹µë³€í•˜ì„¸ìš”**

**ì¤‘ìš”:** ë§Œì•½ ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ê°€ ì•„ë˜ ë¬¸ì„œì— ì—†ìœ¼ë©´, "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì •ë³´ê°€ ë¬¸ì„œì— ì—†ìŠµë‹ˆë‹¤. í™•ì¸ í›„ ë‹µë³€ë“œë¦¬ê² ìŠµë‹ˆë‹¤."ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.

ì•„ë˜ëŠ” ê´€ë ¨ ë¬¸ì„œ ë‚´ìš©ì…ë‹ˆë‹¤:
{context}

ì‚¬ìš©ì ì§ˆë¬¸: {user_query}"""

        return [
            {"role": "system", "content": system_prompt.format(context=context, user_query=user_query)},
            {"role": "user", "content": user_query}
        ]
    
    def get_conversation_history(self):
        """ëŒ€í™” ê¸°ë¡ ë°˜í™˜"""
        return self.conversation_history
    
    def clear_history(self):
        """ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"""
        self.conversation_history = []

# ===== ë¬¸ì„œ ê´€ë¦¬ í•¨ìˆ˜ë“¤ =====

def add_document_to_rag(title, content, document_type='general', category='general', tags=None):
    """RAG ì‹œìŠ¤í…œì— ìƒˆ ë¬¸ì„œ ì¶”ê°€"""
    try:
        conn = connect_to_db()
        cursor = conn.cursor()
        
        cursor.execute("""
            INSERT INTO rag_documents (title, content, document_type, category, tags)
            VALUES (%s, %s, %s, %s, %s)
        """, (title, content, document_type, category, tags))
        
        conn.commit()
        cursor.close()
        conn.close()
        
        return True
        
    except Exception as e:
        st.error(f"ë¬¸ì„œ ì¶”ê°€ ì˜¤ë¥˜: {str(e)}")
        return False

def get_all_rag_documents():
    """ëª¨ë“  RAG ë¬¸ì„œ ì¡°íšŒ"""
    try:
        conn = connect_to_db()
        cursor = conn.cursor(dictionary=True)
        
        cursor.execute("""
            SELECT id, title, content, document_type, category, tags, created_at
            FROM rag_documents 
            WHERE is_active = TRUE
            ORDER BY created_at DESC
        """)
        
        documents = cursor.fetchall()
        cursor.close()
        conn.close()

        return documents
        
    except Exception as e:
        st.error(f"ë¬¸ì„œ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return []

def update_rag_document(doc_id, title, content, document_type=None, category=None, tags=None):
    """RAG ë¬¸ì„œ ìˆ˜ì •"""
    try:
        conn = connect_to_db()
        cursor = conn.cursor()
        
        update_fields = ["title = %s", "content = %s"]
        params = [title, content]
        
        if document_type:
            update_fields.append("document_type = %s")
            params.append(document_type)
        if category:
            update_fields.append("category = %s")
            params.append(category)
        if tags:
            update_fields.append("tags = %s")
            params.append(tags)
        
        params.append(doc_id)
        
        cursor.execute(f"""
            UPDATE rag_documents 
            SET {', '.join(update_fields)}
            WHERE id = %s
        """, params)
        
        conn.commit()
        cursor.close()
        conn.close()

        return True
        
    except Exception as e:
        st.error(f"ë¬¸ì„œ ìˆ˜ì • ì˜¤ë¥˜: {str(e)}")
        return False

def delete_rag_document(doc_id):
    """RAG ë¬¸ì„œ ì‚­ì œ (ì†Œí”„íŠ¸ ì‚­ì œ)"""
    try:
        conn = connect_to_db()
        cursor = conn.cursor()
        
        cursor.execute("""
            UPDATE rag_documents 
            SET is_active = FALSE 
            WHERE id = %s
        """, (doc_id,))
        
        conn.commit()
        cursor.close()
        conn.close()
        
        return True
        
    except Exception as e:
        st.error(f"ë¬¸ì„œ ì‚­ì œ ì˜¤ë¥˜: {str(e)}")
        return False

# ===== ë©”ì¸ UI =====

def main():
    st.title("ğŸ¤– ì•„ì¹´ë¼ë¼ì´í”„ ì‚¬ë‚´ ì±—ë´‡")
    st.markdown("ì—…ë¬´ í”„ë¡œì„¸ìŠ¤, ì „ê²° ê·œì •, ë‹´ë‹¹ì ê²€ìƒ‰ì„ ë„ì™€ë“œë¦½ë‹ˆë‹¤.")
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'chatbot' not in st.session_state:
        st.session_state.chatbot = AqaralifeChatbot()
    
    if 'conversation' not in st.session_state:
        st.session_state.conversation = []
    
    # íƒ­ ì„ íƒì„ ì„¸ì…˜ ìƒíƒœë¡œ ê´€ë¦¬
    tab_options = ["ğŸ” ê²€ìƒ‰", "ğŸ“ ë¬¸ì„œ ê´€ë¦¬", "ğŸ’¬ ì±—ë´‡", "âš™ï¸ ê´€ë¦¬ì ëª¨ë“œ"]
    if 'selected_tab' not in st.session_state:
        st.session_state.selected_tab = tab_options[0]
    selected_tab = st.radio("íƒ­ ì„ íƒ", tab_options, index=tab_options.index(st.session_state.selected_tab), horizontal=True, label_visibility="collapsed")
    st.session_state.selected_tab = selected_tab

    if selected_tab == "ğŸ” ê²€ìƒ‰":
        # ê¸°ì¡´ tab1 ì½”ë“œ (ë¬¸ì„œ ê²€ìƒ‰)
        st.header("ë¬¸ì„œ ê²€ìƒ‰")
        
        # ê²€ìƒ‰ ë°©ì‹ ì„ íƒ
        search_type = st.radio(
            "ê²€ìƒ‰ ë°©ì‹",
            ["ì¼ë°˜ ê²€ìƒ‰", "AI ë„ì›€"],
            horizontal=True
        )
        
        search_query = st.text_input(
            "ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”",
            placeholder="ì—…ë¬´ í”„ë¡œì„¸ìŠ¤, ì „ê²° ê·œì •, ë‹´ë‹¹ì ë“±"
        )
        
        col1, col2 = st.columns([1, 4])
        
        with col1:
            if st.button("ê²€ìƒ‰", type="primary"):
                if search_query:
                    if search_type == "ì¼ë°˜ ê²€ìƒ‰":
                        # ì¼ë°˜ ê²€ìƒ‰ (RAG ê¸°ë°˜)
                        with st.spinner("ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                            relevant_docs = st.session_state.chatbot.rag_system.search_similar_documents(search_query, top_k=8)
                            
                            if relevant_docs:
                                st.success(f"{len(relevant_docs)}ê°œì˜ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                                st.write("### ê²€ìƒ‰ ê²°ê³¼")
                                
                                for i, doc in enumerate(relevant_docs, 1):
                                    title = doc['metadata'].get('title', f'ë¬¸ì„œ {i}')
                                    doc_type = doc['metadata'].get('type', 'unknown')
                                    category = doc['metadata'].get('category', 'unknown')
                                    
                                    with st.expander(f"ğŸ“„ {title} (ìœ ì‚¬ë„: {doc['similarity']:.2f})"):
                                        st.markdown(f"**ìœ í˜•:** {doc_type}")
                                        st.markdown(f"**ì¹´í…Œê³ ë¦¬:** {category}")
                                        st.markdown("**ë‚´ìš©:**")
                                        st.markdown(doc['content'])
                            else:
                                st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:  # AI ë„ì›€
                        with st.spinner("AIê°€ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤..."):
                            # ê¸°ë³¸ ì œê³µì ì„¤ì • (OpenAI ìš°ì„ )
                            default_provider = 'openai' if 'openai' in st.session_state.chatbot.llm_client.get_available_providers() else 'ollama'
                            default_model = 'gpt-4-turbo-preview' if default_provider == 'openai' else 'mistral:latest'
                            
                            response, relevant_docs = st.session_state.chatbot.generate_response(
                                search_query, default_provider, default_model, 0.7
                            )
                            
                            if response:
                                st.write("### AI ë¶„ì„ ê²°ê³¼")
                                st.markdown(response)
                                
                                if relevant_docs:
                                    with st.expander("ğŸ“š ì°¸ê³  ë¬¸ì„œ"):
                                        for j, doc in enumerate(relevant_docs, 1):
                                            title = doc['metadata'].get('title', f'ë¬¸ì„œ {j}')
                                            st.markdown(f"**{title}** (ìœ ì‚¬ë„: {doc['similarity']:.2f})")
                                            st.markdown(f"*{doc['metadata'].get('type', 'unknown')} - {doc['metadata'].get('category', 'unknown')}*")
                                            st.markdown(doc['content'][:200] + "..." if len(doc['content']) > 200 else doc['content'])
                            else:
                                st.warning("AI ë¶„ì„ ê²°ê³¼ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.warning("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                
                with col2:
                    st.markdown("### ğŸ’¡ ê²€ìƒ‰ íŒ")
                    st.markdown("""
                    **ì¼ë°˜ ê²€ìƒ‰:**
                    - í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ìŠµë‹ˆë‹¤
                    - ìœ ì‚¬ë„ ì ìˆ˜ë¡œ ì •í™•ë„ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
                    
                    **AI ë„ì›€:**
                    - AIê°€ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤
                    - ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ë” ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤
                    """)
    
    elif selected_tab == "ğŸ“ ë¬¸ì„œ ê´€ë¦¬":
        # ë¬¸ì„œ ê´€ë¦¬ (ìˆ˜ë™ ì…ë ¥ë§Œ)
        st.header("ë¬¸ì„œ ê´€ë¦¬")
        
        # ë¬¸ì„œ ì¶”ê°€
        with st.expander("â• ìƒˆ ë¬¸ì„œ ì¶”ê°€"):
            with st.form("add_document_form"):
                title = st.text_input("ë¬¸ì„œ ì œëª©*")
                content = st.text_area("ë¬¸ì„œ ë‚´ìš©*", height=200)
                document_type = st.selectbox("ë¬¸ì„œ ìœ í˜•", ["process", "regulation", "organization", "general"])
                category = st.text_input("ì¹´í…Œê³ ë¦¬", placeholder="ì˜ˆ: project_management, approval, contact")
                tags = st.text_input("íƒœê·¸", placeholder="ì‰¼í‘œë¡œ êµ¬ë¶„")
                
                submitted = st.form_submit_button("ë¬¸ì„œ ì¶”ê°€", type="primary")
                
                if submitted:
                    if title.strip() and content.strip():
                        if add_document_to_rag(title, content, document_type, category, tags):
                            st.success("âœ… ë¬¸ì„œê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!")
                            # RAG ì‹œìŠ¤í…œ ì¬êµ¬ì¶•
                            st.session_state.chatbot.rag_system.build_index()
                            st.rerun()
                    else:
                        st.error("ì œëª©ê³¼ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                
                # íŒŒì¼ ê¸°ë°˜ RAG ê´€ë¦¬ UI
                st.markdown("### ğŸ“‚ íŒŒì¼ ì—…ë¡œë“œ ê´€ë¦¬ (PDF/ì—‘ì…€)")
                uploaded_file = st.file_uploader("PDF ë˜ëŠ” ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ", type=["pdf", "xlsx", "xls"])
                if uploaded_file:
                    import io
                    import pandas
                    filetype = uploaded_file.type
                    filename = uploaded_file.name
                    file_bytes = uploaded_file.read()
                    # íŒŒì¼ ì›ë³¸ DB ì €ì¥
                    try:
                        conn = connect_to_db()
                        cursor = conn.cursor()
                        cursor.execute("""
                            INSERT INTO rag_files (filename, filetype, content, is_active)
                            VALUES (%s, %s, %s, TRUE)
                        """, (filename, filetype, file_bytes))
                        conn.commit()
                        cursor.close()
                        conn.close()
                    except Exception as e:
                        st.error(f"íŒŒì¼ DB ì €ì¥ ì˜¤ë¥˜: {str(e)}")
                        return
                    # í…ìŠ¤íŠ¸ ì¶”ì¶œ
                    extracted_text = ""
                    if filename.lower().endswith(".pdf"):
                        try:
                            import PyPDF2
                            pdf_reader = PyPDF2.PdfReader(io.BytesIO(file_bytes))
                            for page in pdf_reader.pages:
                                extracted_text += page.extract_text() or ""
                        except Exception as e:
                            st.error(f"PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")
                            return
                    elif filename.lower().endswith((".xlsx", ".xls")):
                        try:
                            # ì—‘ì…€ íŒŒì¼ì„ êµ¬ì¡°ì ìœ¼ë¡œ ì½ê¸° (ë” ì•ˆì „í•œ ë°©ì‹)
                            df = pandas.read_excel(io.BytesIO(file_bytes), dtype=str)
                            
                            # ë°ì´í„°ë¥¼ ì˜ë¯¸ ìˆëŠ” í˜•íƒœë¡œ ì¬êµ¬ì„±
                            extracted_parts = []
                            
                            # ëª¨ë“  í–‰ì„ ì²˜ë¦¬
                            for idx, row in df.iterrows():
                                valid_values = []
                                for col in df.columns:
                                    val = row[col]
                                    # ë” ì•ˆì „í•œ ê°’ ê²€ì¦
                                    if (pandas.notna(val) and 
                                        str(val).strip() != 'nan' and 
                                        str(val).strip() != '' and
                                        str(val).strip() != 'None'):
                                        valid_values.append(str(val).strip())
                                if valid_values:
                                    extracted_parts.append(' '.join(valid_values))
                            
                            extracted_text = '\n'.join(extracted_parts)
                            
                            # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìœ¼ë©´ ê¸°ë³¸ ë°©ì‹ìœ¼ë¡œ ì¬ì‹œë„
                            if not extracted_text.strip():
                                df = pandas.read_excel(io.BytesIO(file_bytes), header=None, dtype=str)
                                cleaned_rows = []
                                for _, row in df.iterrows():
                                    valid_values = [str(val).strip() for val in row if (pandas.notna(val) and str(val).strip() != 'nan' and str(val).strip() != '' and str(val).strip() != 'None')]
                                    if valid_values:
                                        cleaned_rows.append(' '.join(valid_values))
                                extracted_text = '\n'.join(cleaned_rows)
                                
                        except Exception as e:
                            st.error(f"ì—‘ì…€ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")
                            return
                    else:
                        st.error("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.")
                        return
                    # í…ìŠ¤íŠ¸ ì¶”ì¶œ ê²°ê³¼ í™•ì¸
                    if not extracted_text.strip():
                        st.warning("íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. PDF/ì—‘ì…€ íŒŒì¼ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
                        return
                    # rag_documentsì— ì €ì¥ (ì—¬ëŸ¬ ë¬¸ì„œë¡œ ë¶„í• )
                    try:
                        conn = connect_to_db()
                        cursor = conn.cursor()
                        max_length = 10000
                        part_count = 0
                        for i in range(0, len(extracted_text), max_length):
                            part = extracted_text[i:i+max_length]
                            part_count += 1
                            cursor.execute("""
                                INSERT INTO rag_documents (title, content, document_type, category, tags, is_active)
                                VALUES (%s, %s, %s, %s, %s, TRUE)
                            """, (f"íŒŒì¼:{filename} (part {part_count})" if len(extracted_text) > max_length else f"íŒŒì¼:{filename}", part, "file", "uploaded_file", filename))
                        conn.commit()
                        cursor.close()
                        conn.close()
                        st.success(f"âœ… {filename} íŒŒì¼ì´ ì—…ë¡œë“œ ë° RAGì— ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤! (ì´ {part_count}ê°œ ë¬¸ì„œë¡œ ì €ì¥ë¨)")
                        st.session_state.chatbot.rag_system.build_index()
                    except Exception as e:
                        st.error(f"RAG ë¬¸ì„œ ì €ì¥ ì˜¤ë¥˜: {str(e)}")
                        return
                
                # ì‹œìŠ¤í…œ ì •ë³´ ë° ë¬¸ì„œ ê´€ë¦¬
                st.markdown("### ğŸ“Š ì‹œìŠ¤í…œ ì •ë³´ ë° ë¬¸ì„œ ê´€ë¦¬")
                
                # ë¬¸ì„œ í†µê³„
                documents = get_all_rag_documents()
                if documents:
                    doc_types = {}
                    doc_categories = {}
                    
                    for doc in documents:
                        doc_type = doc['document_type']
                        doc_category = doc['category']
                        
                        doc_types[doc_type] = doc_types.get(doc_type, 0) + 1
                        doc_categories[doc_category] = doc_categories.get(doc_category, 0) + 1
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.markdown("**ë¬¸ì„œ ìœ í˜•ë³„ ë¶„í¬:**")
                        for doc_type, count in doc_types.items():
                            st.markdown(f"- {doc_type}: {count}ê°œ")
                        
                    with col2:
                        st.markdown("**ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬:**")
                        for category, count in doc_categories.items():
                            st.markdown(f"- {category}: {count}ê°œ")
                    
                    # ì „ì²´ ë¬¸ì„œ ëª©ë¡
                    st.markdown("### ğŸ“‹ ì „ì²´ ë¬¸ì„œ ëª©ë¡")
                    for doc in documents:
                        st.markdown(f"### ğŸ“„ {doc['title']} (ID: {doc['id']})")
                        st.markdown(f"**ì œëª©:** {doc['title']}")
                        st.markdown(f"**ìœ í˜•:** {doc['document_type']}")
                        st.markdown(f"**ì¹´í…Œê³ ë¦¬:** {doc['category']}")
                        st.markdown(f"**ìƒì„±ì¼:** {doc['created_at']}")
                        
                        # ê´€ë¦¬ììš© ì‚­ì œ ë²„íŠ¼
                        if st.button("ğŸ—‘ï¸ ì‚­ì œ", key=f"admin_delete_{doc['id']}", type="secondary"):
                            if delete_rag_document(doc['id']):
                                st.success(f"âœ… '{doc['title']}' ë¬¸ì„œê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                                # RAG ì‹œìŠ¤í…œ ì¬êµ¬ì¶•
                                st.session_state.chatbot.rag_system.build_index()
                                st.rerun()
                        
                        st.divider()
                else:
                    st.info("ë“±ë¡ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    elif selected_tab == "ğŸ’¬ ì±—ë´‡":
        # ê¸°ì¡´ tab3 ì½”ë“œ (ì±—ë´‡)
        st.markdown("""
        <style>
        .user-bubble {
            background: #2d2d2d;
            color: #fff;
            padding: 0.7em 1em;
            border-radius: 1em 1em 0 1em;
            margin: 0.5em 0;
            max-width: 70%;
            align-self: flex-end;
            text-align: right;
        }
        .bot-bubble {
            background: #2323a7;
            color: #fff;
            padding: 0.7em 1em;
            border-radius: 1em 1em 1em 0;
            margin: 0.5em 0;
            max-width: 70%;
            align-self: flex-start;
            text-align: left;
        }
        .bubble-container {
            display: flex;
            flex-direction: column;
        }
        </style>
        """, unsafe_allow_html=True)
        st.markdown("### ğŸ’¬ ì±—ë´‡ê³¼ ëŒ€í™”í•˜ê¸°")

        # ì‚¬ì´ë“œë°” ì„¤ì • (ê¸°ì¡´ê³¼ ë™ì¼)
        with st.sidebar:
            st.markdown("## âš™ï¸ ì„¤ì •")
            providers = st.session_state.chatbot.llm_client.get_available_providers()
            if providers:
                # OpenAIë¥¼ ê¸°ë³¸ ì œê³µìë¡œ ì„¤ì •
                default_provider = 'openai' if 'openai' in providers else providers[0]
                provider_index = providers.index(default_provider) if default_provider in providers else 0
                
                selected_provider = st.selectbox(
                    "LLM ì œê³µì ì„ íƒ",
                    providers,
                    index=provider_index
                )
                models = st.session_state.chatbot.llm_client.get_models_for_provider(selected_provider)
                if models:
                    # ê¸°ë³¸ ëª¨ë¸ ì„¤ì •
                    if selected_provider == 'openai' and 'gpt-4-turbo-preview' in models:
                        model_index = models.index('gpt-4-turbo-preview')
                    elif selected_provider == 'ollama' and 'mistral:latest' in models:
                        model_index = models.index('mistral:latest')
                    else:
                        model_index = 0
                    
                    selected_model = st.selectbox(
                        "ëª¨ë¸ ì„ íƒ",
                        models,
                        index=model_index
                    )
                else:
                    selected_model = None
            else:
                st.error("ì‚¬ìš© ê°€ëŠ¥í•œ LLM ì œê³µìê°€ ì—†ìŠµë‹ˆë‹¤.")
                selected_provider = None
                selected_model = None
            temperature = st.slider("ì°½ì˜ì„± (Temperature)", 0.0, 1.0, 0.7, 0.1)
            st.markdown("---")
            st.markdown("## ğŸ’¬ ëŒ€í™” ê´€ë¦¬")
            if st.button("ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"):
                st.session_state.chatbot.clear_history()
                st.session_state.conversation = []
                st.rerun()
            if st.session_state.conversation:
                conversation_text = "\n\n".join([
                    f"**{msg['role']}:** {msg['content']}" 
                    for msg in st.session_state.conversation
                ])
                st.download_button(
                    "ğŸ“¥ ëŒ€í™” ë‚´ë³´ë‚´ê¸°",
                    conversation_text,
                    file_name=f"aqaralife_chat_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                    mime="text/plain"
                )

        # ì˜ˆì‹œ ì§ˆë¬¸ë“¤ (ìƒë‹¨)
        with st.expander("ğŸ’¡ ì˜ˆì‹œ ì§ˆë¬¸ë“¤"):
            st.markdown("""
            **ì—…ë¬´ í”„ë¡œì„¸ìŠ¤ ê´€ë ¨:**
            - ì‹ ê·œ í”„ë¡œì íŠ¸ ê¸°ì•ˆ ì ˆì°¨ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?
            - í”„ë¡œì íŠ¸ ì§„í–‰ìƒí™© ë³´ê³ ëŠ” ì–¸ì œ í•˜ë‚˜ìš”?
            
            **ì „ê²° ê·œì • ê´€ë ¨:**
            - 300ë§Œì› ì˜ˆì‚° ìŠ¹ì¸ì€ ëˆ„ê°€ í•˜ë‚˜ìš”?
            - ê¸´ê¸‰ ì˜ˆì‚° ì‚¬ìš© ì ˆì°¨ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?
            
            **ë‹´ë‹¹ì ê²€ìƒ‰:**
            - ê°œë°œíŒ€ íŒ€ì¥ì€ ëˆ„êµ¬ì¸ê°€ìš”?
            - ë§ˆì¼€íŒ… ê´€ë ¨ ë¬¸ì˜ëŠ” ëˆ„êµ¬ì—ê²Œ í•˜ë©´ ë˜ë‚˜ìš”?
            
            **íŒ€ë©”ì´íŠ¸ ê²€ìƒ‰:**
            - í™ê¸¸ë™ë‹˜ì˜ ì—°ë½ì²˜ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?
            - ë§ˆì¼€íŒ…íŒ€ì—ì„œ ì¼í•˜ëŠ” ì‚¬ëŒì€ ëˆ„êµ¬ì¸ê°€ìš”?
            - ê°œë°œ ê´€ë ¨í•´ì„œ ëˆ„êµ¬ì—ê²Œ ë¬¸ì˜í•˜ë©´ ë˜ë‚˜ìš”?
            """)

        # ì±—ë´‡ íƒ­ì˜ ë©”ì¸ ì˜ì—­ì„ 3:1ë¡œ ë¶„í• 
        col1, col2 = st.columns([3, 1])
        with col1:
            # ëŒ€í™” ê¸°ë¡ (ëˆ„ì , ë§í’ì„ )
            st.markdown('<div class="bubble-container">', unsafe_allow_html=True)
            for i, message in enumerate(st.session_state.conversation):
                if message['role'] == 'ì‚¬ìš©ì':
                    st.markdown(f"<div class='user-bubble'>ğŸ‘¤ {message['content']}</div>", unsafe_allow_html=True)
                else:
                    st.markdown(f"<div class='bot-bubble'>ğŸ¤– {message['content']}</div>", unsafe_allow_html=True)
                    # ê´€ë ¨ ë¬¸ì„œ í‘œì‹œ (ìˆëŠ” ê²½ìš°)
                    if 'relevant_docs' in message and message['relevant_docs']:
                        with st.expander("ğŸ“š ì°¸ê³  ë¬¸ì„œ", expanded=False):
                            for j, doc in enumerate(message['relevant_docs'], 1):
                                title = doc['metadata'].get('title', f'ë¬¸ì„œ {j}')
                                st.markdown(f"**{title}** (ìœ ì‚¬ë„: {doc['similarity']:.2f})")
                                st.markdown(f"*{doc['metadata'].get('type', 'unknown')} - {doc['metadata'].get('category', 'unknown')}*")
                                st.markdown(doc['content'][:200] + "..." if len(doc['content']) > 200 else doc['content'])
                    if 'provider' in message and 'model' in message:
                        st.caption(f"ì‚¬ìš© ëª¨ë¸: {message['provider']} - {message['model']}")
            st.markdown('</div>', unsafe_allow_html=True)

            # í”„ë¡¬í”„íŠ¸ ì…ë ¥ì°½ (í•­ìƒ í•˜ë‹¨)
            if 'chat_input' not in st.session_state:
                st.session_state['chat_input'] = ""
            # ì•ˆì „í•œ ì…ë ¥ ì´ˆê¸°í™” í”Œë˜ê·¸ ë°©ì‹
            if st.session_state.get('clear_input', False):
                user_input = st.text_area(
                    "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:",
                    key="chat_input",
                    value="",
                    height=80,
                    label_visibility="collapsed",
                    placeholder="ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."
                )
                del st.session_state['clear_input']
            else:
                user_input = st.text_area(
                    "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:",
                    key="chat_input",
                    value=st.session_state['chat_input'],
                    height=80,
                    label_visibility="collapsed",
                    placeholder="ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."
                )
            col_send, col_clear = st.columns([1, 1])
            with col_send:
                if st.button("ì „ì†¡", type="primary"):
                    if user_input.strip():
                        st.session_state.conversation.append({'role': 'ì‚¬ìš©ì', 'content': user_input, 'timestamp': datetime.now()})
                        # streaming ë‹µë³€
                        with st.spinner("ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘..."):
                            response, relevant_docs = st.session_state.chatbot.generate_response(user_input, selected_provider, selected_model, temperature)
                            # streaming íš¨ê³¼
                            bot_placeholder = st.empty()
                            streamed = ""
                            for i in range(1, len(response)+1):
                                streamed = response[:i]
                                bot_placeholder.markdown(f"<div class='bot-bubble'>ğŸ¤– {streamed}</div>", unsafe_allow_html=True)
                                time.sleep(0.01)
                            st.session_state.conversation.append({'role': 'ì±—ë´‡', 'content': response, 'timestamp': datetime.now(), 'provider': selected_provider, 'model': selected_model, 'relevant_docs': relevant_docs})
                        st.session_state['clear_input'] = True
                        st.rerun()
            with col_clear:
                if st.button("ì…ë ¥ ì´ˆê¸°í™”"):
                    st.session_state['clear_input'] = True
                    st.rerun()

        with col2:
            st.markdown("### ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ")
            if selected_provider:
                st.success(f"âœ… {selected_provider} ì—°ê²°ë¨")
                if selected_model:
                    st.info(f"ğŸ¤– ëª¨ë¸: {selected_model}")
                else:
                    st.error("âŒ LLM ì—°ê²° ì•ˆë¨")
            
            # Ollama ì„œë²„ ìƒíƒœ í™•ì¸
            if selected_provider == 'ollama':
                try:
                    import requests
                    response = requests.get("http://localhost:11434/api/tags", timeout=3)
                    if response.status_code == 200:
                        st.success("âœ… Ollama ì„œë²„ ì‹¤í–‰ ì¤‘")
                    else:
                        st.error("âŒ Ollama ì„œë²„ ì—°ê²° ì‹¤íŒ¨")
                except:
                    st.error("âŒ Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            if st.session_state.chatbot.rag_system.is_loaded:
                st.success("âœ… RAG ì‹œìŠ¤í…œ ì¤€ë¹„ë¨")
                st.info(f"ğŸ“š ë¬¸ì„œ ìˆ˜: {len(st.session_state.chatbot.rag_system.documents)}")
            else:
                st.error("âŒ RAG ì‹œìŠ¤í…œ ì˜¤ë¥˜")
            if st.session_state.conversation:
                st.metric("ëŒ€í™” ìˆ˜", len([msg for msg in st.session_state.conversation if msg['role'] == 'ì‚¬ìš©ì']))
    
    elif selected_tab == "âš™ï¸ ê´€ë¦¬ì ëª¨ë“œ":
        st.header("ê´€ë¦¬ì ëª¨ë“œ")
        # ê´€ë¦¬ì ì¸ì¦
        admin_password = st.text_input("ê´€ë¦¬ì ë¹„ë°€ë²ˆí˜¸", type="password")
        if admin_password:
            if verify_admin_password(admin_password):
                st.success("ê´€ë¦¬ì ì¸ì¦ ì„±ê³µ")
                # ì‹œìŠ¤í…œ ê´€ë¦¬ ê¸°ëŠ¥
                st.markdown("### ğŸ”§ ì‹œìŠ¤í…œ ê´€ë¦¬")
                col1, col2, col3 = st.columns(3)
                with col1:
                    if st.button("ğŸ”„ RAG ì‹œìŠ¤í…œ ì¬êµ¬ì¶•"):
                        with st.spinner("RAG ì‹œìŠ¤í…œì„ ì¬êµ¬ì¶•í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                            if st.session_state.chatbot.rag_system.build_index():
                                st.success("âœ… RAG ì‹œìŠ¤í…œì´ ì¬êµ¬ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤!")
                            else:
                                st.error("âŒ RAG ì‹œìŠ¤í…œ ì¬êµ¬ì¶•ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                with col2:
                    if st.button("ğŸ‘¥ íŒ€ë©”ì´íŠ¸ ë™ê¸°í™”"):
                        with st.spinner("íŒ€ë©”ì´íŠ¸ ì •ë³´ë¥¼ RAG ì‹œìŠ¤í…œì— ë™ê¸°í™”í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                            success, message = sync_teammates_to_rag()
                            if success:
                                st.success(f"âœ… {message}")
                                st.session_state.chatbot.rag_system.build_index()
                            else:
                                st.error(f"âŒ {message}")
                with col3:
                    if st.button("ğŸ”„ ì™¸ë¶€ ë°ì´í„° ë™ê¸°í™”"):
                        with st.spinner("ì™¸ë¶€ ë°ì´í„° ì†ŒìŠ¤ì™€ ë™ê¸°í™”í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                            if st.session_state.chatbot.rag_system.sync_external_data_sources():
                                st.success("âœ… ì™¸ë¶€ ë°ì´í„° ì†ŒìŠ¤ ë™ê¸°í™” ì™„ë£Œ!")
                            else:
                                st.error("âŒ ì™¸ë¶€ ë°ì´í„° ì†ŒìŠ¤ ë™ê¸°í™” ì‹¤íŒ¨")
                
                # Ollama ëª¨ë¸ ì •ë³´ í‘œì‹œ
                if 'ollama' in st.session_state.chatbot.llm_client.get_available_providers():
                    st.markdown("### ğŸ¤– Ollama ëª¨ë¸ ì •ë³´")
                    try:
                        import requests
                        response = requests.get("http://localhost:11434/api/tags", timeout=5)
                        if response.status_code == 200:
                            models = response.json().get('models', [])
                            if models:
                                st.success(f"âœ… ì‚¬ìš© ê°€ëŠ¥í•œ Ollama ëª¨ë¸: {len(models)}ê°œ")
                                with st.expander("ğŸ“‹ ëª¨ë¸ ëª©ë¡"):
                                    for model in models:
                                        st.markdown(f"- **{model['name']}** (í¬ê¸°: {model.get('size', 'N/A')})")
                            else:
                                st.warning("âš ï¸ Ollamaì— ëª¨ë¸ì´ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
                        else:
                            st.error("âŒ Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    except Exception as e:
                        st.error(f"âŒ Ollama ëª¨ë¸ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
                
                # ìë™ ë™ê¸°í™” ìƒíƒœ í‘œì‹œ
                st.markdown("### ğŸ“Š ìë™ ë™ê¸°í™” ìƒíƒœ")
                col_status1, col_status2, col_status3 = st.columns(3)
                
                with col_status1:
                    if st.session_state.chatbot.rag_system.is_loaded:
                        st.success("âœ… RAG ì¸ë±ìŠ¤ ì¤€ë¹„ë¨")
                        st.info(f"ğŸ“š ë¬¸ì„œ ìˆ˜: {len(st.session_state.chatbot.rag_system.documents)}")
                    else:
                        st.error("âŒ RAG ì¸ë±ìŠ¤ ë¯¸ì¤€ë¹„")
                
                with col_status2:
                    try:
                        conn = connect_to_db()
                        cursor = conn.cursor()
                        cursor.execute("SELECT COUNT(*) FROM company_teammates")
                        teammate_count = cursor.fetchone()[0]
                        cursor.close()
                        conn.close()
                        st.success(f"âœ… íŒ€ë©”ì´íŠ¸ ë°ì´í„°: {teammate_count}ëª…")
                    except:
                        st.warning("âš ï¸ íŒ€ë©”ì´íŠ¸ í…Œì´ë¸” ì—†ìŒ")
                
                with col_status3:
                    try:
                        conn = connect_to_db()
                        cursor = conn.cursor()
                        cursor.execute("SELECT COUNT(*) FROM rag_files WHERE is_active = TRUE")
                        file_count = cursor.fetchone()[0]
                        cursor.close()
                        conn.close()
                        st.success(f"âœ… ì—…ë¡œë“œ íŒŒì¼: {file_count}ê°œ")
                    except:
                        st.warning("âš ï¸ íŒŒì¼ ë°ì´í„° ì—†ìŒ")
                
                # ìˆ˜ë™ ë¬¸ì„œ ê´€ë¦¬ (ê´€ë¦¬ì ì „ìš©)
                st.markdown("### ğŸ“ ìˆ˜ë™ ë¬¸ì„œ ê´€ë¦¬ (ê´€ë¦¬ì ì „ìš©)")
                with st.expander("â• ìƒˆ ë¬¸ì„œ ì¶”ê°€ (ìˆ˜ë™)"):
                    with st.form("manual_document_form"):
                        title = st.text_input("ë¬¸ì„œ ì œëª©*")
                        content = st.text_area("ë¬¸ì„œ ë‚´ìš©*", height=150)
                        document_type = st.selectbox("ë¬¸ì„œ ìœ í˜•", ["process", "regulation", "organization", "teammate", "inventory", "general"])
                        category = st.text_input("ì¹´í…Œê³ ë¦¬", placeholder="ì˜ˆ: project_management, approval, contact")
                        tags = st.text_input("íƒœê·¸", placeholder="ì‰¼í‘œë¡œ êµ¬ë¶„")
                        
                        submitted = st.form_submit_button("ë¬¸ì„œ ì¶”ê°€", type="primary")
                        
                        if submitted:
                            if title.strip() and content.strip():
                                if st.session_state.chatbot.rag_system.add_dynamic_document(
                                    title, content, document_type, category, tags, "manual"
                                ):
                                    st.success("âœ… ìˆ˜ë™ ë¬¸ì„œê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!")
                                    st.session_state.chatbot.rag_system.build_index()
                                    st.rerun()
                            else:
                                st.error("ì œëª©ê³¼ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

def verify_admin_password(input_password):
    """ê´€ë¦¬ì ë¹„ë°€ë²ˆí˜¸ í™•ì¸"""
    return input_password == os.getenv('ADMIN_PASSWORD')

def sync_teammates_to_rag():
    """company_teammates í…Œì´ë¸”ì˜ ë°ì´í„°ë¥¼ RAG ì‹œìŠ¤í…œì— ë™ê¸°í™”"""
    try:
        conn = connect_to_db()
        cursor = conn.cursor(dictionary=True)
        
        # í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        cursor.execute("SHOW TABLES LIKE 'company_teammates'")
        if not cursor.fetchone():
            cursor.close()
            conn.close()
            return False, "company_teammates í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
        
        # ê¸°ì¡´ íŒ€ë©”ì´íŠ¸ ë¬¸ì„œ ì‚­ì œ
        cursor.execute("""
            DELETE FROM rag_documents 
            WHERE document_type = 'teammate' AND tags = 'company_teammates'
        """)
        
        # íŒ€ë©”ì´íŠ¸ ë°ì´í„° ì¡°íšŒ
        cursor.execute("SELECT * FROM company_teammates")
        teammates = cursor.fetchall()
        
        if not teammates:
            conn.commit()
            cursor.close()
            conn.close()
            return True, "íŒ€ë©”ì´íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        # íŒ€ë©”ì´íŠ¸ ë°ì´í„°ë¥¼ RAG ë¬¸ì„œë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
        added_count = 0
        for teammate in teammates:
            # ìœ íš¨í•œ ë°ì´í„°ë§Œ ì¶”ì¶œ
            valid_data = {}
            for key, value in teammate.items():
                if key not in ['created_at', 'updated_at'] and value and str(value).strip():
                    valid_data[key] = str(value).strip()
            
            if valid_data:
                # ì œëª© ìƒì„±
                title = valid_data.get('ì„±ëª…', valid_data.get('ì´ë¦„', 'íŒ€ë©”ì´íŠ¸ ì •ë³´'))
                
                # ë‚´ìš© ìƒì„±
                content_parts = []
                for key, value in valid_data.items():
                    content_parts.append(f"{key}: {value}")
                content = "\n".join(content_parts)
                
                # ìƒˆë¡œ ì¶”ê°€
                cursor.execute("""
                    INSERT INTO rag_documents (title, content, document_type, category, tags)
                    VALUES (%s, %s, %s, %s, %s)
                """, (title, content, 'teammate', 'organization', 'company_teammates'))
                
                added_count += 1
        
        conn.commit()
        cursor.close()
        conn.close()
        
        return True, f"{added_count}ëª…ì˜ íŒ€ë©”ì´íŠ¸ ì •ë³´ê°€ RAG ì‹œìŠ¤í…œì— ë™ê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤."
        
    except Exception as e:
        return False, f"íŒ€ë©”ì´íŠ¸ ë™ê¸°í™” ì˜¤ë¥˜: {str(e)}"

if __name__ == "__main__":
    main() 