import streamlit as st
import mysql.connector
from datetime import datetime
import os
from dotenv import load_dotenv
from openai import OpenAI
import anthropic
import json
import base64
import requests
import graphviz
import traceback

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
openai = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

# Anthropic í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
anthropic_client = anthropic.Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ì˜ì‚¬ê²°ì • ì§€ì› ì‹œìŠ¤í…œ", page_icon="ï¿½ï¿½", layout="wide")

# === MCP-STYLE MODEL SELECTION & DEFAULTS ===
OUTPUT_TOKEN_INFO = {
    "claude-3-5-sonnet-latest": {"max_tokens": 8192},
    "claude-3-5-haiku-latest": {"max_tokens": 8192},
    "claude-3-7-sonnet-latest": {"max_tokens": 16384},
    "gpt-4o": {"max_tokens": 8192},
    "gpt-4o-mini": {"max_tokens": 8192},
}

# Model selection UI (MCP style)
has_anthropic_key = os.environ.get("ANTHROPIC_API_KEY") is not None
has_openai_key = os.environ.get("OPENAI_API_KEY") is not None
available_models = []
if has_anthropic_key:
    available_models.extend([
        "claude-3-7-sonnet-latest",
        "claude-3-5-sonnet-latest",
        "claude-3-5-haiku-latest",
    ])
if has_openai_key:
    available_models.extend(["gpt-4o", "gpt-4o-mini"])
if not available_models:
    available_models = ["claude-3-7-sonnet-latest"]

if 'selected_model' not in st.session_state:
    st.session_state.selected_model = 'claude-3-7-sonnet-latest'

def connect_to_db():
    """MySQL DB ì—°ê²°"""
    return mysql.connector.connect(
        user=os.getenv('SQL_USER'),
        password=os.getenv('SQL_PASSWORD'),
        host=os.getenv('SQL_HOST'),
        database=os.getenv('SQL_DATABASE_NEWBIZ'),
        charset='utf8mb4',
        collation='utf8mb4_unicode_ci'
    )

def save_decision_case(title, description, decision_maker, created_by):
    """ì˜ì‚¬ê²°ì • ì•ˆê±´ ì €ì¥"""
    conn = connect_to_db()
    cursor = conn.cursor()
    
    try:
        cursor.execute("""
            INSERT INTO decision_cases 
            (title, description, decision_maker, created_by)
            VALUES (%s, %s, %s, %s)
        """, (title, description, decision_maker, created_by))
        
        case_id = cursor.lastrowid
        conn.commit()
        return case_id
    except Exception as e:
        st.error(f"ì•ˆê±´ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None
    finally:
        cursor.close()
        conn.close()

def save_decision_option(case_id, option_data):
    """ì˜ì‚¬ê²°ì • ì˜µì…˜ ì €ì¥"""
    conn = connect_to_db()
    cursor = conn.cursor()
    
    try:
        cursor.execute("""
            INSERT INTO decision_options 
            (case_id, option_name, advantages, disadvantages, 
             estimated_duration, priority, additional_info)
            VALUES (%s, %s, %s, %s, %s, %s, %s)
        """, (
            case_id,
            option_data['name'],
            option_data['advantages'],
            option_data['disadvantages'],
            option_data['duration'],
            option_data['priority'],
            option_data.get('additional_info', '')
        ))
        
        conn.commit()
        return cursor.lastrowid
    finally:
        cursor.close()
        conn.close()

def save_ai_analysis(case_id, model_name, analysis_content, recommendation, risk_assessment):
    """AI ë¶„ì„ ê²°ê³¼ ì €ì¥"""
    conn = connect_to_db()
    cursor = conn.cursor()
    
    try:
        cursor.execute("""
            INSERT INTO decision_ai_analysis 
            (case_id, model_name, analysis_content, recommendation, risk_assessment)
            VALUES (%s, %s, %s, %s, %s)
        """, (case_id, model_name, analysis_content, recommendation, risk_assessment))
        
        conn.commit()
        return True
    except Exception as e:
        st.error(f"AI ë¶„ì„ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False
    finally:
        cursor.close()
        conn.close()

def get_decision_cases():
    """ì˜ì‚¬ê²°ì • ì•ˆê±´ ëª©ë¡ ì¡°íšŒ"""
    conn = connect_to_db()
    cursor = conn.cursor(dictionary=True)
    
    try:
        cursor.execute("""
            SELECT * FROM decision_cases 
            ORDER BY created_at DESC
        """)
        return cursor.fetchall()
    finally:
        cursor.close()
        conn.close()

def get_case_options(case_id):
    """ì•ˆê±´ì˜ ì˜µì…˜ ëª©ë¡ ì¡°íšŒ"""
    conn = connect_to_db()
    cursor = conn.cursor(dictionary=True)
    
    try:
        cursor.execute("""
            SELECT * FROM decision_options 
            WHERE case_id = %s 
            ORDER BY priority
        """, (case_id,))
        return cursor.fetchall()
    finally:
        cursor.close()
        conn.close()

def get_ai_analysis(case_id):
    """AI ë¶„ì„ ê²°ê³¼ ì¡°íšŒ"""
    conn = connect_to_db()
    cursor = conn.cursor(dictionary=True)
    
    try:
        cursor.execute("""
            SELECT * FROM decision_ai_analysis 
            WHERE case_id = %s 
            ORDER BY created_at DESC
        """, (case_id,))
        return cursor.fetchall()
    finally:
        cursor.close()
        conn.close()

def update_case_status(case_id, status, final_option_id, final_comment):
    """ì˜ì‚¬ê²°ì • ìƒíƒœ ì—…ë°ì´íŠ¸"""
    conn = connect_to_db()
    cursor = conn.cursor()
    
    try:
        cursor.execute("""
            UPDATE decision_cases 
            SET status = %s, 
                final_option_id = %s, 
                final_comment = %s,
                decided_at = NOW()
            WHERE case_id = %s
        """, (status, final_option_id, final_comment, case_id))
        
        conn.commit()
        return True
    except Exception as e:
        st.error(f"ìƒíƒœ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False
    finally:
        cursor.close()
        conn.close()

def read_markdown_file(uploaded_file):
    """ì—…ë¡œë“œëœ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì½ê¸°"""
    try:
        content = uploaded_file.read().decode('utf-8')
        return {
            'filename': uploaded_file.name,
            'content': content
        }
    except Exception as e:
        st.error(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")
        return None

def analyze_with_ai(title, description, options, reference_files=None, model_choice="claude-3-7-sonnet-latest"):
    """AI ë¶„ì„ ìˆ˜í–‰"""
    try:
        base_prompt = f"""
ë‹¤ìŒ ì˜ì‚¬ê²°ì • ì•ˆê±´ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

ì œëª©: {title}
ì„¤ëª…: {description}
"""
        if reference_files:
            base_prompt += "\nì¶”ê°€ ì°¸ê³  ìë£Œ:\n"
            for file in reference_files:
                base_prompt += f"""
íŒŒì¼ëª…: {file['filename']}
ë‚´ìš©:
{file['content']}
---
"""
        base_prompt += f"""
ì˜µì…˜ë“¤:
{json.dumps([{
    'ì´ë¦„': opt['name'],
    'ì¥ì ': opt['advantages'],
    'ë‹¨ì ': opt['disadvantages'],
    'ì˜ˆìƒê¸°ê°„': opt['duration'],
    'ìš°ì„ ìˆœìœ„': opt['priority']
} for opt in options], ensure_ascii=False, indent=2)}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. ê° ì˜µì…˜ë³„ ê°ê´€ì  ë¶„ì„
2. ê° ì˜µì…˜ì˜ ì‹¤í˜„ ê°€ëŠ¥ì„±ê³¼ ìœ„í—˜ë„
3. ìš°ì„ ìˆœìœ„ ì¶”ì²œê³¼ ê·¸ ì´ìœ 
4. ìµœì¢… ì¶”ì²œì•ˆê³¼ êµ¬ì²´ì ì¸ ì‹¤í–‰ ë°©ì•ˆ

ë¶„ì„ì‹œ ì œê³µëœ ëª¨ë“  ì •ë³´(ì„¤ëª… ë° ì¶”ê°€ ì°¸ê³  ìë£Œ)ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•´ì£¼ì„¸ìš”.
ë¶„ì„ì€ ê°ê´€ì ì´ê³  ì „ë¬¸ì ì¸ ê´€ì ì—ì„œ ìˆ˜í–‰í•´ì£¼ì„¸ìš”."""
        # Model logic
        if model_choice.startswith("gpt-4"):
            response = openai.chat.completions.create(
                model=model_choice,
                messages=[{"role": "user", "content": base_prompt}],
                temperature=0.7,
                max_tokens=OUTPUT_TOKEN_INFO.get(model_choice, {"max_tokens": 2000})["max_tokens"]
            )
            return response.choices[0].message.content
        else:  # Claude ëª¨ë¸ ì‚¬ìš©
            response = anthropic_client.messages.create(
                model=model_choice,
                max_tokens=OUTPUT_TOKEN_INFO.get(model_choice, {"max_tokens": 2000})["max_tokens"],
                messages=[{"role": "user", "content": base_prompt}]
            )
            return response.content[0].text
    except Exception as e:
        st.error(f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def delete_decision_case(case_id):
    """ì˜ì‚¬ê²°ì • ì•ˆê±´ ì‚­ì œ"""
    conn = connect_to_db()
    cursor = conn.cursor()
    
    try:
        # ì™¸ë˜ í‚¤ ì œì•½ ì¡°ê±´ìœ¼ë¡œ ì¸í•´ ìë™ìœ¼ë¡œ ê´€ë ¨ ì˜µì…˜ê³¼ AI ë¶„ì„ë„ ì‚­ì œë¨
        cursor.execute("""
            DELETE FROM decision_cases 
            WHERE case_id = %s
        """, (case_id,))
        
        conn.commit()
        return True
    except Exception as e:
        st.error(f"ì•ˆê±´ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False
    finally:
        cursor.close()
        conn.close()

def save_reference_file(case_id, filename, content):
    """ì°¸ê³  ìë£Œ íŒŒì¼ ì €ì¥"""
    conn = connect_to_db()
    cursor = conn.cursor()
    
    try:
        cursor.execute("""
            INSERT INTO decision_reference_files 
            (case_id, filename, file_content)
            VALUES (%s, %s, %s)
        """, (case_id, filename, content))
        
        conn.commit()
        return True
    except Exception as e:
        st.error(f"íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False
    finally:
        cursor.close()
        conn.close()

def get_reference_files(case_id):
    """ì°¸ê³  ìë£Œ íŒŒì¼ ì¡°íšŒ"""
    conn = connect_to_db()
    cursor = conn.cursor(dictionary=True)
    
    try:
        cursor.execute("""
            SELECT * FROM decision_reference_files 
            WHERE case_id = %s 
            ORDER BY created_at
        """, (case_id,))
        return cursor.fetchall()
    finally:
        cursor.close()
        conn.close()

def perform_perplexity_search(query, debug_mode=False):
    """Perplexity APIë¥¼ ì‚¬ìš©í•œ ê²€ìƒ‰ ìˆ˜í–‰"""
    api_key = os.getenv('PERPLEXITY_API_KEY')
    if not api_key:
        st.error("Perplexity API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None

    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    url = "https://api.perplexity.ai/chat/completions"
    
    data = {
        "model": "sonar",
        "messages": [
            {
                "role": "system",
                "content": "Be precise, professional, and analytical in your responses. Always include sources when available."
            },
            {
                "role": "user",
                "content": query
            }
        ]
    }
    
    if debug_mode:
        st.write("=== API ìš”ì²­ ë””ë²„ê·¸ ì •ë³´ ===")
        st.write("URL:", url)
        st.write("Headers:", {k: v if k != 'Authorization' else f'Bearer {api_key[:8]}...' for k, v in headers.items()})
        st.write("Request Data:", json.dumps(data, indent=2, ensure_ascii=False))
    
    try:
        response = requests.post(url, headers=headers, json=data)
        
        if debug_mode:
            st.write("\n=== API ì‘ë‹µ ë””ë²„ê·¸ ì •ë³´ ===")
            st.write(f"Status Code: {response.status_code}")
            st.write("Response Headers:", dict(response.headers))
            try:
                response_data = response.json()
                st.write("Response JSON:", json.dumps(response_data, indent=2, ensure_ascii=False))
            except:
                st.write("Raw Response:", response.text)
        
        if response.status_code != 200:
            error_msg = f"API ì˜¤ë¥˜ (ìƒíƒœ ì½”ë“œ: {response.status_code})"
            try:
                error_data = response.json()
                if 'error' in error_data:
                    error_msg += f"\nì˜¤ë¥˜ ë‚´ìš©: {error_data['error']}"
            except:
                error_msg += f"\nì‘ë‹µ ë‚´ìš©: {response.text}"
            st.error(error_msg)
            return None
        
        result = response.json()
        
        # ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ì™€ ì¶œì²˜ ì¶”ì¶œ
        if 'choices' in result and len(result['choices']) > 0:
            content = result['choices'][0]['message']['content']
            
            # ì¶œì²˜ ì •ë³´ê°€ ìˆëŠ” ê²½ìš° ë³„ë„ë¡œ í‘œì‹œ
            sources = []
            if 'sources' in result['choices'][0]['message']:
                sources = result['choices'][0]['message']['sources']
            
            # ì¶œì²˜ ì •ë³´ê°€ ë³¸ë¬¸ì— í¬í•¨ëœ ê²½ìš° (URLì´ë‚˜ ì°¸ì¡° í˜•ì‹ìœ¼ë¡œ)
            source_section = "\n\n**ì¶œì²˜:**"
            if sources:
                source_section += "\n" + "\n".join([f"- {source}" for source in sources])
            elif "[" in content and "]" in content:  # ë³¸ë¬¸ì— ì°¸ì¡° í˜•ì‹ìœ¼ë¡œ í¬í•¨ëœ ê²½ìš°
                import re
                citations = re.findall(r'\[(.*?)\]', content)
                if citations:
                    source_section += "\n" + "\n".join([f"- {citation}" for citation in citations])
            
            # URL í˜•ì‹ì˜ ì¶œì²˜ ì¶”ì¶œ
            urls = re.findall(r'https?://(?:[-\w.]|(?:%[\da-fA-F]{2}))+[^\s)"\']', content)
            if urls:
                if source_section == "\n\n**ì¶œì²˜:**":
                    source_section += "\n" + "\n".join([f"- {url}" for url in urls])
            
            # ì¶œì²˜ ì •ë³´ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì¶”ê°€
            if source_section != "\n\n**ì¶œì²˜:**":
                return content + source_section
            return content
            
        return None
        
    except requests.exceptions.RequestException as e:
        st.error(f"Perplexity API ìš”ì²­ ì‹¤íŒ¨: {str(e)}")
        if debug_mode:
            st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return None
    except Exception as e:
        st.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        if debug_mode:
            st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return None

def get_agent_tools(agent_type):
    """ì—ì´ì „íŠ¸ë³„ íŠ¹í™” ë„êµ¬ ë°˜í™˜"""
    tools = {
        'financial_agent': """
ì¬ë¬´ ë¶„ì„ ë„êµ¬:
1. ROI ê³„ì‚°ê¸°: íˆ¬ììˆ˜ìµë¥  = (ìˆœì´ìµ - ì´ˆê¸°íˆ¬ì) / ì´ˆê¸°íˆ¬ì Ã— 100
2. NPV ê³„ì‚°: ìˆœí˜„ì¬ê°€ì¹˜ = Î£(ë¯¸ë˜í˜„ê¸ˆíë¦„ / (1 + í• ì¸ìœ¨)^t)
3. ì†ìµë¶„ê¸°ì  ë¶„ì„: BEP = ê³ ì •ë¹„ìš© / (ë‹¨ìœ„ë‹¹ ë§¤ì¶œ - ë‹¨ìœ„ë‹¹ ë³€ë™ë¹„)
4. í˜„ê¸ˆíë¦„ ë¶„ì„: ì˜ì—…í™œë™, íˆ¬ìí™œë™, ì¬ë¬´í™œë™ í˜„ê¸ˆíë¦„ êµ¬ë¶„
5. ì¬ë¬´ë¹„ìœ¨ ë¶„ì„: ìœ ë™ì„±, ìˆ˜ìµì„±, ì•ˆì •ì„± ë¹„ìœ¨ ê³„ì‚°

ë¶„ì„ì‹œ ìœ„ ë„êµ¬ë“¤ì„ í™œìš©í•˜ì—¬ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ í•¨ê»˜ ë¶„ì„í•´ì£¼ì„¸ìš”.
""",
        'legal_agent': f"""
ë²•ë¥  ê²€í†  ë„êµ¬:
1. ê·œì œ ì¤€ìˆ˜ì„± ì²´í¬ë¦¬ìŠ¤íŠ¸
   - ê´€ë ¨ ë²•ê·œ ë° ê·œì œ ì‹ë³„
   - ì¸í—ˆê°€ ìš”ê±´ í™•ì¸
   - ì˜ë¬´ì‚¬í•­ ì ê²€
2. ê³„ì•½ ìœ„í—˜ë„ í‰ê°€ ë§¤íŠ¸ë¦­ìŠ¤
3. ë²•ì  ì±…ì„ ë²”ìœ„ ë¶„ì„
4. ì§€ì ì¬ì‚°ê¶Œ ê²€í†  ë„êµ¬
5. ê·œì œ ë³€í™” ì˜í–¥ë„ í‰ê°€
6. ì‹¤ì‹œê°„ ë²•ë¥  ê²€ìƒ‰: Perplexity APIë¥¼ í†µí•œ ìµœì‹  ë²•ë¥ /ê·œì œ ì •ë³´ ì¡°íšŒ

ê° ë„êµ¬ë¥¼ í™œìš©í•˜ì—¬ ë²•ì  ë¦¬ìŠ¤í¬ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.
ì‹¤ì‹œê°„ ê²€ìƒ‰ ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ ìµœì‹  ë²•ë¥  ë° ê·œì œ ë™í–¥ì„ ë¶„ì„ì— ë°˜ì˜í•´ì£¼ì„¸ìš”.
""",
        'market_agent': f"""
ì‹œì¥ ë¶„ì„ ë„êµ¬:
1. PEST ë¶„ì„: ì •ì¹˜, ê²½ì œ, ì‚¬íšŒ, ê¸°ìˆ  ìš”ì¸ ë¶„ì„
2. 5-Forces ë¶„ì„: ì‚°ì—… ë‚´ ê²½ìŸ êµ¬ì¡° ë¶„ì„
3. SWOT ë¶„ì„: ê°•ì , ì•½ì , ê¸°íšŒ, ìœ„í˜‘ ìš”ì¸ ë¶„ì„
4. ì‹œì¥ ì„¸ë¶„í™” ë„êµ¬: ê³ ê° ê·¸ë£¹ ë¶„ë¥˜ ë° íŠ¹ì„± ë¶„ì„
5. ê²½ìŸì‚¬ ë§¤í•‘: ì£¼ìš” ê²½ìŸì‚¬ í¬ì§€ì…”ë‹ ë¶„ì„
6. TAM-SAM-SOM ë¶„ì„: ì‹œì¥ ê·œëª¨ ì¶”ì •
7. ì‹¤ì‹œê°„ ì‹œì¥ ê²€ìƒ‰: Perplexity APIë¥¼ í†µí•œ ìµœì‹  ì‹œì¥ ë™í–¥ ì¡°ì‚¬

ê° ë¶„ì„ ë„êµ¬ë¥¼ í™œìš©í•˜ì—¬ ì‹œì¥ ê¸°íšŒì™€ ìœ„í—˜ì„ êµ¬ì²´ì ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”.
ì‹¤ì‹œê°„ ê²€ìƒ‰ ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ ìµœì‹  ì‹œì¥ ë™í–¥ì„ ë¶„ì„ì— ë°˜ì˜í•´ì£¼ì„¸ìš”.
""",
        'risk_agent': """
ë¦¬ìŠ¤í¬ ê´€ë¦¬ ë„êµ¬:
1. ë¦¬ìŠ¤í¬ ë§¤íŠ¸ë¦­ìŠ¤: ë°œìƒê°€ëŠ¥ì„±ê³¼ ì˜í–¥ë„ í‰ê°€
2. ë¦¬ìŠ¤í¬ íˆíŠ¸ë§µ: ë¦¬ìŠ¤í¬ ìš°ì„ ìˆœìœ„ ì‹œê°í™”
3. ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„: ìµœì„ /ìµœì•…/ê¸°ë³¸ ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„
4. ë¯¼ê°ë„ ë¶„ì„: ì£¼ìš” ë³€ìˆ˜ë³„ ì˜í–¥ë„ ë¶„ì„
5. ë¦¬ìŠ¤í¬ ì™„í™” ì „ëµ í…œí”Œë¦¿
6. ë¹„ìƒ ëŒ€ì‘ ê³„íš ìˆ˜ë¦½ ë„êµ¬

ê° ë„êµ¬ë¥¼ í™œìš©í•˜ì—¬ ì¢…í•©ì ì¸ ë¦¬ìŠ¤í¬ í‰ê°€ì™€ ëŒ€ì‘ ë°©ì•ˆì„ ì œì‹œí•´ì£¼ì„¸ìš”.
""",
        'tech_agent': """
ê¸°ìˆ  ë¶„ì„ ë„êµ¬:
1. ê¸°ìˆ  ì„±ìˆ™ë„ í‰ê°€(TRL) ë§¤íŠ¸ë¦­ìŠ¤
2. ê¸°ìˆ  ë¡œë“œë§µ ì‘ì„± ë„êµ¬
3. ê¸°ìˆ  ê²©ì°¨ ë¶„ì„(Gap Analysis)
4. ê¸°ìˆ  ì˜ì¡´ì„± ë§¤í•‘
5. êµ¬í˜„ ë³µì¡ë„ í‰ê°€
6. ê¸°ìˆ  ë¶€ì±„ ë¶„ì„
7. í™•ì¥ì„± í‰ê°€ ë„êµ¬

ê° ë„êµ¬ë¥¼ í™œìš©í•˜ì—¬ ê¸°ìˆ ì  ì‹¤í˜„ ê°€ëŠ¥ì„±ê³¼ ì œì•½ì‚¬í•­ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.
""",
        'hr_agent': """
ì¸ì‚¬/ì¡°ì§ ë¶„ì„ ë„êµ¬:
1. ì¡°ì§ ì˜í–¥ë„ í‰ê°€ ë§¤íŠ¸ë¦­ìŠ¤
2. ì¸ë ¥ ìˆ˜ìš” ì˜ˆì¸¡ ëª¨ë¸
3. ìŠ¤í‚¬ ê°­ ë¶„ì„ ë„êµ¬
4. ì¡°ì§ ë¬¸í™” ì˜í–¥ë„ í‰ê°€
5. ë³€í™” ê´€ë¦¬ ì¤€ë¹„ë„ í‰ê°€
6. êµìœ¡/í›ˆë ¨ ë‹ˆì¦ˆ ë¶„ì„

ê° ë„êµ¬ë¥¼ í™œìš©í•˜ì—¬ ì¸ì  ìì›ê³¼ ì¡°ì§ì  ì¸¡ë©´ì˜ ì˜í–¥ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.
""",
        'operation_agent': """
ìš´ì˜ ë¶„ì„ ë„êµ¬:
1. í”„ë¡œì„¸ìŠ¤ ë§¤í•‘ ë„êµ¬
2. ìš´ì˜ íš¨ìœ¨ì„± í‰ê°€ ë§¤íŠ¸ë¦­ìŠ¤
3. ìì› í• ë‹¹ ìµœì í™” ëª¨ë¸
4. ë³‘ëª© êµ¬ê°„ ë¶„ì„
5. í’ˆì§ˆ ê´€ë¦¬ ë„êµ¬
6. ìš´ì˜ ë¹„ìš© ë¶„ì„
7. ìƒì‚°ì„± ì¸¡ì • ë„êµ¬

ê° ë„êµ¬ë¥¼ í™œìš©í•˜ì—¬ ìš´ì˜ìƒì˜ íš¨ìœ¨ì„±ê³¼ ì‹¤í–‰ ê°€ëŠ¥ì„±ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.
""",
        'strategy_agent': """
ì „ëµ ë¶„ì„ ë„êµ¬:
1. ì „ëµì  ì í•©ì„± í‰ê°€ ë§¤íŠ¸ë¦­ìŠ¤
2. ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ ìº”ë²„ìŠ¤
3. ê°€ì¹˜ ì‚¬ìŠ¬ ë¶„ì„
4. í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„(BCG ë§¤íŠ¸ë¦­ìŠ¤)
5. ì‹œë‚˜ë¦¬ì˜¤ í”Œë˜ë‹
6. ì „ëµ ì‹¤í–‰ ë¡œë“œë§µ
7. í•µì‹¬ ì„±ê³µ ìš”ì¸(CSF) ë¶„ì„

ê° ë„êµ¬ë¥¼ í™œìš©í•˜ì—¬ ì „ëµì  íƒ€ë‹¹ì„±ê³¼ ì¥ê¸°ì  ì˜í–¥ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.
"""
    }
    return tools.get(agent_type, "")

def analyze_with_agents(title, description, options, reference_files, active_agents, debug_mode=False, model_name="claude-3-7-sonnet-latest"):
    """ë©€í‹° ì—ì´ì „íŠ¸ ë¶„ì„ ìˆ˜í–‰"""
    try:
        results = {}
        simplified_options = [{
            'name': opt['name'],
            'advantages': opt.get('advantages', ''),
            'disadvantages': opt.get('disadvantages', ''),
            'duration': opt['duration'],
            'priority': opt['priority']
        } for opt in options]
        for agent_type, is_active in active_agents.items():
            if not is_active or agent_type == 'integration_agent':
                continue
            if debug_mode:
                st.write(f"ğŸ¤– {agent_type} ë¶„ì„ ì‹œì‘...")
            agent_tools = get_agent_tools(agent_type)
            additional_info = ""
            if agent_type == 'market_agent':
                market_search = perform_perplexity_search(
                    f"""ë‹¤ìŒ ì£¼ì œì— ëŒ€í•œ ìµœì‹  ì‹œì¥ ë™í–¥ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:\nì œëª©: {title}\nì„¤ëª…: {description[:200]}\në¶„ì„ ê´€ì :\n1. ì‹œì¥ ê·œëª¨ì™€ ì„±ì¥ì„±\n2. ì£¼ìš” ê²½ìŸì‚¬ í˜„í™©\n3. ìµœê·¼ íŠ¸ë Œë“œì™€ ë³€í™”\n4. ì ì¬ì  ê¸°íšŒì™€ ìœ„í—˜ ìš”ì†Œ""",
                    debug_mode
                )
                if market_search:
                    additional_info = f"\n\n[ì‹¤ì‹œê°„ ì‹œì¥ ë™í–¥ ë¶„ì„]\n{market_search}"
            elif agent_type == 'legal_agent':
                legal_search = perform_perplexity_search(
                    f"""ë‹¤ìŒ ì£¼ì œì™€ ê´€ë ¨ëœ ë²•ë¥  ë° ê·œì œ ì‚¬í•­ì„ ê²€í† í•´ì£¼ì„¸ìš”:\nì œëª©: {title}\nì„¤ëª…: {description[:200]}\nê²€í†  ê´€ì :\n1. ê´€ë ¨ ë²•ê·œ ë° ê·œì œ í˜„í™©\n2. í•„ìš”í•œ ì¸í—ˆê°€ ì‚¬í•­\n3. ì ì¬ì  ë²•ì  ë¦¬ìŠ¤í¬\n4. ê·œì œ ì¤€ìˆ˜ë¥¼ ìœ„í•œ ìš”êµ¬ì‚¬í•­""",
                    debug_mode
                )
                if legal_search:
                    additional_info = f"\n\n[ì‹¤ì‹œê°„ ë²•ë¥ /ê·œì œ ë¶„ì„]\n{legal_search}"
            base_prompt = f"""
ë‹¹ì‹ ì€ {agent_type.replace('_', ' ').title()} ì…ë‹ˆë‹¤.
ë‹¤ìŒ ì˜ì‚¬ê²°ì • ì•ˆê±´ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

ì œëª©: {title}
ì„¤ëª…: {description[:1000]}...

[ë¶„ì„ ë„êµ¬]
{agent_tools}

[íŠ¹ë³„ ë¶„ì„ ì§€ì¹¨]
ì´ë²ˆ ë¶„ì„ì—ì„œëŠ” ë‹¤ìŒ ì‚¬í•­ì„ íŠ¹íˆ ì¤‘ì ì ìœ¼ë¡œ ê³ ë ¤í•´ì£¼ì„¸ìš”:
{description[1000:] if len(description) > 1000 else 'ì¼ë°˜ì ì¸ ê´€ì ì—ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”.'}
{additional_info}

ì˜µì…˜ ê°œìš”:
{json.dumps(simplified_options, ensure_ascii=False, indent=2)}

ë¶„ì„ ê²°ê³¼ì—ëŠ” ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ì˜ flowchartë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”:

```mermaid
graph LR
    A[ì£¼ìš” ì˜µì…˜] --> B[ì˜í–¥ 1]
    A --> C[ì˜í–¥ 2]
    B --> D[ê²°ê³¼ 1]
    C --> E[ê²°ê³¼ 2]
```

ìœ„ í˜•ì‹ì„ ì°¸ê³ í•˜ì—¬ ì‹¤ì œ ë¶„ì„ ë‚´ìš©ì— ë§ëŠ” flowchartë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
ê° ë…¸ë“œëŠ” ëª…í™•í•œ ì„¤ëª…ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.

ë°˜ë“œì‹œ ì œê³µëœ ë¶„ì„ ë„êµ¬ë“¤ì„ í™œìš©í•˜ì—¬ êµ¬ì²´ì ì´ê³  ì •ëŸ‰ì ì¸ ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”.
"""
            detail_prompt = f"""
            ì˜µì…˜ ìƒì„¸:
            {json.dumps(options, ensure_ascii=False, indent=2)}
            """
            try:
                if model_name.startswith("claude"):
                    response = anthropic_client.messages.create(
                        model=model_name,
                        max_tokens=OUTPUT_TOKEN_INFO.get(model_name, {"max_tokens": 2000})["max_tokens"],
                        messages=[{
                            "role": "user",
                            "content": base_prompt
                        }]
                    )
                    analysis_content = response.content[0].text
                else:
                    response = openai.chat.completions.create(
                        model=model_name,
                        messages=[{
                            "role": "user",
                            "content": base_prompt
                        }],
                        temperature=0.7,
                        max_tokens=OUTPUT_TOKEN_INFO.get(model_name, {"max_tokens": 2000})["max_tokens"]
                    )
                    analysis_content = response.choices[0].message.content
                if model_name.startswith("claude"):
                    detail_response = anthropic_client.messages.create(
                        model=model_name,
                        max_tokens=OUTPUT_TOKEN_INFO.get(model_name, {"max_tokens": 2000})["max_tokens"],
                        messages=[{
                            "role": "user",
                            "content": detail_prompt
                        }]
                    )
                    detail_content = detail_response.content[0].text
                else:
                    detail_response = openai.chat.completions.create(
                        model=model_name,
                        messages=[{
                            "role": "user",
                            "content": detail_prompt
                        }],
                        temperature=0.7,
                        max_tokens=OUTPUT_TOKEN_INFO.get(model_name, {"max_tokens": 2000})["max_tokens"]
                    )
                    detail_content = detail_response.choices[0].message.content
                combined_analysis = f"""
                ê¸°ë³¸ ë¶„ì„:
                {analysis_content}

                ìƒì„¸ ë¶„ì„:
                {detail_content}
                """
                results[agent_type] = {
                    'analysis': combined_analysis,
                    'recommendations': extract_recommendations(combined_analysis),
                    'risk_assessment': extract_risk_assessment(combined_analysis)
                }
            except Exception as e:
                st.error(f"{agent_type} ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                if debug_mode:
                    st.write(f"ì˜¤ë¥˜ ìƒì„¸: {traceback.format_exc()}")
                results[agent_type] = {
                    'analysis': f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}",
                    'recommendations': [],
                    'risk_assessment': []
                }
        if active_agents.get('integration_agent', False):
            integration_prompt = f"""
            ë‹¤ìŒì€ ê° ì „ë¬¸ê°€ ì—ì´ì „íŠ¸ì˜ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤. ì´ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ìµœì¢… ê¶Œê³ ì•ˆì„ ë„ì¶œí•´ì£¼ì„¸ìš”:

            {json.dumps(results, ensure_ascii=False, indent=2)}

            ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
            1. ì¢…í•© ë¶„ì„
            2. ìµœì¢… ê¶Œê³ ì•ˆ
            3. ì£¼ìš” ë¦¬ìŠ¤í¬ ë° ëŒ€ì‘ ë°©ì•ˆ
            4. ì‹¤í–‰ ë¡œë“œë§µ
            """
            if model_name.startswith("claude"):
                integration_response = anthropic_client.messages.create(
                    model=model_name,
                    max_tokens=OUTPUT_TOKEN_INFO.get(model_name, {"max_tokens": 2000})["max_tokens"],
                    messages=[{
                        "role": "user",
                        "content": integration_prompt
                    }]
                )
                results['integration'] = {
                    'analysis': integration_response.content[0].text,
                    'recommendations': extract_recommendations(integration_response.content[0].text),
                    'risk_assessment': extract_risk_assessment(integration_response.content[0].text)
                }
            else:
                integration_response = openai.chat.completions.create(
                    model=model_name,
                    messages=[{
                        "role": "user",
                        "content": integration_prompt
                    }],
                    temperature=0.7,
                    max_tokens=OUTPUT_TOKEN_INFO.get(model_name, {"max_tokens": 2000})["max_tokens"]
                )
                results['integration'] = {
                    'analysis': integration_response.choices[0].message.content,
                    'recommendations': extract_recommendations(integration_response.choices[0].message.content),
                    'risk_assessment': extract_risk_assessment(integration_response.choices[0].message.content)
                }
        return results
    except Exception as e:
        st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        if debug_mode:
            st.write(f"ì˜¤ë¥˜ ìƒì„¸: {traceback.format_exc()}")
        return {"error": str(e)}

def delete_ai_analysis(case_id):
    """ê¸°ì¡´ AI ë¶„ì„ ê²°ê³¼ ì‚­ì œ"""
    conn = connect_to_db()
    cursor = conn.cursor()
    
    try:
        cursor.execute("""
            DELETE FROM decision_ai_analysis 
            WHERE case_id = %s
        """, (case_id,))
        
        conn.commit()
        return True
    except Exception as e:
        st.error(f"AI ë¶„ì„ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False
    finally:
        cursor.close()
        conn.close()

def format_options_for_analysis(options):
    """ë°ì´í„°ë² ì´ìŠ¤ ì˜µì…˜ì„ AI ë¶„ì„ìš© í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    return [{
        'name': opt['option_name'],
        'advantages': opt['advantages'],
        'disadvantages': opt['disadvantages'],
        'duration': opt['estimated_duration'],
        'priority': opt['priority'],
        'additional_info': opt.get('additional_info', '')
    } for opt in options]

def generate_recommendation(agent_type, options):
    """ì—ì´ì „íŠ¸ë³„ ì¶”ì²œ ì˜ê²¬ ìƒì„±"""
    try:
        prompt = f"""
        {agent_type.replace('_', ' ').title()} ê´€ì ì—ì„œ ë‹¤ìŒ ì˜µì…˜ë“¤ ì¤‘ 
        ê°€ì¥ ì¶”ì²œí•  ë§Œí•œ ì˜µì…˜ê³¼ ê·¸ ì´ìœ ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”:

        ì˜µì…˜ë“¤:
        {json.dumps([{
            'ì´ë¦„': opt['name'],
            'ìš°ì„ ìˆœìœ„': opt['priority'],
            'ì˜ˆìƒê¸°ê°„': opt['duration']
        } for opt in options], ensure_ascii=False, indent=2)}

        ë¶„ì„ ê²°ê³¼ë¥¼ Mermaid ì°¨íŠ¸ë¡œ í‘œí˜„í•´ì£¼ì„¸ìš”.
        ì˜ˆì‹œ:
        ```mermaid
        graph TD
            A[ìµœìš°ì„  ì¶”ì²œ] --> B[ì˜µì…˜ëª…]
            B --> C[ì£¼ìš” ì´ìœ  1]
            B --> D[ì£¼ìš” ì´ìœ  2]
        ```
        """

        response = openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7
        )

        return response.choices[0].message.content
    except Exception as e:
        st.error(f"ì¶”ì²œ ì˜ê²¬ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return "ì¶”ì²œ ì˜ê²¬ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

def generate_risk_assessment(agent_type, options):
    """ì—ì´ì „íŠ¸ë³„ ìœ„í—˜ë„ í‰ê°€ ìƒì„±"""
    try:
        prompt = f"""
        {agent_type.replace('_', ' ').title()} ê´€ì ì—ì„œ ë‹¤ìŒ ì˜µì…˜ë“¤ì˜ 
        ìœ„í—˜ ìš”ì†Œë¥¼ ë¶„ì„í•˜ê³  ëŒ€ì‘ ë°©ì•ˆì„ ì œì‹œí•´ì£¼ì„¸ìš”:

        ì˜µì…˜ë“¤:
        {json.dumps([{
            'ì´ë¦„': opt['name'],
            'ìš°ì„ ìˆœìœ„': opt['priority'],
            'ì˜ˆìƒê¸°ê°„': opt['duration']
        } for opt in options], ensure_ascii=False, indent=2)}

        ë¶„ì„ ê²°ê³¼ë¥¼ Mermaid ì°¨íŠ¸ë¡œ í‘œí˜„í•´ì£¼ì„¸ìš”.
        ì˜ˆì‹œ:
        ```mermaid
        graph TD
            A[ìœ„í—˜ ìš”ì†Œ] --> B[ìœ„í—˜ 1]
            A --> C[ìœ„í—˜ 2]
            B --> D[ëŒ€ì‘ ë°©ì•ˆ 1]
            C --> E[ëŒ€ì‘ ë°©ì•ˆ 2]
        ```
        """

        response = openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7
        )

        return response.choices[0].message.content
    except Exception as e:
        st.error(f"ìœ„í—˜ë„ í‰ê°€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return "ìœ„í—˜ë„ í‰ê°€ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

def mermaid_to_graphviz(mermaid_code):
    """Mermaid ì½”ë“œë¥¼ Graphvizë¡œ ë³€í™˜"""
    try:
        # Mermaid ì½”ë“œì—ì„œ ë…¸ë“œì™€ ì—£ì§€ ì¶”ì¶œ
        import re
        
        # flowchart/graph í˜•ì‹ íŒŒì‹±
        nodes = {}
        edges = []
        
        # ë…¸ë“œ ì •ì˜ ì°¾ê¸° (ì˜ˆ: A[ë‚´ìš©])
        node_pattern = r'([A-Za-z0-9_]+)\[(.*?)\]'
        for match in re.finditer(node_pattern, mermaid_code):
            node_id, node_label = match.groups()
            nodes[node_id] = node_label
        
        # ì—£ì§€ ì •ì˜ ì°¾ê¸° (ì˜ˆ: A --> B)
        edge_pattern = r'([A-Za-z0-9_]+)\s*-->\s*([A-Za-z0-9_]+)'
        edges = re.findall(edge_pattern, mermaid_code)
        
        # Graphviz ê°ì²´ ìƒì„±
        dot = graphviz.Digraph()
        dot.attr(rankdir='LR')  # ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ë°©í–¥ ì„¤ì •
        
        # ë…¸ë“œ ì¶”ê°€
        for node_id, node_label in nodes.items():
            dot.node(node_id, node_label)
        
        # ì—£ì§€ ì¶”ê°€
        for src, dst in edges:
            dot.edge(src, dst)
        
        return dot
    except Exception as e:
        st.error(f"ì°¨íŠ¸ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def extract_recommendations(text):
    """í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì²œ ì‚¬í•­ ì¶”ì¶œ"""
    recommendations = []
    lines = text.split('\n')
    in_recommendations = False
    
    for line in lines:
        line = line.strip()
        # ì¶”ì²œ ì‚¬í•­ ì„¹ì…˜ ì‹œì‘ í™•ì¸
        if 'ì¶”ì²œ' in line or 'recommendation' in line.lower():
            in_recommendations = True
            continue
        # ë‹¤ìŒ ì„¹ì…˜ ì‹œì‘ í™•ì¸
        if line and line.startswith('#') or line.startswith('=='):
            in_recommendations = False
        # ì¶”ì²œ ì‚¬í•­ ìˆ˜ì§‘
        if in_recommendations and line and not line.startswith('#'):
            recommendations.append(line)
    
    # ì¶”ì²œ ì‚¬í•­ì´ ì—†ìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ ë°˜í™˜
    return '\n'.join(recommendations) if recommendations else text

def extract_risk_assessment(text):
    """í…ìŠ¤íŠ¸ì—ì„œ ìœ„í—˜ í‰ê°€ ì¶”ì¶œ"""
    risks = []
    lines = text.split('\n')
    in_risks = False
    
    for line in lines:
        line = line.strip()
        # ìœ„í—˜ í‰ê°€ ì„¹ì…˜ ì‹œì‘ í™•ì¸
        if 'ìœ„í—˜' in line or 'risk' in line.lower():
            in_risks = True
            continue
        # ë‹¤ìŒ ì„¹ì…˜ ì‹œì‘ í™•ì¸
        if line and line.startswith('#') or line.startswith('=='):
            in_risks = False
        # ìœ„í—˜ í‰ê°€ ìˆ˜ì§‘
        if in_risks and line and not line.startswith('#'):
            risks.append(line)
    
    # ìœ„í—˜ í‰ê°€ê°€ ì—†ìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ ë°˜í™˜
    return '\n'.join(risks) if risks else text

def display_mermaid_chart(markdown_text):
    """Mermaid ì°¨íŠ¸ê°€ í¬í•¨ëœ ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ë¥¼ í‘œì‹œ"""
    if not isinstance(markdown_text, str):
        st.warning("ì°¨íŠ¸ ë°ì´í„°ê°€ ë¬¸ìì—´ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
        return
        
    import re
    mermaid_pattern = r"```mermaid\n(.*?)\n```"
    
    # ì¼ë°˜ ë§ˆí¬ë‹¤ìš´ê³¼ Mermaid ì°¨íŠ¸ ë¶„ë¦¬
    parts = re.split(mermaid_pattern, markdown_text, flags=re.DOTALL)
    
    for i, part in enumerate(parts):
        if i % 2 == 0:  # ì¼ë°˜ ë§ˆí¬ë‹¤ìš´
            if part.strip():
                st.markdown(part)
        else:  # Mermaid ì°¨íŠ¸
            # Graphvizë¡œ ë³€í™˜í•˜ì—¬ í‘œì‹œ
            dot = mermaid_to_graphviz(part)
            if dot:
                st.graphviz_chart(dot)
            else:
                # ë³€í™˜ ì‹¤íŒ¨ ì‹œ ì½”ë“œ í‘œì‹œ
                st.code(part, language="mermaid")

def get_short_model_name(model_name):
    """ê¸´ ëª¨ë¸ ì´ë¦„ì„ ì§§ì€ ë²„ì „ìœ¼ë¡œ ë³€í™˜"""
    model_mapping = {
        "claude-3-7-sonnet-latest": "claude-3.7",
        "gpt-4o-mini": "gpt-4o-mini"
    }
    return model_mapping.get(model_name, model_name)

def main():
    st.title("ğŸ¯ ì˜ì‚¬ê²°ì • ì§€ì› ì‹œìŠ¤í…œ")
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'current_case_id' not in st.session_state:
        st.session_state.current_case_id = None
    if 'ai_analysis_results' not in st.session_state:
        st.session_state.ai_analysis_results = {}
    if 'options' not in st.session_state:
        st.session_state.options = []

    # ë””ë²„ê·¸ ëª¨ë“œ ì„¤ì •
    debug_mode = st.sidebar.checkbox(
        "ë””ë²„ê·¸ ëª¨ë“œ",
        help="ì—ì´ì „íŠ¸ì™€ íƒœìŠ¤í¬ì˜ ì‹¤í–‰ ê³¼ì •ì„ ìì„¸íˆ í‘œì‹œí•©ë‹ˆë‹¤.",
        value=False
    )
    
    # AI ì—ì´ì „íŠ¸ ì„¤ì •
    with st.expander("ğŸ¤– AI ì—ì´ì „íŠ¸ ì„¤ì •"):
        st.subheader("í™œì„±í™”í•  ì—ì´ì „íŠ¸")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            financial_agent = st.checkbox("ì¬ë¬´ ì „ë¬¸ê°€", value=True)
            legal_agent = st.checkbox("ë²•ë¥  ì „ë¬¸ê°€", value=True)
            market_agent = st.checkbox("ì‹œì¥ ë¶„ì„ê°€", value=True)
            
        with col2:
            risk_agent = st.checkbox("ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì „ë¬¸ê°€", value=True)
            tech_agent = st.checkbox("ê¸°ìˆ  ì „ë¬¸ê°€", value=True)
            hr_agent = st.checkbox("ì¸ì‚¬/ì¡°ì§ ì „ë¬¸ê°€", value=True)
            
        with col3:
            operation_agent = st.checkbox("ìš´ì˜ ì „ë¬¸ê°€", value=True)
            strategy_agent = st.checkbox("ì „ëµ ì „ë¬¸ê°€", value=True)
            integration_agent = st.checkbox("í†µí•© ë§¤ë‹ˆì €", value=True, disabled=True)

    # í™œì„±í™”ëœ ì—ì´ì „íŠ¸ ì •ë³´ ì €ì¥
    active_agents = {
        'financial_agent': financial_agent,
        'legal_agent': legal_agent,
        'market_agent': market_agent,
        'risk_agent': risk_agent,
        'tech_agent': tech_agent,
        'hr_agent': hr_agent,
        'operation_agent': operation_agent,
        'strategy_agent': strategy_agent,
        'integration_agent': True  # í•­ìƒ í™œì„±í™”
    }

    # ëª¨ë¸ ì„ íƒ UI (Claude 3.7 ë””í´íŠ¸, MCP ìŠ¤íƒ€ì¼)
    st.session_state.selected_model = st.selectbox(
        "ì‚¬ìš©í•  ëª¨ë¸",
        options=available_models,
        index=available_models.index(st.session_state.selected_model) if st.session_state.selected_model in available_models else 0,
        help="ë¶„ì„ì— ì‚¬ìš©í•  AI ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš” (ClaudeëŠ” ANTHROPIC_API_KEY í•„ìš”, OpenAIëŠ” OPENAI_API_KEY í•„ìš”)"
    )
    model_name = st.session_state.selected_model

    tab1, tab2 = st.tabs(["ì˜ì‚¬ê²°ì • ì•ˆê±´ ë“±ë¡", "ì˜ì‚¬ê²°ì • í˜„í™©"])
    
    with tab1:
        st.header("ìƒˆë¡œìš´ ì˜ì‚¬ê²°ì • ì•ˆê±´ ë“±ë¡")
        
        # ê¸°ë³¸ ì •ë³´ ì…ë ¥
        title = st.text_input("ì•ˆê±´ ì œëª©")
        description = st.text_area("ì•ˆê±´ ì„¤ëª…")
        
        # ì—¬ëŸ¬ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì—…ë¡œë“œ
        uploaded_files = st.file_uploader(
            "ì°¸ê³  ìë£Œ ì—…ë¡œë“œ (ì—¬ëŸ¬ íŒŒì¼ ì„ íƒ ê°€ëŠ¥)", 
            type=['md', 'txt'],
            accept_multiple_files=True,
            help="ì¶”ê°€ ì°¸ê³  ìë£Œê°€ ìˆë‹¤ë©´ ë§ˆí¬ë‹¤ìš´(.md) ë˜ëŠ” í…ìŠ¤íŠ¸(.txt) íŒŒì¼ë¡œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
        )
        
        reference_files = []
        if uploaded_files:
            for uploaded_file in uploaded_files:
                file_data = read_markdown_file(uploaded_file)
                if file_data:
                    reference_files.append(file_data)
            
            if reference_files:
                with st.expander("ì—…ë¡œë“œëœ ì°¸ê³  ìë£Œ ëª©ë¡"):
                    for file in reference_files:
                        st.markdown(f"### ğŸ“„ {file['filename']}")
                        st.markdown(file['content'])
                        st.markdown("---")
        
        decision_maker = st.text_input("ìµœì¢… ì˜ì‚¬ê²°ì •ì")
        created_by = st.text_input("ì‘ì„±ì")
        
        # ì˜µì…˜ ì…ë ¥
        st.subheader("ì˜ì‚¬ê²°ì • ì˜µì…˜")
        num_options = st.number_input("ì˜µì…˜ ìˆ˜", min_value=1, max_value=10, value=2)
        
        # ì˜µì…˜ ëª©ë¡ ì—…ë°ì´íŠ¸
        if len(st.session_state.options) != num_options:
            st.session_state.options = [None] * num_options
        
        options = []
        for i in range(num_options):
            with st.expander(f"ì˜µì…˜ {i+1}"):
                option = {
                    'name': st.text_input(f"ì˜µì…˜ {i+1} ì´ë¦„", key=f"name_{i}"),
                    'advantages': st.text_area(f"ì¥ì ", key=f"adv_{i}"),
                    'disadvantages': st.text_area(f"ë‹¨ì ", key=f"dis_{i}"),
                    'duration': st.text_input(f"ì˜ˆìƒ ì†Œìš” ê¸°ê°„", key=f"dur_{i}"),
                    'priority': st.number_input(f"ìš°ì„ ìˆœìœ„", 1, 10, key=f"pri_{i}"),
                    'additional_info': st.text_area(f"ì¶”ê°€ ì •ë³´", key=f"add_{i}")
                }
                st.session_state.options[i] = option
                options.append(option)
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            if st.button("ì•ˆê±´ ì €ì¥", type="primary"):
                if title and description and decision_maker and created_by:
                    case_id = save_decision_case(title, description, decision_maker, created_by)
                    if case_id:
                        st.session_state.current_case_id = case_id
                        for option in options:
                            save_decision_option(case_id, option)
                        # ì°¸ê³  ìë£Œ íŒŒì¼ ì €ì¥
                        if reference_files:
                            for file in reference_files:
                                save_reference_file(
                                    case_id,
                                    file['filename'],
                                    file['content']
                                )
                        st.success("âœ… ì˜ì‚¬ê²°ì • ì•ˆê±´ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                else:
                    st.error("ëª¨ë“  í•„ìˆ˜ í•­ëª©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        with col2:
            if st.button("AI ë¶„ì„ ìš”ì²­"):
                if not st.session_state.current_case_id:
                    st.error("ë¨¼ì € ì•ˆê±´ì„ ì €ì¥í•´ì£¼ì„¸ìš”.")
                    return
                
                if title and description and all(opt['name'] for opt in options):
                    with st.spinner("AIê°€ ë¶„ì„ì¤‘ì…ë‹ˆë‹¤..."):
                        # ë©€í‹° ì—ì´ì „íŠ¸ ë¶„ì„ ì‹¤í–‰
                        analysis_results = analyze_with_agents(
                            title,
                            description,
                            options,
                            reference_files if reference_files else None,
                            active_agents,
                            debug_mode,
                            model_name
                        )
                        
                        if analysis_results:
                            st.session_state.ai_analysis_results = analysis_results
                            
                            # ê° ì—ì´ì „íŠ¸ì˜ ë¶„ì„ ê²°ê³¼ ì €ì¥
                            for agent_type, analysis in analysis_results.items():
                                if isinstance(analysis, dict):
                                    save_ai_analysis(
                                        st.session_state.current_case_id,
                                        f"AI {agent_type} ({get_short_model_name(model_name)})",
                                        analysis.get('analysis', ''),
                                        analysis.get('recommendations', ''),
                                        analysis.get('risk_assessment', '')
                                    )
                                else:
                                    # ë¬¸ìì—´ì¸ ê²½ìš° ì „ì²´ë¥¼ ë¶„ì„ ë‚´ìš©ìœ¼ë¡œ ì²˜ë¦¬
                                    save_ai_analysis(
                                        st.session_state.current_case_id,
                                        f"AI {agent_type} ({get_short_model_name(model_name)})",
                                        str(analysis),
                                        extract_recommendations(str(analysis)),
                                        extract_risk_assessment(str(analysis))
                                    )
        
        # AI ë¶„ì„ ê²°ê³¼ í‘œì‹œ - ì—ì´ì „íŠ¸ë³„ íƒ­ìœ¼ë¡œ êµ¬ì„±
        if st.session_state.ai_analysis_results:
            st.write("### AI ë¶„ì„ ê²°ê³¼")
            
            # ì—ì´ì „íŠ¸ë³„ íƒ­ ìƒì„±
            agent_tabs = st.tabs([
                agent_name.replace('_', ' ').title() 
                for agent_name, is_active in active_agents.items() 
                if is_active
            ])
            
            for tab, (agent_name, analysis) in zip(
                agent_tabs, 
                {k: v for k, v in st.session_state.ai_analysis_results.items() 
                 if active_agents.get(k, False)}.items()
            ):
                with tab:
                    st.markdown(f"### {agent_name.replace('_', ' ').title()} ë¶„ì„")
                    display_mermaid_chart(analysis['analysis'])
                    
                    st.markdown("#### ì¶”ì²œ ì˜ê²¬")
                    display_mermaid_chart(analysis['recommendations'])
                    
                    st.markdown("#### ìœ„í—˜ë„ í‰ê°€")
                    display_mermaid_chart(analysis['risk_assessment'])

    with tab2:
        st.header("ì˜ì‚¬ê²°ì • í˜„í™©")
        
        # ì•ˆê±´ ëª©ë¡ ì¡°íšŒ
        cases = get_decision_cases()
        
        for case in cases:
            status_emoji = {
                'pending': 'â³',
                'approved': 'âœ…',
                'rejected': 'âŒ',
                'deferred': 'â¸ï¸'
            }.get(case['status'], 'â“')
            
            with st.expander(f"{status_emoji} {case['title']} ({case['created_at'].strftime('%Y-%m-%d')})"):
                # ìƒë‹¨ì— ë²„íŠ¼ë“¤ì„ ë°°ì¹˜í•  ì»¬ëŸ¼ ì¶”ê°€
                col1, col2, col3 = st.columns([4, 1, 1])
                
                with col1:
                    st.write(f"**ì„¤ëª…:** {case['description']}")
                    st.write(f"**ì˜ì‚¬ê²°ì •ì:** {case['decision_maker']}")
                    st.write(f"**ìƒíƒœ:** {case['status'].upper()}")
                
                with col2:
                    # ì¶”ê°€ ì§€ì¹¨ ì…ë ¥ í…ìŠ¤íŠ¸ ë°•ìŠ¤ë¥¼ ë¨¼ì € í‘œì‹œ
                    additional_instructions = st.text_area(
                        "ì¬ë¶„ì„ ì‹œ ì°¸ê³ í•  ì¶”ê°€ ì§€ì¹¨",
                        placeholder="ì˜ˆ: ìµœê·¼ì˜ ì‹œì¥ ë³€í™”ë¥¼ ê³ ë ¤í•´ì£¼ì„¸ìš”. / ESG ê´€ì ì—ì„œ ì¬ê²€í† í•´ì£¼ì„¸ìš”. / íŠ¹ì • ìœ„í—˜ ìš”ì†Œë¥¼ ì¤‘ì ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.",
                        help="AIê°€ ì¬ë¶„ì„ ì‹œ íŠ¹ë³„íˆ ê³ ë ¤í•´ì•¼ í•  ì‚¬í•­ì´ë‚˜ ê´€ì ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.",
                        key=f"instructions_{case['case_id']}"
                    )
                    
                    # ë¶„ì„ ê²°ê³¼ ì €ì¥ ì„¤ì •ì„ ìœ„í•œ ì²´í¬ë°•ìŠ¤
                    save_to_db = st.checkbox(
                        "ì¬ë¶„ì„ ê²°ê³¼ë¥¼ DBì— ìë™ ì €ì¥",
                        value=False,
                        key=f"save_to_db_{case['case_id']}",
                        help="ì²´í¬í•˜ë©´ ì¬ë¶„ì„ ì‹œ ê²°ê³¼ê°€ ìë™ìœ¼ë¡œ DBì— ì €ì¥ë©ë‹ˆë‹¤."
                    )
                    
                    # AI ì¬ë¶„ì„ ë²„íŠ¼
                    if st.button("ğŸ¤– AI ì¬ë¶„ì„ ì‹œì‘", key=f"reanalyze_{case['case_id']}", type="primary"):
                        # ì˜µì…˜ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
                        db_options = get_case_options(case['case_id'])
                        formatted_options = format_options_for_analysis(db_options)
                        reference_files = get_reference_files(case['case_id'])
                        
                        with st.spinner("AIê°€ ì¬ë¶„ì„ì¤‘ì…ë‹ˆë‹¤..."):
                            # ì¶”ê°€ ì§€ì¹¨ì„ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
                            modified_description = f"""
                            {case['description']}

                            [ì¶”ê°€ ë¶„ì„ ì§€ì¹¨]
                            {additional_instructions if additional_instructions.strip() else 'ì¼ë°˜ì ì¸ ê´€ì ì—ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”.'}
                            """
                            
                            analysis_results = analyze_with_agents(
                                case['title'],
                                modified_description,
                                formatted_options,
                                reference_files,
                                active_agents,
                                debug_mode,
                                model_name
                            )
                            
                            if analysis_results:
                                # DB ì €ì¥ì´ ì„ íƒëœ ê²½ìš° ìë™ ì €ì¥ ìˆ˜í–‰
                                if save_to_db:
                                    with st.spinner("ë¶„ì„ ê²°ê³¼ë¥¼ DBì— ì €ì¥ì¤‘..."):
                                        # ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ ì‚­ì œ
                                        delete_ai_analysis(case['case_id'])
                                        st.info("ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ë¥¼ ì‚­ì œí•˜ê³  ìƒˆë¡œìš´ ë¶„ì„ì„ ì €ì¥í•©ë‹ˆë‹¤...")
                                        
                                        for agent_type, analysis in analysis_results.items():
                                            try:
                                                if isinstance(analysis, dict):
                                                    success = save_ai_analysis(
                                                        case['case_id'],
                                                        f"AI {agent_type} ({get_short_model_name(model_name)}) - {additional_instructions[:30]}...",
                                                        analysis.get('analysis', ''),
                                                        analysis.get('recommendations', ''),
                                                        analysis.get('risk_assessment', '')
                                                    )
                                                else:
                                                    success = save_ai_analysis(
                                                        case['case_id'],
                                                        f"AI {agent_type} ({get_short_model_name(model_name)}) - {additional_instructions[:30]}...",
                                                        str(analysis),
                                                        extract_recommendations(str(analysis)),
                                                        extract_risk_assessment(str(analysis))
                                                    )
                                                
                                                if success:
                                                    st.success(f"âœ… {agent_type} ë¶„ì„ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                                                else:
                                                    st.error(f"âŒ {agent_type} ë¶„ì„ ê²°ê³¼ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                                            except Exception as e:
                                                st.error(f"âŒ {agent_type} ë¶„ì„ ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                                        
                                        st.success("âœ… ëª¨ë“  AI ë¶„ì„ì´ DBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                                else:
                                    st.info("ğŸ’¡ ë¶„ì„ ê²°ê³¼ê°€ í™”ë©´ì—ë§Œ í‘œì‹œë©ë‹ˆë‹¤. DBì—ëŠ” ì €ì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                                
                                # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                                st.write("### ìƒˆë¡œìš´ ë¶„ì„ ê²°ê³¼")
                                st.write(f"**ë¶„ì„ ì§€ì¹¨:** {additional_instructions}")
                                
                                # ì—ì´ì „íŠ¸ë³„ íƒ­ ìƒì„±
                                agent_tabs = st.tabs([
                                    agent_name.replace('_', ' ').title() 
                                    for agent_name, is_active in active_agents.items() 
                                    if is_active
                                ])
                                
                                for tab, (agent_name, analysis) in zip(
                                    agent_tabs,
                                    {k: v for k, v in analysis_results.items() 
                                     if active_agents.get(k, False)}.items()
                                ):
                                    with tab:
                                        st.markdown(f"### {agent_name.replace('_', ' ').title()} ë¶„ì„")
                                        display_mermaid_chart(analysis['analysis'])
                                        
                                        st.markdown("#### ì¶”ì²œ ì˜ê²¬")
                                        display_mermaid_chart(analysis['recommendations'])
                                        
                                        st.markdown("#### ìœ„í—˜ë„ í‰ê°€")
                                        display_mermaid_chart(analysis['risk_assessment'])
                                
                                st.success("âœ… AI ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                
                with col3:
                    # ê¸°ì¡´ ì‚­ì œ ë²„íŠ¼ ë¡œì§
                    delete_checkbox = st.checkbox("ì‚­ì œ í™•ì¸", key=f"delete_confirm_{case['case_id']}")
                    if delete_checkbox:
                        if st.button("ğŸ—‘ï¸ ì‚­ì œ", key=f"delete_{case['case_id']}", type="primary"):
                            if delete_decision_case(case['case_id']):
                                st.success("âœ… ì˜ì‚¬ê²°ì • ì•ˆê±´ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                                st.rerun()
                    else:
                        st.button("ğŸ—‘ï¸ ì‚­ì œ", key=f"delete_{case['case_id']}", disabled=True)
                        st.caption("ì‚­ì œí•˜ë ¤ë©´ ë¨¼ì € ì²´í¬ë°•ìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”")

                # ì˜µì…˜ ëª©ë¡ í‘œì‹œ
                options = get_case_options(case['case_id'])
                st.write("### ì˜µì…˜ ëª©ë¡")
                
                # ì˜µì…˜ë“¤ì„ í‘œ í˜•íƒœë¡œ í‘œì‹œ
                for opt in options:
                    is_selected = case['final_option_id'] == opt['option_id']
                    st.markdown(f"""
                    ### {'âœ… ' if is_selected else ''}ì˜µì…˜ {opt['option_name']}
                    **ìš°ì„ ìˆœìœ„:** {opt['priority']}
                    
                    **ì¥ì :**
                    {opt['advantages']}
                    
                    **ë‹¨ì :**
                    {opt['disadvantages']}
                    
                    **ì˜ˆìƒ ê¸°ê°„:** {opt['estimated_duration']}""")
                    
                    if opt.get('additional_info'):
                        st.markdown("**ì¶”ê°€ ì •ë³´:**")
                        st.markdown(opt['additional_info'])
                    
                    st.markdown("---")
                
                # AI ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                analyses = get_ai_analysis(case['case_id'])
                if analyses:
                    st.write("### AI ë¶„ì„ ê²°ê³¼")
                    
                    # ê° ë¶„ì„ ê²°ê³¼ë¥¼ íƒ­ìœ¼ë¡œ í‘œì‹œ
                    analysis_tabs = st.tabs([
                        f"ë¶„ì„ {idx} ({analysis['created_at'].strftime('%Y-%m-%d %H:%M')})" 
                        for idx, analysis in enumerate(analyses, 1)
                    ])
                    
                    for tab, analysis in zip(analysis_tabs, analyses):
                        with tab:
                            st.markdown(f"**ëª¨ë¸:** {analysis['model_name']}")
                            
                            st.markdown("**ë¶„ì„ ë‚´ìš©:**")
                            display_mermaid_chart(analysis['analysis_content'])
                            
                            # ì•ˆì „í•˜ê²Œ recommendations í‚¤ í™•ì¸
                            if isinstance(analysis, dict) and analysis.get('recommendations'):
                                st.markdown("**ì¶”ì²œ ì˜ê²¬:**")
                                display_mermaid_chart(analysis['recommendations'])
                            
                            # ì•ˆì „í•˜ê²Œ risk_assessment í‚¤ í™•ì¸
                            if isinstance(analysis, dict) and analysis.get('risk_assessment'):
                                st.markdown("**ìœ„í—˜ë„ í‰ê°€:**")
                                display_mermaid_chart(analysis['risk_assessment'])
                
                # ì˜ì‚¬ê²°ì • ì…ë ¥ (pending ìƒíƒœì¼ ë•Œë§Œ)
                if case['status'] == 'pending':
                    st.write("### ìµœì¢… ì˜ì‚¬ê²°ì •")
                    col1, col2 = st.columns([1, 2])
                    
                    with col1:
                        decision_status = st.selectbox(
                            "ê²°ì • ìƒíƒœ",
                            ['approved', 'rejected', 'deferred'],
                            key=f"status_{case['case_id']}"
                        )
                    
                    with col2:
                        selected_option = st.selectbox(
                            "ì„ íƒëœ ì˜µì…˜",
                            options,
                            format_func=lambda x: x['option_name'],
                            key=f"option_{case['case_id']}"
                        )
                    
                    final_comment = st.text_area(
                        "ìµœì¢… ì½”ë©˜íŠ¸",
                        key=f"comment_{case['case_id']}"
                    )
                    
                    if st.button("ì˜ì‚¬ê²°ì • í™•ì •", key=f"decide_{case['case_id']}", type="primary"):
                        if update_case_status(
                            case['case_id'],
                            decision_status,
                            selected_option['option_id'],
                            final_comment
                        ):
                            st.success("âœ… ì˜ì‚¬ê²°ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                            st.rerun()
                else:
                    if case['final_comment']:
                        st.write("### ìµœì¢… ì˜ì‚¬ê²°ì • ë‚´ìš©")
                        st.write(case['final_comment'])

                # ì°¸ê³  ìë£Œ íŒŒì¼ í‘œì‹œ
                reference_files = get_reference_files(case['case_id'])
                if reference_files:
                    st.write("### ğŸ“ ì°¸ê³  ìë£Œ")
                    for file in reference_files:
                        st.markdown(f"""
                        #### ğŸ“„ {file['filename']}
                        ```
                        {file['file_content']}
                        ```
                        ---
                        """)

if __name__ == "__main__":
    main() 