import streamlit as st
import pandas as pd
import numpy as np
from sklearn import (
    linear_model, tree, ensemble, svm, neural_network, 
    preprocessing, metrics, model_selection
)
from sklearn.impute import SimpleImputer
import plotly.express as px
import plotly.graph_objects as go
from io import BytesIO
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import json
import base64

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ML Explorer",
    page_icon="ğŸ”¬",
    layout="wide"
)

# ì‚¬ìš© ê°€ëŠ¥í•œ ML ì•Œê³ ë¦¬ì¦˜
ALGORITHMS = {
    "íšŒê·€": {
        "Linear Regression": linear_model.LinearRegression,
        "Ridge Regression": linear_model.Ridge,
        "Lasso Regression": linear_model.Lasso,
        "Decision Tree Regressor": tree.DecisionTreeRegressor,
        "Random Forest Regressor": ensemble.RandomForestRegressor,
        "SVR": svm.SVR,
        "Neural Network Regressor": neural_network.MLPRegressor
    },
    "ë¶„ë¥˜": {
        "Logistic Regression": linear_model.LogisticRegression,
        "Decision Tree Classifier": tree.DecisionTreeClassifier,
        "Random Forest Classifier": ensemble.RandomForestClassifier,
        "SVC": svm.SVC,
        "Neural Network Classifier": neural_network.MLPClassifier
    }
}

def load_data():
    """ë°ì´í„° ë¡œë“œ í•¨ìˆ˜"""
    uploaded_file = st.file_uploader(
        "ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ (CSV, Excel, Google Sheets)", 
        type=['csv', 'xlsx']
    )
    
    if uploaded_file is not None:
        try:
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)
            return df
        except Exception as e:
            st.error(f"íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None
    return None

def explore_data(df):
    """ë°ì´í„° íƒìƒ‰ í•¨ìˆ˜"""
    st.subheader("1. ë°ì´í„° ê¸°ë³¸ ì •ë³´")
    
    # ê¸°ë³¸ ì •ë³´ í‘œì‹œ
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("í–‰ ìˆ˜", df.shape[0])
    with col2:
        st.metric("ì—´ ìˆ˜", df.shape[1])
    with col3:
        st.metric("ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ì—´ ìˆ˜", df.isna().any().sum())
    
    # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
    st.subheader("2. ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
    st.dataframe(df.head())
    
    # ê¸°ìˆ  í†µê³„ëŸ‰
    st.subheader("3. ê¸°ìˆ  í†µê³„ëŸ‰")
    st.dataframe(df.describe())
    
    # ê²°ì¸¡ì¹˜ ì‹œê°í™”
    st.subheader("4. ê²°ì¸¡ì¹˜ ë¶„í¬")
    missing_data = df.isnull().sum()
    if missing_data.any():
        fig = px.bar(
            x=missing_data.index,
            y=missing_data.values,
            title="ì»¬ëŸ¼ë³„ ê²°ì¸¡ì¹˜ ìˆ˜"
        )
        st.plotly_chart(fig)
    
    # ìƒê´€ê´€ê³„ ë¶„ì„
    st.subheader("5. ìƒê´€ê´€ê³„ ë¶„ì„")
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    if len(numeric_cols) > 1:
        corr = df[numeric_cols].corr()
        fig = px.imshow(
            corr,
            title="ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ",
            labels=dict(color="ìƒê´€ê³„ìˆ˜")
        )
        st.plotly_chart(fig)

def prepare_data(df):
    """ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜"""
    st.subheader("ë°ì´í„° ì „ì²˜ë¦¬")
    
    # ë°ì´í„° íƒ€ì… ì •ë³´ í‘œì‹œ
    st.write("ì»¬ëŸ¼ë³„ ë°ì´í„° íƒ€ì…:")
    dtype_df = pd.DataFrame({
        'ë°ì´í„° íƒ€ì…': df.dtypes,
        'ê³ ìœ ê°’ ìˆ˜': df.nunique(),
        'ìƒ˜í”Œ ê°’': [df[col].iloc[0] if len(df) > 0 else None for col in df.columns]
    })
    st.dataframe(dtype_df)
    
    # íƒ€ê²Ÿ ë³€ìˆ˜ ì„ íƒ
    target = st.selectbox("íƒ€ê²Ÿ ë³€ìˆ˜ ì„ íƒ", df.columns)
    features = st.multiselect("íŠ¹ì„± ë³€ìˆ˜ ì„ íƒ", [col for col in df.columns if col != target])
    
    if not features:
        st.warning("íŠ¹ì„± ë³€ìˆ˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
        return None, None
    
    # ì „ì²˜ë¦¬ ì˜µì…˜
    st.write("ì „ì²˜ë¦¬ ì˜µì…˜:")
    handle_missing = st.checkbox("ê²°ì¸¡ì¹˜ ì²˜ë¦¬", value=True)
    scale_features = st.checkbox("íŠ¹ì„± ìŠ¤ì¼€ì¼ë§")
    encode_categorical = st.checkbox("ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©", value=True)
    
    try:
        X = df[features].copy()
        y = df[target].copy()
        
        # ë°ì´í„° íƒ€ì… ìë™ ê°ì§€ ë° ë³€í™˜
        for col in X.columns:
            try:
                X[col] = pd.to_numeric(X[col], errors='raise')
            except (ValueError, TypeError):
                X[col] = X[col].astype(str)
        
        # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        if handle_missing:
            # ìˆ«ìí˜• ì»¬ëŸ¼
            num_cols = X.select_dtypes(include=[np.number]).columns
            if len(num_cols) > 0:
                num_imputer = SimpleImputer(strategy='mean')
                X[num_cols] = num_imputer.fit_transform(X[num_cols])
            
            # ë²”ì£¼í˜• ì»¬ëŸ¼
            cat_cols = X.select_dtypes(exclude=[np.number]).columns
            if len(cat_cols) > 0:
                cat_imputer = SimpleImputer(strategy='most_frequent')
                X[cat_cols] = cat_imputer.fit_transform(X[cat_cols])
        
        # ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©
        if encode_categorical:
            cat_cols = X.select_dtypes(exclude=[np.number]).columns
            if len(cat_cols) > 0:
                # Label Encoding for target if it's categorical
                if not pd.api.types.is_numeric_dtype(y):
                    label_encoder = preprocessing.LabelEncoder()
                    y = label_encoder.fit_transform(y)
                    st.info(f"íƒ€ê²Ÿ ë³€ìˆ˜ì˜ í´ë˜ìŠ¤: {list(label_encoder.classes_)}")
                
                # One-Hot Encoding for features
                encoder = preprocessing.OneHotEncoder(
                    sparse_output=False,
                    handle_unknown='ignore'
                )
                encoded_cats = encoder.fit_transform(X[cat_cols])
                encoded_df = pd.DataFrame(
                    encoded_cats,
                    columns=encoder.get_feature_names_out(cat_cols)
                )
                
                # ì›ë³¸ ë°ì´í„°ì—ì„œ ë²”ì£¼í˜• ì»¬ëŸ¼ ì œê±°í•˜ê³  ì¸ì½”ë”©ëœ ê²°ê³¼ ì¶”ê°€
                X = pd.concat([X.select_dtypes(include=[np.number]), encoded_df], axis=1)
                
                # ì¸ì½”ë”© ê²°ê³¼ í‘œì‹œ
                st.write("ì¸ì½”ë”©ëœ íŠ¹ì„±:", X.columns.tolist())
        
        # íŠ¹ì„± ìŠ¤ì¼€ì¼ë§
        if scale_features and len(X.select_dtypes(include=[np.number]).columns) > 0:
            scaler = preprocessing.StandardScaler()
            X = pd.DataFrame(
                scaler.fit_transform(X),
                columns=X.columns
            )
        
        # ìµœì¢… ë°ì´í„°ì…‹ ë¯¸ë¦¬ë³´ê¸°
        st.write("ì „ì²˜ë¦¬ ì™„ë£Œëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:")
        st.write("X shape:", X.shape)
        st.write("y shape:", y.shape)
        st.dataframe(X.head())
        
        return X, y
        
    except Exception as e:
        st.error(f"ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None, None

def train_model(X, y, task_type="íšŒê·€"):
    """ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜"""
    st.subheader("ëª¨ë¸ í•™ìŠµ")
    
    # ì•Œê³ ë¦¬ì¦˜ ì„ íƒ
    algorithm = st.selectbox(
        "ì•Œê³ ë¦¬ì¦˜ ì„ íƒ",
        options=list(ALGORITHMS[task_type].keys())
    )
    
    # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
    test_size = st.slider("í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ë¹„ìœ¨", 0.1, 0.5, 0.2)
    
    try:
        # ë°ì´í„° ë¶„í• 
        X_train, X_test, y_train, y_test = model_selection.train_test_split(
            X, y, test_size=test_size, random_state=42
        )
        
        # ëª¨ë¸ í•™ìŠµ
        model = ALGORITHMS[task_type][algorithm]()
        model.fit(X_train, y_train)
        
        # ì˜ˆì¸¡
        y_pred = model.predict(X_test)
        
        # ì„±ëŠ¥ í‰ê°€
        if task_type == "íšŒê·€":
            mse = metrics.mean_squared_error(y_test, y_pred)
            rmse = np.sqrt(mse)
            r2 = metrics.r2_score(y_test, y_pred)
            
            st.write("ëª¨ë¸ ì„±ëŠ¥:")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("MSE", f"{mse:.4f}")
            with col2:
                st.metric("RMSE", f"{rmse:.4f}")
            with col3:
                st.metric("R2 Score", f"{r2:.4f}")
            
            # ì‹¤ì œê°’ vs ì˜ˆì¸¡ê°’ ì‚°ì ë„
            fig = px.scatter(
                x=y_test, y=y_pred,
                labels={"x": "ì‹¤ì œê°’", "y": "ì˜ˆì¸¡ê°’"},
                title="ì‹¤ì œê°’ vs ì˜ˆì¸¡ê°’"
            )
            fig.add_trace(
                go.Scatter(x=[y_test.min(), y_test.max()], 
                          y=[y_test.min(), y_test.max()],
                          mode='lines', name='Perfect Prediction')
            )
            st.plotly_chart(fig)
            
        else:  # ë¶„ë¥˜
            accuracy = metrics.accuracy_score(y_test, y_pred)
            precision = metrics.precision_score(y_test, y_pred, average='weighted')
            recall = metrics.recall_score(y_test, y_pred, average='weighted')
            
            st.write("ëª¨ë¸ ì„±ëŠ¥:")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Accuracy", f"{accuracy:.4f}")
            with col2:
                st.metric("Precision", f"{precision:.4f}")
            with col3:
                st.metric("Recall", f"{recall:.4f}")
            
            # í˜¼ë™ í–‰ë ¬
            cm = metrics.confusion_matrix(y_test, y_pred)
            fig = px.imshow(
                cm,
                labels=dict(x="ì˜ˆì¸¡ê°’", y="ì‹¤ì œê°’"),
                title="í˜¼ë™ í–‰ë ¬"
            )
            st.plotly_chart(fig)
        
        return model
        
    except Exception as e:
        st.error(f"ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def export_results(model, X, y):
    """ê²°ê³¼ ë‚´ë³´ë‚´ê¸° í•¨ìˆ˜"""
    st.subheader("ê²°ê³¼ ë‚´ë³´ë‚´ê¸°")
    
    # ëª¨ë¸ ì €ì¥
    if st.button("ëª¨ë¸ ì €ì¥"):
        try:
            joblib.dump(model, 'trained_model.joblib')
            st.success("ëª¨ë¸ì´ 'trained_model.joblib'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"ëª¨ë¸ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    # ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„±
    if st.button("ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„±"):
        try:
            report = generate_markdown_report(model, X, y)
            download_link = create_download_link(report, "report.md")
            st.markdown(download_link, unsafe_allow_html=True)
        except Exception as e:
            st.error(f"ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

def generate_markdown_report(model, X, y):
    """ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„± í•¨ìˆ˜"""
    report = f"""# ë¨¸ì‹ ëŸ¬ë‹ ë¶„ì„ ë¦¬í¬íŠ¸

## 1. ë°ì´í„°ì…‹ ì •ë³´
- ìƒ˜í”Œ ìˆ˜: {X.shape[0]}
- íŠ¹ì„± ìˆ˜: {X.shape[1]}
- íŠ¹ì„± ì´ë¦„: {', '.join(X.columns)}

## 2. ëª¨ë¸ ì •ë³´
- ì•Œê³ ë¦¬ì¦˜: {type(model).__name__}
- ëª¨ë¸ íŒŒë¼ë¯¸í„°: {model.get_params()}

## 3. ì„±ëŠ¥ ì§€í‘œ
"""
    # ì—¬ê¸°ì— ì„±ëŠ¥ ì§€í‘œ ì¶”ê°€
    
    return report

def create_download_link(content, filename):
    """ë‹¤ìš´ë¡œë“œ ë§í¬ ìƒì„± í•¨ìˆ˜"""
    b64 = base64.b64encode(content.encode()).decode()
    return f'<a href="data:text/markdown;base64,{b64}" download="{filename}">ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ</a>'

def main():
    st.title("ğŸ”¬ ML Explorer")
    st.write("ë°ì´í„° ë¶„ì„ê³¼ ë¨¸ì‹ ëŸ¬ë‹ì„ ìœ„í•œ ì˜¬ì¸ì› ë„êµ¬")
    
    # ë°ì´í„° ë¡œë“œ
    df = load_data()
    
    if df is not None:
        # íƒ­ ìƒì„±
        tab1, tab2, tab3 = st.tabs(["ë°ì´í„° íƒìƒ‰", "ëª¨ë¸ í•™ìŠµ", "ê²°ê³¼ ë‚´ë³´ë‚´ê¸°"])
        
        with tab1:
            explore_data(df)
        
        with tab2:
            X, y = prepare_data(df)
            if X is not None and y is not None:
                task_type = st.radio("ì‘ì—… ìœ í˜•", ["íšŒê·€", "ë¶„ë¥˜"])
                model = train_model(X, y, task_type)
        
        with tab3:
            if 'model' in locals() and model is not None:
                export_results(model, X, y)

if __name__ == "__main__":
    main() 