import streamlit as st
import os
from dotenv import load_dotenv
import openai
import numpy as np
import time
import json
from datetime import datetime
import hashlib
import glob
import requests
from concurrent.futures import ThreadPoolExecutor
import pandas as pd
from reportlab.lib.pagesizes import letter, A4
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak, Table, TableStyle
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import inch
from reportlab.lib import colors
from reportlab.lib.enums import TA_CENTER, TA_LEFT, TA_RIGHT
import io

# FPDF2ë¥¼ ì‚¬ìš©í•œ í•œê¸€ PDF ìƒì„±
try:
    from fpdf import FPDF
    FPDF2_AVAILABLE = True
except ImportError:
    FPDF2_AVAILABLE = False

# WeasyPrintëŠ” ì‹œìŠ¤í…œ ì˜ì¡´ì„± ë¬¸ì œë¡œ ì œê±°
WEASYPRINT_AVAILABLE = False

# DOCX ìƒì„±ì„ ìœ„í•œ python-docx ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    from docx import Document
    from docx.shared import Inches, Pt
    from docx.enum.text import WD_ALIGN_PARAGRAPH
    from docx.oxml.shared import OxmlElement, qn
    DOCX_AVAILABLE = True
except ImportError:
    DOCX_AVAILABLE = False

# langchain ë° FAISS ê´€ë ¨
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings
from langchain.document_loaders import (
    PyPDFLoader, UnstructuredPowerPointLoader, UnstructuredExcelLoader, 
    UnstructuredWordDocumentLoader, UnstructuredMarkdownLoader, UnstructuredFileLoader
)
from langchain.schema import Document

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Q-Li",
    page_icon="ğŸ¤”",
    layout="wide"
)

load_dotenv()

# ===== LLM í´ë¼ì´ì–¸íŠ¸ ê´€ë¦¬ =====
class LLMClient:
    """ë‹¤ì–‘í•œ LLM í´ë¼ì´ì–¸íŠ¸ë¥¼ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.clients = {}
        self.models = {}
        self.setup_clients()
    
    def setup_clients(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ LLM í´ë¼ì´ì–¸íŠ¸ë“¤ì„ ì„¤ì •"""
        # OpenAI í´ë¼ì´ì–¸íŠ¸ (ê¸°ë³¸)
        openai_key = os.getenv('OPENAI_API_KEY')
        if openai_key:
            try:
                self.clients['openai'] = openai.OpenAI(api_key=openai_key)
                self.models['openai'] = [
                    'gpt-4o-mini',
                    'gpt-4o',
                    'gpt-4-turbo',
                    'gpt-4',
                    'gpt-3.5-turbo'
                ]
            except Exception as e:
                st.warning(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ì‹¤íŒ¨: {e}")
        
        # Ollama í´ë¼ì´ì–¸íŠ¸ (ë¡œì»¬ LLM) - ì„ íƒì 
        try:
            import requests
            # Ollama ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸ (ì§§ì€ íƒ€ì„ì•„ì›ƒ)
            response = requests.get("http://localhost:11434/api/tags", timeout=2)
            if response.status_code == 200:
                self.clients['ollama'] = requests
                self.models['ollama'] = [
                    'mistral:latest',
                    'llama3.1:latest',
                    'llama3.1:8b',
                    'phi4:latest',
                    'llama2:latest',
                    'gemma2:latest',
                    'gemma:latest',
                    'llama3.2:latest',
                    'deepseek-r1:14b',
                    'nomic-embed-text:latest'
                ]
        except Exception as e:
            # Ollama ì—°ê²° ì‹¤íŒ¨ ì‹œ ì¡°ìš©íˆ ë¬´ì‹œ (ê²½ê³  ë©”ì‹œì§€ ì œê±°)
            pass
        
        # Perplexity í´ë¼ì´ì–¸íŠ¸
        perplexity_key = os.getenv('PERPLEXITY_API_KEY')
        if perplexity_key:
            try:
                self.clients['perplexity'] = openai.OpenAI(
                    api_key=perplexity_key,
                    base_url="https://api.perplexity.ai"
                )
                self.models['perplexity'] = [
                    'sonar-pro',
                    'sonar-small-online',
                    'llama-3.1-sonar-small-128k-online',
                    'llama-3.1-sonar-medium-128k-online',
                    'llama-3.1-sonar-large-128k-online'
                ]
            except Exception as e:
                st.warning(f"Perplexity í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ì‹¤íŒ¨: {e}")
        
        # Anthropic í´ë¼ì´ì–¸íŠ¸ (Claude)
        anthropic_key = os.getenv('ANTHROPIC_API_KEY')
        if anthropic_key:
            try:
                import anthropic
                self.clients['anthropic'] = anthropic.Anthropic(api_key=anthropic_key)
                self.models['anthropic'] = [
                    'claude-3-7-sonnet-latest',
                    'claude-3-5-sonnet-20241022',
                    'claude-3-5-haiku-20241022',
                    'claude-3-opus-20240229',
                    'claude-3-sonnet-20240229',
                    'claude-3-haiku-20240307'
                ]
            except Exception as e:
                st.warning(f"Anthropic í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ì‹¤íŒ¨: {e}")
        
        # Google Gemini í´ë¼ì´ì–¸íŠ¸
        google_key = os.getenv('GOOGLE_API_KEY')
        if google_key:
            try:
                import google.generativeai as genai
                genai.configure(api_key=google_key)
                self.clients['google'] = genai
                self.models['google'] = [
                    'gemini-1.5-pro',
                    'gemini-1.5-flash',
                    'gemini-pro',
                    'gemini-pro-vision'
                ]
            except Exception as e:
                st.warning(f"Google Gemini í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ì‹¤íŒ¨: {e}")
    
    def get_available_providers(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ LLM ì œê³µì ëª©ë¡ ë°˜í™˜"""
        return list(self.clients.keys())
    
    def get_models_for_provider(self, provider):
        """íŠ¹ì • ì œê³µìì˜ ëª¨ë¸ ëª©ë¡ ë°˜í™˜"""
        return self.models.get(provider, [])
    
    def generate_response(self, provider, model, messages, temperature=0.7, max_tokens=2000):
        """ì„ íƒëœ LLMìœ¼ë¡œ ì‘ë‹µ ìƒì„±"""
        try:
            if provider == 'ollama':
                return self._generate_ollama_response(model, messages, temperature, max_tokens)
            elif provider == 'openai':
                return self._generate_openai_response(model, messages, temperature, max_tokens)
            elif provider == 'perplexity':
                return self._generate_perplexity_response(model, messages, temperature, max_tokens)
            elif provider == 'anthropic':
                return self._generate_anthropic_response(model, messages, temperature, max_tokens)
            elif provider == 'google':
                return self._generate_google_response(model, messages, temperature, max_tokens)
            else:
                return None, f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì œê³µì: {provider}"
        except Exception as e:
            return None, f"ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {str(e)}"
    
    def _generate_ollama_response(self, model, messages, temperature, max_tokens):
        """Ollama ì‘ë‹µ ìƒì„±"""
        try:
            # Ollama API í˜•ì‹ì— ë§ê²Œ ë©”ì‹œì§€ ë³€í™˜
            ollama_messages = []
            for msg in messages:
                if msg['role'] == 'system':
                    # ì‹œìŠ¤í…œ ë©”ì‹œì§€ëŠ” í”„ë¡¬í”„íŠ¸ì— í¬í•¨
                    continue
                elif msg['role'] == 'user':
                    ollama_messages.append({
                        'role': 'user',
                        'content': msg['content']
                    })
                elif msg['role'] == 'assistant':
                    ollama_messages.append({
                        'role': 'assistant',
                        'content': msg['content']
                    })
            
            # ì‹œìŠ¤í…œ ë©”ì‹œì§€ê°€ ìˆìœ¼ë©´ ì²« ë²ˆì§¸ ì‚¬ìš©ì ë©”ì‹œì§€ì— í¬í•¨
            system_content = ""
            for msg in messages:
                if msg['role'] == 'system':
                    system_content = msg['content']
                    break
            
            if system_content and ollama_messages:
                ollama_messages[0]['content'] = f"{system_content}\n\n{ollama_messages[0]['content']}"
            
            # Ollama API í˜¸ì¶œ
            response = self.clients['ollama'].post(
                "http://localhost:11434/api/chat",
                json={
                    "model": model,
                    "messages": ollama_messages,
                    "stream": False,
                    "options": {
                        "temperature": temperature,
                        "num_predict": max_tokens
                    }
                },
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                return result['message']['content'], None
            else:
                return None, f"Ollama API ì˜¤ë¥˜: {response.status_code}"
                
        except Exception as e:
            return None, f"Ollama ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {str(e)}"
    
    def _generate_openai_response(self, model, messages, temperature, max_tokens):
        """OpenAI ì‘ë‹µ ìƒì„±"""
        response = self.clients['openai'].chat.completions.create(
            model=model,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens
        )
        return response.choices[0].message.content, None
    
    def _generate_perplexity_response(self, model, messages, temperature, max_tokens):
        """Perplexity ì‘ë‹µ ìƒì„±"""
        response = self.clients['perplexity'].chat.completions.create(
            model=model,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens
        )
        return response.choices[0].message.content, None
    
    def _generate_anthropic_response(self, model, messages, temperature, max_tokens):
        """Anthropic ì‘ë‹µ ìƒì„±"""
        # Anthropicì€ ë‹¤ë¥¸ ë©”ì‹œì§€ í˜•ì‹ì„ ì‚¬ìš©
        system_message = ""
        user_messages = []
        
        for msg in messages:
            if msg['role'] == 'system':
                system_message = msg['content']
            else:
                user_messages.append(msg['content'])
        
        user_content = "\n\n".join(user_messages)
        
        response = self.clients['anthropic'].messages.create(
            model=model,
            max_tokens=max_tokens,
            temperature=temperature,
            system=system_message,
            messages=[{"role": "user", "content": user_content}]
        )
        return response.content[0].text, None
    
    def _generate_google_response(self, model, messages, temperature, max_tokens):
        """Google Gemini ì‘ë‹µ ìƒì„±"""
        # GeminiëŠ” ë‹¤ë¥¸ ë©”ì‹œì§€ í˜•ì‹ì„ ì‚¬ìš©
        user_content = ""
        for msg in messages:
            if msg['role'] == 'user':
                user_content += msg['content'] + "\n\n"
        
        model_instance = self.clients['google'].GenerativeModel(model)
        response = model_instance.generate_content(
            user_content,
            generation_config=self.clients['google'].types.GenerationConfig(
                temperature=temperature,
                max_output_tokens=max_tokens
            )
        )
        return response.text, None

# ===== FAISS ê¸°ë°˜ íŒŒì¼ì‹œìŠ¤í…œ RAGSystem =====
class FileRAGSystem:
    """FAISS + íŒŒì¼ì‹œìŠ¤í…œ ê¸°ë°˜ RAG ì‹œìŠ¤í…œ (ê°œì„ ëœ ì„ë² ë”©)"""
    def __init__(self, base_folder_path="./pages/rag_files"):
        self.base_folder_path = base_folder_path
        self.current_folder_path = base_folder_path
        self.vectorstore = None
        self.docs = []
        self.is_loaded = False
        self.embeddings = self._setup_embeddings()
        self.load_files_and_build_index()

    def _setup_embeddings(self):
        """ì„ë² ë”© ëª¨ë¸ ì„¤ì • (ê°œì„ ëœ ë²„ì „)"""
        try:
            # 1. OpenAI ì„ë² ë”© (ê¸°ë³¸)
            openai_key = os.getenv('OPENAI_API_KEY')
            if openai_key:
                try:
                    # text-embedding-3-smallì´ ë” ë‚˜ì€ ì„±ëŠ¥ ì œê³µ
                    from langchain_openai import OpenAIEmbeddings
                    return OpenAIEmbeddings(
                        model="text-embedding-3-small",
                        dimensions=1536  # ë” ì‘ì€ ì°¨ì›ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ
                    )
                except Exception as e:
                    st.warning(f"OpenAI ì„ë² ë”© ì„¤ì • ì‹¤íŒ¨: {e}")
            
            # 2. Ollama ì„ë² ë”© (ë¡œì»¬ ëŒ€ì•ˆ)
            try:
                import requests
                response = requests.get("http://localhost:11434/api/tags", timeout=2)
                if response.status_code == 200:
                    from langchain_community.embeddings import OllamaEmbeddings
                    return OllamaEmbeddings(model="nomic-embed-text")
            except:
                pass
            
            # 3. ê¸°ë³¸ OpenAI ì„ë² ë”© (fallback)
            from langchain_openai import OpenAIEmbeddings
            return OpenAIEmbeddings()
            
        except Exception as e:
            st.error(f"ì„ë² ë”© ì„¤ì • ì‹¤íŒ¨: {e}")
            # ìµœí›„ ìˆ˜ë‹¨ìœ¼ë¡œ ê¸°ë³¸ OpenAI ì„ë² ë”©
            from langchain_openai import OpenAIEmbeddings
            return OpenAIEmbeddings()

    def set_search_folder(self, folder_path):
        """ê²€ìƒ‰í•  í´ë” ì„¤ì •"""
        self.current_folder_path = folder_path
        self.load_files_and_build_index()

    def load_files_and_build_index(self):
        """í´ë” ë‚´ ëª¨ë“  ì§€ì› íŒŒì¼ì„ ì½ì–´ ë²¡í„° ì¸ë±ìŠ¤ êµ¬ì¶• (ê°œì„ ëœ ì²­í‚¹)"""
        loaders = [
            ("*.pdf", PyPDFLoader),
            ("*.pptx", UnstructuredPowerPointLoader),
            ("*.xlsx", None),  # Excelì€ ë³„ë„ ì²˜ë¦¬
            ("*.docx", UnstructuredWordDocumentLoader),
            ("*.md", UnstructuredMarkdownLoader),
            ("*.gdoc", UnstructuredFileLoader),  # Google Docs (HTML í˜•ì‹)
            ("*.gsheet", UnstructuredFileLoader), # Google Sheets (HTML í˜•ì‹)
            ("*.gslides", UnstructuredFileLoader), # Google Slides (HTML í˜•ì‹)
        ]
        all_docs = []
        
        # ì „ì²´ ê²€ìƒ‰ì¸ ê²½ìš° finance í´ë” ì œì™¸
        if self.current_folder_path == "./pages/rag_files":
            # ëª¨ë“  í•˜ìœ„ í´ë”ë¥¼ ê²€ìƒ‰í•˜ë˜ finance í´ë”ëŠ” ì œì™¸
            for root, dirs, files in os.walk(self.current_folder_path):
                # finance í´ë” ì œì™¸
                if "finance" in dirs:
                    dirs.remove("finance")
                
                for pattern, loader_cls in loaders:
                    for file in glob.glob(os.path.join(root, pattern)):
                        try:
                            if pattern == "*.xlsx":
                                # Excel íŒŒì¼ì€ ëª¨ë“  ì‹œíŠ¸ë¥¼ ë³„ë„ë¡œ ì²˜ë¦¬
                                all_docs.extend(self._load_excel_with_all_sheets(file))
                            elif loader_cls:
                                loader = loader_cls(file)
                                all_docs.extend(loader.load())
                        except Exception as e:
                            st.warning(f"{file} ë¡œë”© ì‹¤íŒ¨: {e}")
        else:
            # íŠ¹ì • í´ë”ë§Œ ê²€ìƒ‰
            for pattern, loader_cls in loaders:
                for file in glob.glob(os.path.join(self.current_folder_path, pattern)):
                    try:
                        if pattern == "*.xlsx":
                            # Excel íŒŒì¼ì€ ëª¨ë“  ì‹œíŠ¸ë¥¼ ë³„ë„ë¡œ ì²˜ë¦¬
                            all_docs.extend(self._load_excel_with_all_sheets(file))
                        elif loader_cls:
                            loader = loader_cls(file)
                            all_docs.extend(loader.load())
                    except Exception as e:
                        st.warning(f"{file} ë¡œë”© ì‹¤íŒ¨: {e}")
        
        # ê°œì„ ëœ ì²­í‚¹ ì ìš©
        all_docs = self._improved_chunking(all_docs)
        
        self.docs = all_docs
        if all_docs:
            self.vectorstore = FAISS.from_documents(all_docs, self.embeddings)
            self.is_loaded = True
        else:
            self.vectorstore = None
            self.is_loaded = False

    def _improved_chunking(self, docs):
        """ê°œì„ ëœ ì²­í‚¹ ë°©ë²•"""
        from langchain.text_splitter import RecursiveCharacterTextSplitter
        
        # í•œêµ­ì–´ íŠ¹í™” í…ìŠ¤íŠ¸ ë¶„í• ê¸°
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,  # ë” ì‘ì€ ì²­í¬ë¡œ ì„¸ë°€í•œ ê²€ìƒ‰
            chunk_overlap=200,  # ì˜¤ë²„ë©ìœ¼ë¡œ ë¬¸ë§¥ ìœ ì§€
            length_function=len,
            separators=["\n\n", "\n", ". ", "! ", "? ", " ", ""],  # í•œêµ­ì–´ ë¬¸ì¥ êµ¬ë¶„ì ì¶”ê°€
            is_separator_regex=False
        )
        
        improved_docs = []
        
        for doc in docs:
            # ì›ë³¸ ë¬¸ì„œ ë‚´ìš©
            original_content = doc.page_content
            
            # ì²­í‚¹ ì ìš©
            chunks = text_splitter.split_text(original_content)
            
            for i, chunk in enumerate(chunks):
                # ê°œì„ ëœ ë©”íƒ€ë°ì´í„°
                metadata = doc.metadata.copy()
                metadata['chunk_id'] = i
                metadata['total_chunks'] = len(chunks)
                
                # ì²­í¬ë³„ ì¶”ê°€ ì •ë³´
                if 'source' in metadata:
                    source = metadata['source']
                    if source.endswith('.xlsx'):
                        metadata['content_type'] = 'excel_data'
                    elif source.endswith('.pdf'):
                        metadata['content_type'] = 'pdf_text'
                    elif source.endswith('.docx'):
                        metadata['content_type'] = 'word_document'
                    elif source.endswith('.pptx'):
                        metadata['content_type'] = 'powerpoint'
                    else:
                        metadata['content_type'] = 'text'
                
                # ê°œì„ ëœ ì²­í¬ ìƒì„±
                improved_doc = Document(
                    page_content=chunk,
                    metadata=metadata
                )
                
                improved_docs.append(improved_doc)
        
        return improved_docs

    def _load_excel_with_all_sheets(self, file_path):
        """Excel íŒŒì¼ì˜ ëª¨ë“  ì‹œíŠ¸ë¥¼ ë¡œë“œ"""
        try:
            import pandas as pd
            from langchain.schema import Document
            
            # Excel íŒŒì¼ì˜ ëª¨ë“  ì‹œíŠ¸ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
            excel_file = pd.ExcelFile(file_path)
            sheet_names = excel_file.sheet_names
            
            documents = []
            
            for sheet_name in sheet_names:
                try:
                    # ê° ì‹œíŠ¸ë¥¼ DataFrameìœ¼ë¡œ ì½ê¸°
                    df = pd.read_excel(file_path, sheet_name=sheet_name)
                    
                    # DataFrameì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
                    sheet_content = []
                    sheet_content.append(f"=== ì‹œíŠ¸: {sheet_name} ===")
                    
                    # ì»¬ëŸ¼ëª… ì¶”ê°€
                    if not df.empty:
                        sheet_content.append(f"ì»¬ëŸ¼: {', '.join(df.columns.tolist())}")
                        sheet_content.append("")
                        
                        # ë°ì´í„° í–‰ë“¤ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
                        for index, row in df.iterrows():
                            row_data = []
                            for col in df.columns:
                                value = str(row[col]) if pd.notna(row[col]) else ""
                                row_data.append(f"{col}: {value}")
                            sheet_content.append(f"í–‰ {index + 1}: {' | '.join(row_data)}")
                    
                    # ì‹œíŠ¸ë³„ë¡œ Document ìƒì„±
                    content = "\n".join(sheet_content)
                    if content.strip():  # ë‚´ìš©ì´ ìˆëŠ” ê²½ìš°ë§Œ ì¶”ê°€
                        doc = Document(
                            page_content=content,
                            metadata={
                                'source': file_path,
                                'sheet_name': sheet_name,
                                'file_type': 'excel'
                            }
                        )
                        documents.append(doc)
                        
                except Exception as e:
                    st.warning(f"ì‹œíŠ¸ '{sheet_name}' ë¡œë”© ì‹¤íŒ¨: {e}")
                    continue
            
            return documents
            
        except Exception as e:
            st.error(f"Excel íŒŒì¼ '{file_path}' ë¡œë”© ì‹¤íŒ¨: {e}")
            return []

    def search(self, query, k=5):
        """ì¿¼ë¦¬ì™€ ìœ ì‚¬í•œ ë¬¸ì„œ top-k ë°˜í™˜ (ê°œì„ ëœ ì„ë² ë”© ê¸°ë°˜ ê²€ìƒ‰)"""
        if not self.is_loaded:
            return []
        try:
            # 1. ë‹¤ì–‘í•œ ì¿¼ë¦¬ ë³€í˜•ìœ¼ë¡œ ê²€ìƒ‰
            query_variations = self._generate_query_variations(query)
            
            all_results = []
            seen_chunks = set()
            
            # ê° ì¿¼ë¦¬ ë³€í˜•ì— ëŒ€í•´ ê²€ìƒ‰
            for variation in query_variations:
                try:
                    # ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰
                    vector_results = self.vectorstore.similarity_search(variation, k=k)
                    
                    for doc in vector_results:
                        # ì²­í¬ë³„ ì¤‘ë³µ ì œê±° (ë” ì„¸ë°€í•œ ì œì–´)
                        chunk_key = f"{doc.metadata.get('source', '')}_{doc.metadata.get('chunk_id', 0)}"
                        if chunk_key not in seen_chunks:
                            all_results.append(doc)
                            seen_chunks.add(chunk_key)
                            
                except Exception as e:
                    st.warning(f"ì¿¼ë¦¬ ë³€í˜• '{variation}' ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                    continue
            
            # 2. í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ ì¶”ê°€ (ë³´ì¡°ì )
            keyword_results = self._keyword_search(query, k=k//2)
            for doc in keyword_results:
                chunk_key = f"{doc.metadata.get('source', '')}_{doc.metadata.get('chunk_id', 0)}"
                if chunk_key not in seen_chunks:
                    all_results.append(doc)
                    seen_chunks.add(chunk_key)
            
            # 3. ê²°ê³¼ ìŠ¤ì½”ì–´ë§ ë° ì •ë ¬
            scored_results = self._score_and_rank_results(all_results, query)
            
            return scored_results[:k]
            
        except Exception as e:
            st.error(f"FAISS ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    def _generate_query_variations(self, query):
        """ì¿¼ë¦¬ ë³€í˜• ìƒì„± (ì„ë² ë”© ê²€ìƒ‰ ìµœì í™”)"""
        variations = [query]  # ì›ë³¸ ì¿¼ë¦¬
        
        # í•œêµ­ì–´ ì´ë¦„ íŠ¹í™” ë³€í˜•
        if "ë‹˜" in query:
            # "ë‹˜" ì œê±°
            without_nim = query.replace("ë‹˜", "").strip()
            if without_nim:
                variations.append(without_nim)
        
        # ì„±ì”¨ë§Œ ì¶”ì¶œ
        if len(query) >= 2:
            if query[0] in "ê¹€ì´ë°•ìµœì •ê°•ì¡°ìœ¤ì¥ì„í•œì˜¤ì„œì‹ ê¶Œí™©ì•ˆì†¡ë¥˜ì „ê³ ë¬¸ì–‘ì†ë°°ì¡°ë°±í—ˆìœ ë‚¨ì‹¬ë…¸ì •í•˜ê³½ì„±ì°¨ì£¼ìš°êµ¬ì‹ ì„ë‚˜ì „ë¯¼":
                variations.append(query[0])
        
        # ë‹¨ì–´ë³„ ë³€í˜•
        words = query.split()
        for word in words:
            if len(word) > 1:
                variations.append(word)
        
        # ì¤‘ë³µ ì œê±°
        return list(set(variations))
    
    def _score_and_rank_results(self, results, original_query):
        """ê²°ê³¼ ìŠ¤ì½”ì–´ë§ ë° ì •ë ¬"""
        scored_results = []
        
        for doc in results:
            score = 0
            
            # 1. ì›ë³¸ ì¿¼ë¦¬ì™€ì˜ ì •í™•í•œ ì¼ì¹˜
            if original_query.lower() in doc.page_content.lower():
                score += 10
            
            # 2. ì¿¼ë¦¬ ë‹¨ì–´ë“¤ê³¼ì˜ ì¼ì¹˜
            query_words = original_query.lower().split()
            content_lower = doc.page_content.lower()
            for word in query_words:
                if word in content_lower:
                    score += 2
            
            # 3. í•œêµ­ì–´ ì´ë¦„ íŠ¹í™” ìŠ¤ì½”ì–´ë§
            if "ë‹˜" in original_query:
                name_without_nim = original_query.replace("ë‹˜", "").strip()
                if name_without_nim and name_without_nim.lower() in content_lower:
                    score += 5
            
            # 4. ì²­í¬ í¬ê¸°ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜ (ì‘ì€ ì²­í¬ê°€ ë” ì •í™•í•  ìˆ˜ ìˆìŒ)
            chunk_size = len(doc.page_content)
            if chunk_size < 500:
                score += 1
            elif chunk_size > 2000:
                score -= 1
            
            # ìŠ¤ì½”ì–´ë¥¼ ë©”íƒ€ë°ì´í„°ì— ì €ì¥
            doc.metadata['search_score'] = score
            scored_results.append(doc)
        
        # ìŠ¤ì½”ì–´ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        scored_results.sort(key=lambda x: x.metadata.get('search_score', 0), reverse=True)
        return scored_results
    
    def _keyword_search(self, query, k=5):
        """í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ (ë¶€ë¶„ ì¼ì¹˜ ì§€ì›)"""
        try:
            # ê²€ìƒ‰ì–´ ì „ì²˜ë¦¬
            query_terms = self._extract_keywords(query)
            
            keyword_results = []
            for doc in self.docs:
                score = self._calculate_keyword_score(doc.page_content, query_terms)
                if score > 0:
                    # ì›ë³¸ ë¬¸ì„œë¥¼ ë³µì‚¬í•˜ì—¬ ìŠ¤ì½”ì–´ ì¶”ê°€
                    metadata_copy = doc.metadata.copy()
                    metadata_copy['keyword_score'] = score
                    doc_copy = Document(
                        page_content=doc.page_content,
                        metadata=metadata_copy
                    )
                    keyword_results.append(doc_copy)
            
            # ìŠ¤ì½”ì–´ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            keyword_results.sort(key=lambda x: x.metadata.get('keyword_score', 0), reverse=True)
            return keyword_results[:k]
            
        except Exception as e:
            st.warning(f"í‚¤ì›Œë“œ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    def _extract_keywords(self, query):
        """ê²€ìƒ‰ì–´ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # í•œêµ­ì–´ íŠ¹ì„±ì„ ê³ ë ¤í•œ í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = []
        
        # ì „ì²´ ê²€ìƒ‰ì–´
        keywords.append(query.lower())
        
        # ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬ëœ ë‹¨ì–´ë“¤
        words = query.split()
        for word in words:
            if len(word) > 1:  # 1ê¸€ì ë‹¨ì–´ ì œì™¸
                keywords.append(word.lower())
        
        # í•œêµ­ì–´ íŠ¹ì„±: "ë‹˜" ì œê±° í›„ ê²€ìƒ‰
        if "ë‹˜" in query:
            without_nim = query.replace("ë‹˜", "").strip()
            if without_nim:
                keywords.append(without_nim.lower())
        
        # í•œêµ­ì–´ íŠ¹ì„±: ì„±ì”¨ë§Œ ì¶”ì¶œ
        if len(query) >= 2:
            # ì²« ê¸€ìê°€ ì„±ì”¨ì¼ ê°€ëŠ¥ì„±ì´ ë†’ì€ ê²½ìš°
            if query[0] in "ê¹€ì´ë°•ìµœì •ê°•ì¡°ìœ¤ì¥ì„í•œì˜¤ì„œì‹ ê¶Œí™©ì•ˆì†¡ë¥˜ì „ê³ ë¬¸ì–‘ì†ë°°ì¡°ë°±í—ˆìœ ë‚¨ì‹¬ë…¸ì •í•˜ê³½ì„±ì°¨ì£¼ìš°êµ¬ì‹ ì„ë‚˜ì „ë¯¼":
                keywords.append(query[0].lower())
        
        return list(set(keywords))  # ì¤‘ë³µ ì œê±°
    
    def _calculate_keyword_score(self, content, keywords):
        """í‚¤ì›Œë“œ ë§¤ì¹­ ìŠ¤ì½”ì–´ ê³„ì‚°"""
        content_lower = content.lower()
        score = 0
        
        for keyword in keywords:
            if keyword in content_lower:
                # í‚¤ì›Œë“œ ê¸¸ì´ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜
                weight = len(keyword) / max(len(max(keywords, key=len)), 1)
                score += weight
                
                # ì •í™•í•œ ì¼ì¹˜ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜
                if keyword == content_lower or f" {keyword} " in f" {content_lower} ":
                    score += 2
        
        return score

# ===== ì±—ë´‡ í´ë˜ìŠ¤ (FAISS ê¸°ë°˜) =====
class FileRAGChatbot:
    def __init__(self):
        self.llm_client = LLMClient()
        self.rag_system = FileRAGSystem()
        self.conversation_history = []

    def generate_response(self, user_query, provider='openai', model=None, temperature=0.7):
        try:
            # 1. RAGë¥¼ í†µí•œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ (ê°œì„ ëœ ê²€ìƒ‰)
            relevant_docs = self.rag_system.search(user_query, k=5)
            
            # ë””ë²„ê·¸ ì •ë³´ (ê°œë°œ ì¤‘ì—ë§Œ ì‚¬ìš©)
            if st.session_state.get('debug_mode', False):
                st.info(f"ğŸ” ê²€ìƒ‰ì–´: '{user_query}'")
                st.info(f"ğŸ“„ ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(relevant_docs)}")
                if relevant_docs:
                    for i, doc in enumerate(relevant_docs[:3], 1):
                        score = doc.metadata.get('search_score', 'N/A')
                        chunk_info = f"ì²­í¬ {doc.metadata.get('chunk_id', 0)}/{doc.metadata.get('total_chunks', 1)}"
                        st.info(f"ë¬¸ì„œ {i}: {doc.metadata.get('source', 'Unknown')} (ìŠ¤ì½”ì–´: {score}, {chunk_info})")
                        st.info(f"ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {doc.page_content[:100]}...")
            
            # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš° ë” êµ¬ì²´ì ì¸ ì•ˆë‚´ ì œê³µ
            if not relevant_docs:
                # ê²€ìƒ‰ì–´ ë¶„ì„ì„ í†µí•œ ì œì•ˆ
                suggestions = self._generate_search_suggestions(user_query)
                return f"""âŒ **í•´ë‹¹ ì •ë³´ê°€ ë¬¸ì„œì— ì—†ìŠµë‹ˆë‹¤.**

ğŸ’¡ **ê²€ìƒ‰ ì œì•ˆ:**
{suggestions}

ğŸ” **ë‹¤ë¥¸ ë°©ë²•:**
â€¢ ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”
â€¢ ê´€ë ¨ ë¶€ì„œëª…ì´ë‚˜ ì§ì±…ëª…ìœ¼ë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”
â€¢ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ê²€ìƒ‰ ë²”ìœ„ë¥¼ í™•ì¥í•´ë³´ì„¸ìš”""", None
            
            # 2. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context = self._build_context(relevant_docs)
            # 3. í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = self._build_prompt(user_query, context)
            # 4. LLM ì‘ë‹µ ìƒì„±
            if model is None:
                models = self.llm_client.get_models_for_provider(provider)
                model = models[0] if models else None
            if not model:
                return "ì§€ì›í•˜ëŠ” ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.", None
            response, error = self.llm_client.generate_response(
                provider, model, prompt, temperature
            )
            if error:
                return f"ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {error}", None
            # 5. ëŒ€í™” ê¸°ë¡ ì—…ë°ì´íŠ¸
            self.conversation_history.append({
                'user': user_query,
                'assistant': response,
                'timestamp': datetime.now(),
                'provider': provider,
                'model': model
            })
            return response, relevant_docs
        except Exception as e:
            return f"ì±—ë´‡ ì˜¤ë¥˜: {str(e)}", None
    
    def _generate_search_suggestions(self, query):
        """ê²€ìƒ‰ì–´ì— ëŒ€í•œ ì œì•ˆ ìƒì„±"""
        suggestions = []
        
        # í•œêµ­ì–´ ì´ë¦„ ê´€ë ¨ ì œì•ˆ
        if "ë‹˜" in query:
            name_without_nim = query.replace("ë‹˜", "").strip()
            if name_without_nim:
                suggestions.append(f"â€¢ '{name_without_nim}'ìœ¼ë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”")
                suggestions.append(f"â€¢ '{name_without_nim}ë‹˜'ìœ¼ë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”")
        
        # ì„±ì”¨ë§Œ ìˆëŠ” ê²½ìš°
        if len(query) == 1 and query in "ê¹€ì´ë°•ìµœì •ê°•ì¡°ìœ¤ì¥ì„í•œì˜¤ì„œì‹ ê¶Œí™©ì•ˆì†¡ë¥˜ì „ê³ ë¬¸ì–‘ì†ë°°ì¡°ë°±í—ˆìœ ë‚¨ì‹¬ë…¸ì •í•˜ê³½ì„±ì°¨ì£¼ìš°êµ¬ì‹ ì„ë‚˜ì „ë¯¼":
            suggestions.append(f"â€¢ '{query}ì”¨'ë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”")
            suggestions.append(f"â€¢ '{query}ë‹˜'ìœ¼ë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”")
        
        # ì¼ë°˜ì ì¸ ê²€ìƒ‰ ì œì•ˆ
        suggestions.append("â€¢ ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”")
        suggestions.append("â€¢ ê´€ë ¨ ë¶€ì„œëª…ì´ë‚˜ ì§ì±…ëª…ìœ¼ë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”")
        suggestions.append("â€¢ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ê²€ìƒ‰ ë²”ìœ„ë¥¼ í™•ì¥í•´ë³´ì„¸ìš”")
        
        return "\n".join(suggestions)

    def _build_context(self, relevant_docs):
        context_parts = []
        for i, doc in enumerate(relevant_docs, 1):
            title = doc.metadata.get('source', f'ë¬¸ì„œ {i}')
            content = doc.page_content[:1000]
            context_parts.append(f"ë¬¸ì„œ {i} - {title}:\n{content}")
        return "\n\n".join(context_parts)

    def _build_prompt(self, user_query, context):
        system_prompt = f"""ë‹¹ì‹ ì€ ì•„ì¹´ë¼ë¼ì´í”„ì˜ ì‚¬ë‚´ ì±—ë´‡ì…ë‹ˆë‹¤.

ã€ë‹µë³€ ê·œì¹™ã€‘
1. ì•„ë˜ ë¬¸ì„œ ë‚´ìš©ì— ê·¼ê±°í•´ì„œë§Œ ë‹µë³€í•˜ì„¸ìš”.
2. ë¬¸ì„œì— ì—†ëŠ” ì •ë³´ëŠ” 'í•´ë‹¹ ì •ë³´ê°€ ë¬¸ì„œì— ì—†ìŠµë‹ˆë‹¤'ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.
3. í•œêµ­ì–´ ì´ë¦„ ê²€ìƒ‰ ì‹œ ì„±ì”¨, ì´ë¦„, ì „ì²´ ì´ë¦„, "ë‹˜" í¬í•¨/ì œì™¸ ë“± ë‹¤ì–‘í•œ í˜•íƒœë¥¼ ê³ ë ¤í•˜ì„¸ìš”.
4. ë¶€ë¶„ ì¼ì¹˜ë‚˜ ìœ ì‚¬í•œ í‘œí˜„ë„ ì¸ì‹í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
5. ë‹µë³€ì€ ì •í™•í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ì œê³µí•˜ì„¸ìš”.

ã€ë‹µë³€ í˜•ì‹ã€‘
ë‹µë³€ì„ ì œê³µí•  ë•ŒëŠ” ë‹¤ìŒ í˜•ì‹ì„ ë”°ë¼ì£¼ì„¸ìš”:

ğŸ“‹ **í•µì‹¬ ì •ë³´**
- ê°€ì¥ ì¤‘ìš”í•œ ì •ë³´ë¥¼ ê°„ë‹¨íˆ ìš”ì•½

ğŸ“„ **ìƒì„¸ ë‚´ìš©**
- êµ¬ì²´ì ì¸ ë‚´ìš©ì„ ë‹¨ë½ë³„ë¡œ ì •ë¦¬
- ê´€ë ¨ ë°ì´í„°ë‚˜ ìˆ˜ì¹˜ê°€ ìˆë‹¤ë©´ í¬í•¨

ğŸ”— **ê´€ë ¨ ì •ë³´**
- ì¶”ê°€ë¡œ ê´€ë ¨ëœ ì •ë³´ë‚˜ ì°¸ê³ ì‚¬í•­

ğŸ“š **ì°¸ê³  ë¬¸ì„œ**
- ë‹µë³€ì˜ ê·¼ê±°ê°€ ëœ ë¬¸ì„œ ì •ë³´

ã€ê²€ìƒ‰ íŒã€‘
- "ì¥í˜ì‹ ë‹˜" â†’ "ì¥í˜ì‹ ", "í˜ì‹ ", "ì¥" ë“±ìœ¼ë¡œë„ ê²€ìƒ‰
- "ê¹€ì˜ìˆ˜ë‹˜" â†’ "ê¹€ì˜ìˆ˜", "ì˜ìˆ˜", "ê¹€" ë“±ìœ¼ë¡œë„ ê²€ìƒ‰
- ì§ì±…ëª…, ë¶€ì„œëª…, ì—­í•  ë“±ë„ ë‹¤ì–‘í•œ í‘œí˜„ìœ¼ë¡œ ê²€ìƒ‰

ì•„ë˜ëŠ” ê´€ë ¨ ë¬¸ì„œ ë‚´ìš©ì…ë‹ˆë‹¤:
{context}

ì‚¬ìš©ì ì§ˆë¬¸: {user_query}"""
        return [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_query}
        ]

    def clear_history(self):
        self.conversation_history = []

# ===== Perplexity APIë¥¼ í™œìš©í•œ ì‹œì¥ ì¡°ì‚¬ ê¸°ëŠ¥ =====
def perform_perplexity_search(query, debug_mode=False):
    """Perplexity APIë¥¼ ì‚¬ìš©í•œ ê²€ìƒ‰ ìˆ˜í–‰"""
    api_key = os.getenv('PERPLEXITY_API_KEY')
    if not api_key:
        st.error("Perplexity API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
    
    try:
        url = "https://api.perplexity.ai/chat/completions"
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": "sonar-pro",
            "messages": [
                {
                    "role": "user",
                    "content": f"ë‹¤ìŒ ì£¼ì œì— ëŒ€í•´ ìµœì‹  ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸íˆ ì¡°ì‚¬í•´ì£¼ì„¸ìš”: {query}"
                }
            ],
            "max_tokens": 2000,
            "temperature": 0.1
        }
        
        if debug_mode:
            st.write("=== Perplexity API ìš”ì²­ ë””ë²„ê·¸ ì •ë³´ ===")
            st.write(f"URL: {url}")
            st.write(f"Headers: {headers}")
            st.write(f"Data: {data}")
        
        response = requests.post(url, headers=headers, json=data, timeout=30)
        
        if debug_mode:
            st.write("\n=== Perplexity API ì‘ë‹µ ë””ë²„ê·¸ ì •ë³´ ===")
            st.write(f"Status Code: {response.status_code}")
            st.write(f"Response Headers: {dict(response.headers)}")
        
        if response.status_code == 200:
            result = response.json()
            if 'choices' in result and len(result['choices']) > 0:
                content = result['choices'][0]['message']['content']
                if debug_mode:
                    st.write(f"Content: {content[:500]}...")
                return content
            else:
                st.error("Perplexity API ì‘ë‹µì—ì„œ contentë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None
        else:
            error_msg = f"Perplexity API ì˜¤ë¥˜ (ìƒíƒœ ì½”ë“œ: {response.status_code})"
            if debug_mode:
                st.write(f"Error Response: {response.text}")
            st.error(error_msg)
            return None
            
    except requests.exceptions.Timeout:
        st.error("Perplexity API ìš”ì²­ ì‹œê°„ ì´ˆê³¼")
        return None
    except requests.exceptions.RequestException as e:
        st.error(f"Perplexity API ìš”ì²­ ì‹¤íŒ¨: {str(e)}")
        return None
    except Exception as e:
        st.error(f"Perplexity API ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

# ===== ë©€í‹°ì—ì´ì „íŠ¸ ë¶„ì„ ê¸°ëŠ¥ =====
def analyze_with_finance_persona(user_query, persona_key, persona_info, rag_context="", market_research="", model_name="claude-3-7-sonnet-latest"):
    """ì¬ë¬´ ì „ë¬¸ê°€ í˜ë¥´ì†Œë‚˜ë¡œ ë¶„ì„ ìˆ˜í–‰"""
    try:
        # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        analysis_prompt = f"""
ë‹¤ìŒ ì£¼ì œ/ì§ˆë¬¸ì— ëŒ€í•´ {persona_info['role']} ê´€ì ì—ì„œ ì „ë¬¸ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:

ã€ë¶„ì„ ëŒ€ìƒã€‘
{user_query}

ã€ì „ë¬¸ê°€ ì—­í• ã€‘
{persona_info['name']} ({persona_info['emoji']})
{persona_info['expertise']}

ã€ë¶„ì„ ê´€ì ã€‘
{persona_info['perspective']}

"""

        # RAG ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
        if rag_context:
            analysis_prompt += f"""
ã€ë‚´ë¶€ ì¬ë¬´ ë°ì´í„°ã€‘
{rag_context}

ì´ ë‚´ë¶€ ì¬ë¬´ ë°ì´í„°ë¥¼ ë°˜ë“œì‹œ í™œìš©í•˜ì—¬ ë¶„ì„í•´ì£¼ì„¸ìš”.

"""

        # ì‹œì¥ ì¡°ì‚¬ ê²°ê³¼ ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
        if market_research:
            analysis_prompt += f"""
ã€ì‹œì¥ ì¡°ì‚¬ ê²°ê³¼ã€‘
{market_research}

ì´ ì‹œì¥ ì¡°ì‚¬ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì—¬ ë¶„ì„í•´ì£¼ì„¸ìš”.

"""

        analysis_prompt += f"""
ã€ì „ë¬¸ê°€ ìˆ˜ì¤€ ë¶„ì„ ìš”êµ¬ì‚¬í•­ã€‘
- {persona_info['perspective']}
- ì—…ê³„ ìµœê³  ìˆ˜ì¤€ì˜ ìƒì„¸í•˜ê³  ê¹Šì´ ìˆëŠ” ì „ë¬¸ ë¶„ì„ ì œê³µ
- êµ¬ì²´ì ì¸ ìˆ˜ì¹˜, ì§€í‘œ, ë°ì´í„°ë¥¼ í¬í•¨í•œ ì •ëŸ‰ì  ë¶„ì„
- ë‹¨ê³„ë³„ ì‹¤í–‰ ê³„íšê³¼ íƒ€ì„ë¼ì¸ì„ í¬í•¨í•œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì œì•ˆ
- ë¦¬ìŠ¤í¬ ìš”ì¸ê³¼ ì™„í™” ì „ëµì„ êµ¬ì²´ì ìœ¼ë¡œ ë¶„ì„
- ì„±ê³¼ ì¸¡ì • ì§€í‘œ(KPI)ì™€ ëª¨ë‹ˆí„°ë§ ë°©ì•ˆ ëª…ì‹œ
- ë‹¤ë¥¸ ë¶€ì„œì™€ì˜ êµ¬ì²´ì  í˜‘ì—… ë°©ì•ˆê³¼ ì—­í•  ë¶„ë‹´
- ì˜ˆìƒ ë¹„ìš©, ë¦¬ì†ŒìŠ¤, ê¸°ê°„ì„ í¬í•¨í•œ ìƒì„¸í•œ ì‹¤í–‰ ê³„íš
{'- ì œê³µëœ ë‚´ë¶€ ì¬ë¬´ ë°ì´í„°ë¥¼ ë°˜ë“œì‹œ ë¶„ì„ì— í™œìš©í•˜ê³  ì¸ì‚¬ì´íŠ¸ ë„ì¶œ' if rag_context else ''}
{'- ì œê³µëœ ì‹œì¥ ì¡°ì‚¬ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì—¬ ì™¸ë¶€ í™˜ê²½ì„ ê³ ë ¤í•œ ë¶„ì„ ìˆ˜í–‰' if market_research else ''}

ã€ì‘ë‹µ í˜•ì‹ã€‘
## í•µì‹¬ ë¶„ì„
(2-3ì¤„ë¡œ í•µì‹¬ í¬ì¸íŠ¸ ìš”ì•½)

## ìƒì„¸ ë¶„ì„
(ì „ë¬¸ ë¶„ì•¼ ê´€ì ì—ì„œ ìƒì„¸í•œ ë¶„ì„)

## ì‹¤í–‰ ì œì•ˆ
(êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜ ì•„ì´í…œë“¤)

## ë‹¤ë¥¸ ë¶€ì„œ í˜‘ì—… ë°©ì•ˆ
(ë‹¤ë¥¸ ì „ë¬¸ê°€ì™€ì˜ í˜‘ì—…ì´ í•„ìš”í•œ ë¶€ë¶„)

## ë¦¬ìŠ¤í¬ ë° ê³ ë ¤ì‚¬í•­
(ì£¼ì˜í•´ì•¼ í•  ì ë“¤)

## ì°¸ê³  ìë£Œ
(ë¶„ì„ì— í™œìš©í•œ ë‚´ë¶€ ë°ì´í„° ë° ì‹œì¥ ì¡°ì‚¬ ê²°ê³¼ ìš”ì•½)
"""

        # ëª¨ë¸ ì •ë³´ ë””ë²„ê¹…
        st.info(f"{persona_key} ë¶„ì„ ì‹œì‘ - ëª¨ë¸: {model_name}")
        
        result = get_ai_response(analysis_prompt, model_name, persona_info['system_prompt'])
        
        if result and not result.startswith("ì‘ë‹µ ìƒì„± ì˜¤ë¥˜"):
            return result
        else:
            st.error(f"âŒ {persona_key} ë¶„ì„ ì‹¤íŒ¨: {result}")
            return None

    except Exception as e:
        st.error(f"âŒ {persona_key} ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def analyze_persona_concurrent_finance(args):
    """ThreadPoolExecutor ë˜í¼ í•¨ìˆ˜"""
    user_query, persona_key, persona_info, rag_context, market_research, model_name = args
    try:
        result = analyze_with_finance_persona(user_query, persona_key, persona_info, rag_context, market_research, model_name)
        if result is None:
            return persona_key, f"AI ì‘ë‹µì´ Noneì…ë‹ˆë‹¤. API í‚¤ë‚˜ ëª¨ë¸ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.", False
        return persona_key, result, True
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        return persona_key, f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}\nìƒì„¸: {error_details}", False

def synthesize_finance_analysis(user_query, persona_analyses, rag_context="", market_research="", model_name="claude-3-7-sonnet-latest"):
    """ìµœì¢… ë³´ê³ ì„œ ì‘ì„±ìê°€ ëª¨ë“  ë¶„ì„ì„ ì¢…í•©"""
    try:
        synthesis_prompt = f"""
ë‹¤ìŒì€ ìš°ë¦¬ íšŒì‚¬ ì¬ë¬´ ì „ë¬¸ê°€ë“¤ì´ ë¶„ì„í•œ ë‚´ìš©ì…ë‹ˆë‹¤. 
ìµœì¢… ë³´ê³ ì„œ ì‘ì„±ìë¡œì„œ ì´ë“¤ì˜ ë¶„ì„ì„ ì¢…í•©í•˜ì—¬ ì‹¤í˜„ ê°€ëŠ¥í•œ ì „ëµê³¼ ì‹¤í–‰ ê³„íšì„ ì œì‹œí•´ì£¼ì„¸ìš”.

ã€ì›ë˜ ì£¼ì œ/ì§ˆë¬¸ã€‘
{user_query}

ã€ë‚´ë¶€ ì¬ë¬´ ë°ì´í„°ã€‘
{rag_context if rag_context else "ë‚´ë¶€ ì¬ë¬´ ë°ì´í„° ì—†ìŒ"}

ã€ì‹œì¥ ì¡°ì‚¬ ê²°ê³¼ã€‘
{market_research if market_research else "ì‹œì¥ ì¡°ì‚¬ ê²°ê³¼ ì—†ìŒ"}

ã€ê° ì „ë¬¸ê°€ ë¶„ì„ ê²°ê³¼ã€‘
"""
        
        for persona_key, analysis in persona_analyses.items():
            if analysis and analysis.get('result'):
                persona_info = FINANCE_PERSONAS[persona_key]
                synthesis_prompt += f"""
--- {persona_info['emoji']} {persona_info['name']} ë¶„ì„ ---
{analysis['result']}

"""
        
        synthesis_prompt += """
ã€ìµœì¢… ë³´ê³ ì„œ ì‘ì„± ìš”êµ¬ì‚¬í•­ã€‘
- ê° ì „ë¬¸ê°€ì˜ ê´€ì ì„ ê· í˜•ìˆê²Œ ê³ ë ¤
- ì‹¤í˜„ ê°€ëŠ¥í•œ ìš°ì„ ìˆœìœ„ ì„¤ì •
- êµ¬ì²´ì ì¸ ì‹¤í–‰ ê³„íšê³¼ íƒ€ì„ë¼ì¸ ìˆ˜ë¦½
- ë¦¬ìŠ¤í¬ì™€ ê¸°íšŒ ìš”ì¸ì˜ ì¢…í•©ì  í‰ê°€
- ëª…í™•í•œ ì˜ì‚¬ê²°ì • ë°©í–¥ ì œì‹œ
- ì„±ê³¼ ì¸¡ì • ì§€í‘œì™€ ëª¨ë‹ˆí„°ë§ ë°©ì•ˆ í¬í•¨

ã€ì‘ë‹µ í˜•ì‹ã€‘
## ğŸ¯ í•µì‹¬ ê²°ë¡  ë° ì „ëµì  ì œì•ˆ
(ìµœì¢… ë³´ê³ ì„œ ì‘ì„±ìë¡œì„œì˜ í•µì‹¬ íŒë‹¨ê³¼ ì œì•ˆì‚¬í•­)

## ğŸ“Š ì „ë¬¸ê°€ ë¶„ì„ ì¢…í•©
(ê° ì „ë¬¸ê°€ ì˜ê²¬ì˜ í•µì‹¬ í¬ì¸íŠ¸ë“¤)

## ğŸš€ í†µí•© ì‹¤í–‰ ê³„íš
(ë‹¨ê³„ë³„ ì‹¤í–‰ ë°©ì•ˆê³¼ ìš°ì„ ìˆœìœ„)

## âš–ï¸ ë¦¬ìŠ¤í¬ vs ê¸°íšŒ
(ì¢…í•©ì  ë¦¬ìŠ¤í¬-ê¸°íšŒ ë¶„ì„)

## ğŸ“ˆ ì„±ê³¼ ì§€í‘œ ë° ëª¨ë‹ˆí„°ë§
(ì„±ê³¼ ì¸¡ì • ë°©ë²•ê³¼ KPI)

## ğŸ’¡ ìµœì¢… ë©”ì‹œì§€
(ì¡°ì§ì— ì „ë‹¬í•  í•µì‹¬ ë©”ì‹œì§€)

## ğŸ“‹ ì°¸ê³  ìë£Œ
(ë¶„ì„ì— í™œìš©í•œ ë‚´ë¶€ ë°ì´í„° ë° ì‹œì¥ ì¡°ì‚¬ ê²°ê³¼)
"""
        
        return get_ai_response(synthesis_prompt, model_name, REPORT_SYNTHESIZER['system_prompt'])

    except Exception as e:
        st.error(f"âŒ ìµœì¢… ë³´ê³ ì„œ ì‘ì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

# ===== AI ì‘ë‹µ ìƒì„± í•¨ìˆ˜ =====
def get_ai_response(prompt, model_name, system_prompt=""):
    """AI ì‘ë‹µ ìƒì„± (LLMClient í™œìš©)"""
    try:
        # LLMClient ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        llm_client = LLMClient()
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ì œê³µì í™•ì¸
        available_providers = llm_client.get_available_providers()
        if not available_providers:
            return "ì‚¬ìš© ê°€ëŠ¥í•œ LLM ì œê³µìê°€ ì—†ìŠµë‹ˆë‹¤."
        
        # ëª¨ë¸ ì´ë¦„ì—ì„œ ì œê³µì ì¶”ì¶œ
        provider = None
        if model_name:
            # ëª¨ë¸ ì´ë¦„ìœ¼ë¡œ ì œê³µì íŒë‹¨
            if model_name.startswith('gpt-'):
                provider = 'openai'
            elif model_name.startswith('claude-'):
                provider = 'anthropic'
            elif model_name.startswith('sonar-') or model_name.startswith('llama-'):
                provider = 'perplexity'
            elif model_name.startswith('gemini-'):
                provider = 'google'
            elif ':' in model_name:  # ollama ëª¨ë¸
                provider = 'ollama'
        
        # ì œê³µìë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©
        if not provider or provider not in available_providers:
            # OpenAIë¥¼ ìš°ì„ ìœ¼ë¡œ, ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ì‚¬ìš© ê°€ëŠ¥í•œ ì œê³µì
            provider = 'openai' if 'openai' in available_providers else available_providers[0]
        
        # ëª¨ë¸ ì„¤ì •
        if not model_name:
            models = llm_client.get_models_for_provider(provider)
            model_name = models[0] if models else None
        
        if not model_name:
            return "ì§€ì›í•˜ëŠ” ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤."
        
        # ë©”ì‹œì§€ êµ¬ì„±
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": prompt})
        
        # ë””ë²„ê¹… ì •ë³´
        st.info(f"AI ì‘ë‹µ ìƒì„± - ì œê³µì: {provider}, ëª¨ë¸: {model_name}")
        
        # ì‘ë‹µ ìƒì„±
        response, error = llm_client.generate_response(provider, model_name, messages, temperature=0.7)
        
        if error:
            st.error(f"LLM ì‘ë‹µ ì˜¤ë¥˜: {error}")
            return f"ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {error}"
        
        return response
        
    except Exception as e:
        return f"AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"

# ===== PDF ìƒì„± ê¸°ëŠ¥ =====
def create_finance_analysis_pdf(user_query, persona_analyses, final_report, rag_context="", market_research=""):
    """ì¬ë¬´ ë¶„ì„ ê²°ê³¼ë¥¼ PDFë¡œ ìƒì„±"""
    try:
        # ReportLabì„ ìš°ì„  ì‚¬ìš© (í•œê¸€ í°íŠ¸ ë¬¸ì œ í•´ê²°)
        return create_finance_analysis_pdf_reportlab(user_query, persona_analyses, final_report, rag_context, market_research)
    except Exception as e:
        st.error(f"PDF ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

def create_finance_analysis_pdf_fpdf2(user_query, persona_analyses, final_report, rag_context="", market_research=""):
    """FPDF2ë¥¼ ì‚¬ìš©í•œ ì¬ë¬´ ë¶„ì„ PDF ìƒì„±"""
    try:
        # PDF ë²„í¼ ìƒì„±
        pdf_buffer = io.BytesIO()
        
        # FPDF2 ê°ì²´ ìƒì„±
        pdf = FPDF()
        pdf.add_page()
        
        # í•œê¸€ í°íŠ¸ ì„¤ì •
        try:
            import platform
            system = platform.system()
            
            # ìš´ì˜ì²´ì œë³„ í•œê¸€ í°íŠ¸ ê²½ë¡œ
            font_paths = []
            if system == "Darwin":  # macOS
                font_paths = [
                    "/System/Library/Fonts/AppleGothic.ttf",
                    "/System/Library/Fonts/Supplemental/Arial Unicode MS.ttf",
                    "/Library/Fonts/AppleGothic.ttf"
                ]
            elif system == "Windows":
                font_paths = [
                    "C:/Windows/Fonts/malgun.ttf",
                    "C:/Windows/Fonts/NanumGothic.ttf",
                    "C:/Windows/Fonts/gulim.ttc"
                ]
            else:  # Linux
                font_paths = [
                    "/usr/share/fonts/truetype/nanum/NanumGothic.ttf",
                    "/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf"
                ]
            
            # í°íŠ¸ ë“±ë¡ ì‹œë„
            font_registered = False
            for font_path in font_paths:
                try:
                    if os.path.exists(font_path):
                        pdf.add_font('KoreanFont', '', font_path, uni=True)
                        font_name = 'KoreanFont'
                        font_registered = True
                        st.info(f"í•œê¸€ í°íŠ¸ ë“±ë¡ ì„±ê³µ: {font_path}")
                        break
                except Exception as e:
                    st.warning(f"í°íŠ¸ ë“±ë¡ ì‹¤íŒ¨ ({font_path}): {e}")
                    continue
            
            # í°íŠ¸ ë“±ë¡ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©
            if not font_registered:
                # FPDF2ì˜ ë‚´ì¥ ìœ ë‹ˆì½”ë“œ í°íŠ¸ ì‹œë„
                try:
                    pdf.add_font('DejaVu', '', uni=True)
                    font_name = 'DejaVu'
                    st.info("DejaVu ìœ ë‹ˆì½”ë“œ í°íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                except:
                    font_name = 'Arial'
                    st.warning("í•œê¸€ í°íŠ¸ ë“±ë¡ ì‹¤íŒ¨. ê¸°ë³¸ í°íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                
        except Exception as e:
            font_name = 'Arial'
            st.warning(f"í°íŠ¸ ì„¤ì • ì˜¤ë¥˜: {e}. ê¸°ë³¸ í°íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        
        # ì œëª©
        pdf.set_font(font_name, 'B', 16)
        pdf.set_text_color(30, 58, 138)  # darkblue
        pdf.cell(0, 10, 'ë©€í‹°ì—ì´ì „íŠ¸ ì¬ë¬´ ë¶„ì„ ë³´ê³ ì„œ', ln=True, align='C')
        pdf.ln(10)
        
        # ë¶„ì„ ìš”ì²­
        pdf.set_font(font_name, 'B', 12)
        pdf.set_text_color(30, 58, 138)
        pdf.cell(0, 8, 'ë¶„ì„ ìš”ì²­', ln=True)
        pdf.set_font(font_name, '', 10)
        pdf.set_text_color(0, 0, 0)
        pdf.multi_cell(0, 6, user_query)
        pdf.ln(5)
        
        # ë¶„ì„ ì¼ì‹œ
        pdf.set_font(font_name, 'B', 12)
        pdf.set_text_color(30, 58, 138)
        pdf.cell(0, 8, 'ë¶„ì„ ì¼ì‹œ', ln=True)
        pdf.set_font(font_name, '', 10)
        pdf.set_text_color(0, 0, 0)
        pdf.cell(0, 6, datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M'), ln=True)
        pdf.ln(5)
        
        # ë‚´ë¶€ ì¬ë¬´ ë°ì´í„° (ìˆëŠ” ê²½ìš°)
        if rag_context:
            pdf.set_font(font_name, 'B', 12)
            pdf.set_text_color(30, 58, 138)
            pdf.cell(0, 8, 'ë‚´ë¶€ ì¬ë¬´ ë°ì´í„°', ln=True)
            pdf.set_font(font_name, '', 10)
            pdf.set_text_color(0, 0, 0)
            pdf.multi_cell(0, 6, 'ë¶„ì„ì— í™œìš©ëœ ë‚´ë¶€ ì¬ë¬´ ë°ì´í„°ê°€ í¬í•¨ë˜ì—ˆìŠµë‹ˆë‹¤.')
            pdf.ln(5)
        
        # ì‹œì¥ ì¡°ì‚¬ ê²°ê³¼ (ìˆëŠ” ê²½ìš°)
        if market_research:
            pdf.set_font(font_name, 'B', 12)
            pdf.set_text_color(30, 58, 138)
            pdf.cell(0, 8, 'ì‹œì¥ ì¡°ì‚¬ ê²°ê³¼', ln=True)
            pdf.set_font(font_name, '', 10)
            pdf.set_text_color(0, 0, 0)
            pdf.multi_cell(0, 6, market_research[:1000] + ('...' if len(market_research) > 1000 else ''))
            pdf.ln(5)
        
        # ì „ë¬¸ê°€ë³„ ë¶„ì„
        pdf.set_font(font_name, 'B', 12)
        pdf.set_text_color(30, 58, 138)
        pdf.cell(0, 8, 'ì „ë¬¸ê°€ë³„ ë¶„ì„', ln=True)
        pdf.ln(5)
        
        for persona_key, analysis in persona_analyses.items():
            if analysis.get('success') and analysis.get('result'):
                persona_info = FINANCE_PERSONAS[persona_key]
                
                # ì „ë¬¸ê°€ ì œëª©
                pdf.set_font(font_name, 'B', 11)
                pdf.set_text_color(30, 58, 138)
                pdf.cell(0, 6, f"{persona_info['name']}", ln=True)
                
                # ë¶„ì„ ë‚´ìš©
                pdf.set_font(font_name, '', 10)
                pdf.set_text_color(0, 0, 0)
                pdf.multi_cell(0, 6, analysis['result'])
                pdf.ln(5)
        
        # ìµœì¢… ì¢…í•© ë³´ê³ ì„œ
        if final_report:
            pdf.add_page()
            pdf.set_font(font_name, 'B', 12)
            pdf.set_text_color(30, 58, 138)
            pdf.cell(0, 8, 'ìµœì¢… ì¢…í•© ë³´ê³ ì„œ', ln=True)
            pdf.ln(5)
            
            pdf.set_font(font_name, '', 10)
            pdf.set_text_color(0, 0, 0)
            pdf.multi_cell(0, 6, final_report)
        
        # PDF ì¶œë ¥
        pdf.output(pdf_buffer)
        pdf_buffer.seek(0)
        
        return pdf_buffer
        
    except Exception as e:
        st.error(f"FPDF2 PDF ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

def create_finance_analysis_pdf_weasyprint(user_query, persona_analyses, final_report, rag_context="", market_research=""):
    """WeasyPrintë¥¼ ì‚¬ìš©í•œ ì¬ë¬´ ë¶„ì„ PDF ìƒì„±"""
    try:
        # HTML ì½˜í…ì¸  ìƒì„±
        html_content = f"""
        <!DOCTYPE html>
        <html lang="ko">
        <head>
            <meta charset="utf-8">
            <title>ì¬ë¬´ ë¶„ì„ ë³´ê³ ì„œ</title>
            <style>
                body {{
                    font-family: 'Malgun Gothic', 'AppleGothic', 'NanumGothic', 'Arial Unicode MS', sans-serif;
                    font-size: 12px;
                    line-height: 1.6;
                    margin: 20px;
                    color: #333;
                }}
                .title {{
                    font-size: 18px;
                    font-weight: bold;
                    text-align: center;
                    color: #1e3a8a;
                    margin-bottom: 30px;
                    border-bottom: 2px solid #1e3a8a;
                    padding-bottom: 10px;
                }}
                .section {{
                    margin-bottom: 20px;
                }}
                .section-title {{
                    font-size: 14px;
                    font-weight: bold;
                    color: #1e3a8a;
                    margin-bottom: 10px;
                    border-left: 4px solid #1e3a8a;
                    padding-left: 10px;
                }}
                .content {{
                    margin-bottom: 15px;
                    text-align: justify;
                }}
                .persona-analysis {{
                    margin-bottom: 25px;
                    padding: 15px;
                    border: 1px solid #e5e7eb;
                    border-radius: 5px;
                    background-color: #f9fafb;
                }}
                .persona-title {{
                    font-weight: bold;
                    color: #1e3a8a;
                    margin-bottom: 10px;
                }}
                .final-report {{
                    margin-top: 30px;
                    padding: 20px;
                    border: 2px solid #1e3a8a;
                    border-radius: 8px;
                    background-color: #f0f4ff;
                }}
                .timestamp {{
                    font-size: 10px;
                    color: #666;
                    text-align: center;
                    margin-top: 20px;
                }}
            </style>
        </head>
        <body>
            <div class="title">ğŸ” ë©€í‹°ì—ì´ì „íŠ¸ ì¬ë¬´ ë¶„ì„ ë³´ê³ ì„œ</div>
            
            <div class="section">
                <div class="section-title">ğŸ“‹ ë¶„ì„ ìš”ì²­</div>
                <div class="content">{user_query}</div>
            </div>
            
            <div class="section">
                <div class="section-title">ğŸ“… ë¶„ì„ ì¼ì‹œ</div>
                <div class="content">{datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M')}</div>
            </div>
        """
        
        # ë‚´ë¶€ ì¬ë¬´ ë°ì´í„° (ìˆëŠ” ê²½ìš°)
        if rag_context:
            html_content += f"""
            <div class="section">
                <div class="section-title">ğŸ“Š ë‚´ë¶€ ì¬ë¬´ ë°ì´í„°</div>
                <div class="content">ë¶„ì„ì— í™œìš©ëœ ë‚´ë¶€ ì¬ë¬´ ë°ì´í„°ê°€ í¬í•¨ë˜ì—ˆìŠµë‹ˆë‹¤.</div>
            </div>
            """
        
        # ì‹œì¥ ì¡°ì‚¬ ê²°ê³¼ (ìˆëŠ” ê²½ìš°)
        if market_research:
            html_content += f"""
            <div class="section">
                <div class="section-title">ğŸŒ ì‹œì¥ ì¡°ì‚¬ ê²°ê³¼</div>
                <div class="content">{market_research[:1000]}{'...' if len(market_research) > 1000 else ''}</div>
            </div>
            """
        
        # ì „ë¬¸ê°€ë³„ ë¶„ì„
        html_content += """
            <div class="section">
                <div class="section-title">ğŸ‘¥ ì „ë¬¸ê°€ë³„ ë¶„ì„</div>
        """
        
        for persona_key, analysis in persona_analyses.items():
            if analysis.get('success') and analysis.get('result'):
                persona_info = FINANCE_PERSONAS[persona_key]
                html_content += f"""
                <div class="persona-analysis">
                    <div class="persona-title">{persona_info['emoji']} {persona_info['name']}</div>
                    <div class="content">{analysis['result'].replace(chr(10), '<br>')}</div>
                </div>
                """
        
        # ìµœì¢… ì¢…í•© ë³´ê³ ì„œ
        if final_report:
            html_content += f"""
            <div class="final-report">
                <div class="section-title">ğŸ“‹ ìµœì¢… ì¢…í•© ë³´ê³ ì„œ</div>
                <div class="content">{final_report.replace(chr(10), '<br>')}</div>
            </div>
            """
        
        html_content += f"""
            <div class="timestamp">ìƒì„±ì¼ì‹œ: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S')}</div>
        </body>
        </html>
        """
        
        # HTMLì„ PDFë¡œ ë³€í™˜
        pdf_buffer = io.BytesIO()
        weasyprint.HTML(string=html_content).write_pdf(pdf_buffer)
        pdf_buffer.seek(0)
        
        return pdf_buffer
        
    except Exception as e:
        st.error(f"WeasyPrint PDF ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

def create_finance_analysis_pdf_reportlab(user_query, persona_analyses, final_report, rag_context="", market_research=""):
    """ReportLabì„ ì‚¬ìš©í•œ ì¬ë¬´ ë¶„ì„ PDF ìƒì„± (í•œê¸€ ì§€ì› ê°œì„ )"""
    try:
        from reportlab.pdfgen import canvas
        from reportlab.lib.pagesizes import A4
        from reportlab.lib.units import inch
        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
        from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak
        from reportlab.lib.enums import TA_LEFT, TA_CENTER, TA_JUSTIFY
        from reportlab.pdfbase import pdfmetrics
        from reportlab.pdfbase.ttfonts import TTFont
        from reportlab.pdfbase.cidfonts import UnicodeCIDFont
        from reportlab.lib.colors import black, blue, red, green, darkblue
        import io
        import os
        import platform
        
        # PDF ë²„í¼ ìƒì„±
        buffer = io.BytesIO()
        doc = SimpleDocTemplate(buffer, pagesize=A4, rightMargin=72, leftMargin=72, topMargin=72, bottomMargin=18)
        
        # í•œê¸€ í°íŠ¸ ì„¤ì • (Archives.py ë°©ì‹ ì°¸ê³ )
        font_name = 'Helvetica'  # ê¸°ë³¸ê°’
        
        try:
            # ë°©ë²• 1: UnicodeCIDFont ì‚¬ìš© (ê°€ì¥ ì•ˆì •ì )
            try:
                pdfmetrics.registerFont(UnicodeCIDFont('STSong-Light'))
                font_name = 'STSong-Light'
                st.info("âœ… UnicodeCIDFontë¥¼ ì‚¬ìš©í•˜ì—¬ í•œê¸€ì„ ì§€ì›í•©ë‹ˆë‹¤.")
            except Exception as e:
                st.warning(f"STSong-Light ë“±ë¡ ì‹¤íŒ¨: {e}")
                try:
                    # ë‹¤ë¥¸ UnicodeCIDFont ì‹œë„
                    pdfmetrics.registerFont(UnicodeCIDFont('HeiseiMin-W3'))
                    font_name = 'HeiseiMin-W3'
                    st.info("âœ… HeiseiMin-W3 UnicodeCIDFontë¥¼ ì‚¬ìš©í•˜ì—¬ í•œê¸€ì„ ì§€ì›í•©ë‹ˆë‹¤.")
                except Exception as e2:
                    st.warning(f"HeiseiMin-W3 ë“±ë¡ ì‹¤íŒ¨: {e2}")
                    try:
                        # ë˜ ë‹¤ë¥¸ UnicodeCIDFont ì‹œë„
                        pdfmetrics.registerFont(UnicodeCIDFont('HeiseiKakuGo-W5'))
                        font_name = 'HeiseiKakuGo-W5'
                        st.info("âœ… HeiseiKakuGo-W5 UnicodeCIDFontë¥¼ ì‚¬ìš©í•˜ì—¬ í•œê¸€ì„ ì§€ì›í•©ë‹ˆë‹¤.")
                    except Exception as e3:
                        st.warning(f"ëª¨ë“  UnicodeCIDFont ë“±ë¡ ì‹¤íŒ¨: {e3}")
                        
                        # ë°©ë²• 2: ì‹œìŠ¤í…œë³„ í•œê¸€ í°íŠ¸ ì‹œë„
                        system = platform.system()
                        font_paths = []
                        
                        if system == "Darwin":  # macOS
                            font_paths = [
                                '/System/Library/Fonts/AppleGothic.ttc',
                                '/System/Library/Fonts/PingFang.ttc',
                                '/System/Library/Fonts/STHeiti Light.ttc',
                                '/System/Library/Fonts/STHeiti Medium.ttc',
                                '/System/Library/Fonts/Supplemental/Arial Unicode MS.ttf',
                                '/Library/Fonts/Arial Unicode MS.ttf'
                            ]
                        elif system == "Windows":
                            font_paths = [
                                'C:/Windows/Fonts/malgun.ttf',  # ë§‘ì€ ê³ ë”•
                                'C:/Windows/Fonts/gulim.ttc',  # êµ´ë¦¼
                                'C:/Windows/Fonts/batang.ttc',  # ë°”íƒ•
                                'C:/Windows/Fonts/Arial.ttf'
                            ]
                        elif system == "Linux":
                            font_paths = [
                                '/usr/share/fonts/truetype/nanum/NanumGothic.ttf',
                                '/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf',
                                '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf'
                            ]
                        
                        # í°íŠ¸ ë“±ë¡ ì‹œë„
                        font_registered = False
                        for font_path in font_paths:
                            try:
                                if os.path.exists(font_path):
                                    pdfmetrics.registerFont(TTFont('KoreanFont', font_path))
                                    font_name = 'KoreanFont'
                                    font_registered = True
                                    st.success(f"âœ… í•œê¸€ í°íŠ¸ ë“±ë¡ ì„±ê³µ: {font_path}")
                                    break
                            except Exception as e:
                                st.warning(f"í°íŠ¸ ë“±ë¡ ì‹¤íŒ¨ ({font_path}): {e}")
                                continue
                        
                        # í°íŠ¸ ë“±ë¡ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©
                        if not font_registered:
                            font_name = 'Helvetica'
                            st.warning(f"âš ï¸ í•œê¸€ í°íŠ¸ ë“±ë¡ ì‹¤íŒ¨. ê¸°ë³¸ í°íŠ¸({font_name})ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                            
        except Exception as e:
            font_name = 'Helvetica'
            st.warning(f"í°íŠ¸ ì„¤ì • ì˜¤ë¥˜: {e}. ê¸°ë³¸ í°íŠ¸({font_name})ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        
        # ìŠ¤íƒ€ì¼ ì •ì˜
        styles = getSampleStyleSheet()
        title_style = ParagraphStyle(
            'CustomTitle',
            parent=styles['Heading1'],
            fontSize=16,
            spaceAfter=30,
            alignment=TA_CENTER,
            textColor=darkblue,
            fontName=font_name
        )
        heading_style = ParagraphStyle(
            'CustomHeading',
            parent=styles['Heading2'],
            fontSize=14,
            spaceAfter=12,
            spaceBefore=12,
            textColor=darkblue,
            fontName=font_name
        )
        normal_style = ParagraphStyle(
            'KoreanNormal',
            parent=styles['Normal'],
            fontName=font_name,
            fontSize=10,
            spaceAfter=6
        )
        small_style = ParagraphStyle(
            'KoreanSmall',
            parent=styles['Normal'],
            fontName=font_name,
            fontSize=8,
            spaceAfter=4
        )
        
        # ìŠ¤í† ë¦¬ êµ¬ì„±
        story = []
        
        # ì œëª©
        story.append(Paragraph("ğŸ” ë©€í‹°ì—ì´ì „íŠ¸ ì¬ë¬´ ë¶„ì„ ë³´ê³ ì„œ", title_style))
        story.append(Spacer(1, 12))
        
        # ë¶„ì„ ìš”ì²­
        story.append(Paragraph("ğŸ“‹ ë¶„ì„ ìš”ì²­", heading_style))
        story.append(Paragraph(user_query, normal_style))
        story.append(Spacer(1, 12))
        
        # ë¶„ì„ ì¼ì‹œ
        story.append(Paragraph(f"ğŸ“… ë¶„ì„ ì¼ì‹œ: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M')}", normal_style))
        story.append(Spacer(1, 20))
        
        # ë‚´ë¶€ ì¬ë¬´ ë°ì´í„° (ìˆëŠ” ê²½ìš°)
        if rag_context:
            story.append(Paragraph("ğŸ“Š ë‚´ë¶€ ì¬ë¬´ ë°ì´í„°", heading_style))
            story.append(Paragraph("ë¶„ì„ì— í™œìš©ëœ ë‚´ë¶€ ì¬ë¬´ ë°ì´í„°ê°€ í¬í•¨ë˜ì—ˆìŠµë‹ˆë‹¤.", normal_style))
            story.append(Spacer(1, 12))
        
        # ì‹œì¥ ì¡°ì‚¬ ê²°ê³¼ (ìˆëŠ” ê²½ìš°)
        if market_research:
            story.append(Paragraph("ğŸŒ ì‹œì¥ ì¡°ì‚¬ ê²°ê³¼", heading_style))
            # ì‹œì¥ ì¡°ì‚¬ ê²°ê³¼ë¥¼ ì—¬ëŸ¬ ë‹¨ë½ìœ¼ë¡œ ë¶„í• 
            market_paragraphs = market_research.split('\n\n')
            for para in market_paragraphs[:3]:  # ì²˜ìŒ 3ê°œ ë‹¨ë½ë§Œ í¬í•¨
                if para.strip():
                    story.append(Paragraph(para.strip(), normal_style))
                    story.append(Spacer(1, 6))
            story.append(Spacer(1, 12))
        
        # ì „ë¬¸ê°€ë³„ ë¶„ì„
        story.append(Paragraph("ğŸ‘¥ ì „ë¬¸ê°€ë³„ ë¶„ì„", heading_style))
        story.append(Spacer(1, 12))
        
        for persona_key, analysis in persona_analyses.items():
            if analysis.get('success') and analysis.get('result'):
                persona_info = FINANCE_PERSONAS[persona_key]
                story.append(Paragraph(f"{persona_info['emoji']} {persona_info['name']}", heading_style))
                
                # ë¶„ì„ ê²°ê³¼ë¥¼ ì—¬ëŸ¬ ë‹¨ë½ìœ¼ë¡œ ë¶„í• 
                result_paragraphs = analysis['result'].split('\n\n')
                for para in result_paragraphs:
                    if para.strip():
                        story.append(Paragraph(para.strip(), normal_style))
                        story.append(Spacer(1, 6))
                
                story.append(Spacer(1, 12))
        
        # ìµœì¢… ì¢…í•© ë³´ê³ ì„œ
        if final_report:
            story.append(Paragraph("ğŸ“‹ ìµœì¢… ì¢…í•© ë³´ê³ ì„œ", heading_style))
            story.append(Spacer(1, 12))
            
            # ìµœì¢… ë³´ê³ ì„œë¥¼ ì—¬ëŸ¬ ë‹¨ë½ìœ¼ë¡œ ë¶„í• 
            final_paragraphs = final_report.split('\n\n')
            for para in final_paragraphs:
                if para.strip():
                    story.append(Paragraph(para.strip(), normal_style))
                    story.append(Spacer(1, 6))
        
        # PDF ìƒì„±
        doc.build(story)
        buffer.seek(0)
        
        return buffer
        
    except Exception as e:
        st.error(f"PDF ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

def create_simple_analysis_pdf(user_query, response, relevant_docs=None):
    """ì¼ë°˜ ì±—ë´‡ ì‘ë‹µì„ PDFë¡œ ìƒì„±"""
    try:
        # ReportLabì„ ìš°ì„  ì‚¬ìš© (í•œê¸€ í°íŠ¸ ë¬¸ì œ í•´ê²°)
        return create_simple_analysis_pdf_reportlab(user_query, response, relevant_docs)
    except Exception as e:
        st.error(f"PDF ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

def create_simple_analysis_pdf_fpdf2(user_query, response, relevant_docs=None):
    """FPDF2ë¥¼ ì‚¬ìš©í•œ ì¼ë°˜ ì±—ë´‡ PDF ìƒì„±"""
    try:
        # PDF ë²„í¼ ìƒì„±
        pdf_buffer = io.BytesIO()
        
        # FPDF2 ê°ì²´ ìƒì„±
        pdf = FPDF()
        pdf.add_page()
        
        # í•œê¸€ í°íŠ¸ ì„¤ì •
        try:
            import platform
            system = platform.system()
            
            # ìš´ì˜ì²´ì œë³„ í•œê¸€ í°íŠ¸ ê²½ë¡œ
            font_paths = []
            if system == "Darwin":  # macOS
                font_paths = [
                    "/System/Library/Fonts/AppleGothic.ttf",
                    "/System/Library/Fonts/Supplemental/Arial Unicode MS.ttf",
                    "/Library/Fonts/AppleGothic.ttf"
                ]
            elif system == "Windows":
                font_paths = [
                    "C:/Windows/Fonts/malgun.ttf",
                    "C:/Windows/Fonts/NanumGothic.ttf",
                    "C:/Windows/Fonts/gulim.ttc"
                ]
            else:  # Linux
                font_paths = [
                    "/usr/share/fonts/truetype/nanum/NanumGothic.ttf",
                    "/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf"
                ]
            
            # í°íŠ¸ ë“±ë¡ ì‹œë„
            font_registered = False
            for font_path in font_paths:
                try:
                    if os.path.exists(font_path):
                        pdf.add_font('KoreanFont', '', font_path, uni=True)
                        font_name = 'KoreanFont'
                        font_registered = True
                        st.info(f"í•œê¸€ í°íŠ¸ ë“±ë¡ ì„±ê³µ: {font_path}")
                        break
                except Exception as e:
                    st.warning(f"í°íŠ¸ ë“±ë¡ ì‹¤íŒ¨ ({font_path}): {e}")
                    continue
            
            # í°íŠ¸ ë“±ë¡ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©
            if not font_registered:
                # FPDF2ì˜ ë‚´ì¥ ìœ ë‹ˆì½”ë“œ í°íŠ¸ ì‹œë„
                try:
                    pdf.add_font('DejaVu', '', uni=True)
                    font_name = 'DejaVu'
                    st.info("DejaVu ìœ ë‹ˆì½”ë“œ í°íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                except:
                    font_name = 'Arial'
                    st.warning("í•œê¸€ í°íŠ¸ ë“±ë¡ ì‹¤íŒ¨. ê¸°ë³¸ í°íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                
        except Exception as e:
            font_name = 'Arial'
            st.warning(f"í°íŠ¸ ì„¤ì • ì˜¤ë¥˜: {e}. ê¸°ë³¸ í°íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        
        # ì œëª©
        pdf.set_font(font_name, 'B', 16)
        pdf.set_text_color(30, 58, 138)  # darkblue
        pdf.cell(0, 10, 'Q-Li ì±—ë´‡ ë¶„ì„ ë³´ê³ ì„œ', ln=True, align='C')
        pdf.ln(10)
        
        # ë¶„ì„ ìš”ì²­
        pdf.set_font(font_name, 'B', 12)
        pdf.set_text_color(30, 58, 138)
        pdf.cell(0, 8, 'ë¶„ì„ ìš”ì²­', ln=True)
        pdf.set_font(font_name, '', 10)
        pdf.set_text_color(0, 0, 0)
        pdf.multi_cell(0, 6, user_query)
        pdf.ln(5)
        
        # ë¶„ì„ ì¼ì‹œ
        pdf.set_font(font_name, 'B', 12)
        pdf.set_text_color(30, 58, 138)
        pdf.cell(0, 8, 'ë¶„ì„ ì¼ì‹œ', ln=True)
        pdf.set_font(font_name, '', 10)
        pdf.set_text_color(0, 0, 0)
        pdf.cell(0, 6, datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M'), ln=True)
        pdf.ln(5)
        
        # ì±—ë´‡ ì‘ë‹µ
        pdf.set_font(font_name, 'B', 12)
        pdf.set_text_color(30, 58, 138)
        pdf.cell(0, 8, 'ì±—ë´‡ ì‘ë‹µ', ln=True)
        pdf.set_font(font_name, '', 10)
        pdf.set_text_color(0, 0, 0)
        pdf.multi_cell(0, 6, response)
        pdf.ln(5)
        
        # ì°¸ê³  ë¬¸ì„œ (ìˆëŠ” ê²½ìš°)
        if relevant_docs:
            pdf.set_font(font_name, 'B', 12)
            pdf.set_text_color(30, 58, 138)
            pdf.cell(0, 8, 'ì°¸ê³  ë¬¸ì„œ', ln=True)
            pdf.ln(5)
            
            for i, doc in enumerate(relevant_docs, 1):
                title = doc.metadata.get('source', f'ë¬¸ì„œ {i}')
                content = doc.page_content[:200] + "..." if len(doc.page_content) > 200 else doc.page_content
                
                pdf.set_font(font_name, 'B', 10)
                pdf.set_text_color(30, 58, 138)
                pdf.cell(0, 6, f"{i}. {title}", ln=True)
                pdf.set_font(font_name, '', 9)
                pdf.set_text_color(0, 0, 0)
                pdf.multi_cell(0, 5, content)
                pdf.ln(3)
        
        # PDF ì¶œë ¥
        pdf.output(pdf_buffer)
        pdf_buffer.seek(0)
        
        return pdf_buffer
        
    except Exception as e:
        st.error(f"FPDF2 PDF ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

def create_simple_analysis_pdf_weasyprint(user_query, response, relevant_docs=None):
    """WeasyPrintë¥¼ ì‚¬ìš©í•œ ì¼ë°˜ ì±—ë´‡ PDF ìƒì„±"""
    try:
        # HTML ì½˜í…ì¸  ìƒì„±
        html_content = f"""
        <!DOCTYPE html>
        <html lang="ko">
        <head>
            <meta charset="utf-8">
            <title>Q-Li ì±—ë´‡ ë¶„ì„ ë³´ê³ ì„œ</title>
            <style>
                body {{
                    font-family: 'Malgun Gothic', 'AppleGothic', 'NanumGothic', 'Arial Unicode MS', sans-serif;
                    font-size: 12px;
                    line-height: 1.6;
                    margin: 20px;
                    color: #333;
                }}
                .title {{
                    font-size: 18px;
                    font-weight: bold;
                    text-align: center;
                    color: #1e3a8a;
                    margin-bottom: 30px;
                    border-bottom: 2px solid #1e3a8a;
                    padding-bottom: 10px;
                }}
                .section {{
                    margin-bottom: 20px;
                }}
                .section-title {{
                    font-size: 14px;
                    font-weight: bold;
                    color: #1e3a8a;
                    margin-bottom: 10px;
                    border-left: 4px solid #1e3a8a;
                    padding-left: 10px;
                }}
                .content {{
                    margin-bottom: 15px;
                    text-align: justify;
                }}
                .chatbot-response {{
                    margin-bottom: 25px;
                    padding: 15px;
                    border: 1px solid #e5e7eb;
                    border-radius: 5px;
                    background-color: #f9fafb;
                }}
                .timestamp {{
                    font-size: 10px;
                    color: #666;
                    text-align: center;
                    margin-top: 20px;
                }}
            </style>
        </head>
        <body>
            <div class="title">ğŸ¤” Q-Li ì±—ë´‡ ë¶„ì„ ë³´ê³ ì„œ</div>
            
            <div class="section">
                <div class="section-title">ğŸ“‹ ë¶„ì„ ìš”ì²­</div>
                <div class="content">{user_query}</div>
            </div>
            
            <div class="section">
                <div class="section-title">ğŸ“… ë¶„ì„ ì¼ì‹œ</div>
                <div class="content">{datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M')}</div>
            </div>
            
            <div class="section">
                <div class="section-title">ğŸ¤– ì±—ë´‡ ì‘ë‹µ</div>
                <div class="chatbot-response">{response.replace(chr(10), '<br>')}</div>
            </div>
        """
        
        # ì°¸ê³  ë¬¸ì„œ (ìˆëŠ” ê²½ìš°)
        if relevant_docs:
            html_content += """
                <div class="section">
                    <div class="section-title">ğŸ“š ì°¸ê³  ë¬¸ì„œ</div>
            """
            for i, doc in enumerate(relevant_docs, 1):
                title = doc.metadata.get('source', f'ë¬¸ì„œ {i}')
                content = doc.page_content[:200] + "..." if len(doc.page_content) > 200 else doc.page_content
                html_content += f"""
                    <div class="content">
                        <strong>{title}</strong><br>
                        {content.replace(chr(10), '<br>')}
                    </div>
                """
            html_content += "</div>"
        
        html_content += f"""
            <div class="timestamp">ìƒì„±ì¼ì‹œ: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S')}</div>
        </body>
        </html>
        """
        
        # HTMLì„ PDFë¡œ ë³€í™˜
        pdf_buffer = io.BytesIO()
        weasyprint.HTML(string=html_content).write_pdf(pdf_buffer)
        pdf_buffer.seek(0)
        
        return pdf_buffer
        
    except Exception as e:
        st.error(f"WeasyPrint PDF ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

def create_simple_analysis_pdf_reportlab(user_query, response, relevant_docs=None):
    """ReportLabì„ ì‚¬ìš©í•œ ì¼ë°˜ ì±—ë´‡ PDF ìƒì„± (í•œê¸€ ì§€ì› ê°œì„ )"""
    try:
        from reportlab.pdfgen import canvas
        from reportlab.lib.pagesizes import A4
        from reportlab.lib.units import inch
        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
        from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak
        from reportlab.lib.enums import TA_LEFT, TA_CENTER, TA_JUSTIFY
        from reportlab.pdfbase import pdfmetrics
        from reportlab.pdfbase.ttfonts import TTFont
        from reportlab.pdfbase.cidfonts import UnicodeCIDFont
        from reportlab.lib.colors import black, blue, red, green, darkblue
        import io
        import os
        import platform
        
        # PDF ë²„í¼ ìƒì„±
        buffer = io.BytesIO()
        doc = SimpleDocTemplate(buffer, pagesize=A4, rightMargin=72, leftMargin=72, topMargin=72, bottomMargin=18)
        
        # í•œê¸€ í°íŠ¸ ì„¤ì • (Archives.py ë°©ì‹ ì°¸ê³ )
        font_name = 'Helvetica'  # ê¸°ë³¸ê°’
        
        try:
            # ë°©ë²• 1: UnicodeCIDFont ì‚¬ìš© (ê°€ì¥ ì•ˆì •ì )
            try:
                pdfmetrics.registerFont(UnicodeCIDFont('STSong-Light'))
                font_name = 'STSong-Light'
                st.info("âœ… UnicodeCIDFontë¥¼ ì‚¬ìš©í•˜ì—¬ í•œê¸€ì„ ì§€ì›í•©ë‹ˆë‹¤.")
            except Exception as e:
                st.warning(f"STSong-Light ë“±ë¡ ì‹¤íŒ¨: {e}")
                try:
                    # ë‹¤ë¥¸ UnicodeCIDFont ì‹œë„
                    pdfmetrics.registerFont(UnicodeCIDFont('HeiseiMin-W3'))
                    font_name = 'HeiseiMin-W3'
                    st.info("âœ… HeiseiMin-W3 UnicodeCIDFontë¥¼ ì‚¬ìš©í•˜ì—¬ í•œê¸€ì„ ì§€ì›í•©ë‹ˆë‹¤.")
                except Exception as e2:
                    st.warning(f"HeiseiMin-W3 ë“±ë¡ ì‹¤íŒ¨: {e2}")
                    try:
                        # ë˜ ë‹¤ë¥¸ UnicodeCIDFont ì‹œë„
                        pdfmetrics.registerFont(UnicodeCIDFont('HeiseiKakuGo-W5'))
                        font_name = 'HeiseiKakuGo-W5'
                        st.info("âœ… HeiseiKakuGo-W5 UnicodeCIDFontë¥¼ ì‚¬ìš©í•˜ì—¬ í•œê¸€ì„ ì§€ì›í•©ë‹ˆë‹¤.")
                    except Exception as e3:
                        st.warning(f"ëª¨ë“  UnicodeCIDFont ë“±ë¡ ì‹¤íŒ¨: {e3}")
                        
                        # ë°©ë²• 2: ì‹œìŠ¤í…œë³„ í•œê¸€ í°íŠ¸ ì‹œë„
                system = platform.system()
                font_paths = []
                
                if system == "Darwin":  # macOS
                    font_paths = [
                        '/System/Library/Fonts/AppleGothic.ttc',
                        '/System/Library/Fonts/PingFang.ttc',
                        '/System/Library/Fonts/STHeiti Light.ttc',
                        '/System/Library/Fonts/STHeiti Medium.ttc',
                        '/System/Library/Fonts/Supplemental/Arial Unicode MS.ttf',
                        '/Library/Fonts/Arial Unicode MS.ttf'
                    ]
                elif system == "Windows":
                    font_paths = [
                        'C:/Windows/Fonts/malgun.ttf',  # ë§‘ì€ ê³ ë”•
                        'C:/Windows/Fonts/gulim.ttc',  # êµ´ë¦¼
                        'C:/Windows/Fonts/batang.ttc',  # ë°”íƒ•
                        'C:/Windows/Fonts/Arial.ttf'
                    ]
                elif system == "Linux":
                    font_paths = [
                        '/usr/share/fonts/truetype/nanum/NanumGothic.ttf',
                        '/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf',
                        '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf'
                    ]
                
                # í°íŠ¸ ë“±ë¡ ì‹œë„
                font_registered = False
                for font_path in font_paths:
                    try:
                        if os.path.exists(font_path):
                            pdfmetrics.registerFont(TTFont('KoreanFont', font_path))
                            font_name = 'KoreanFont'
                            font_registered = True
                            st.success(f"âœ… í•œê¸€ í°íŠ¸ ë“±ë¡ ì„±ê³µ: {font_path}")
                            break
                    except Exception as e:
                        st.warning(f"í°íŠ¸ ë“±ë¡ ì‹¤íŒ¨ ({font_path}): {e}")
                        continue
                
                # í°íŠ¸ ë“±ë¡ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©
                if not font_registered:
                    font_name = 'Helvetica'
                    st.warning(f"âš ï¸ í•œê¸€ í°íŠ¸ ë“±ë¡ ì‹¤íŒ¨. ê¸°ë³¸ í°íŠ¸({font_name})ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                    
        except Exception as e:
            font_name = 'Helvetica'
            st.warning(f"í°íŠ¸ ì„¤ì • ì˜¤ë¥˜: {e}. ê¸°ë³¸ í°íŠ¸({font_name})ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        
        # ìŠ¤íƒ€ì¼ ì •ì˜
        styles = getSampleStyleSheet()
        title_style = ParagraphStyle(
            'CustomTitle',
            parent=styles['Heading1'],
            fontSize=16,
            spaceAfter=30,
            alignment=TA_CENTER,
            textColor=darkblue,
            fontName=font_name
        )
        heading_style = ParagraphStyle(
            'CustomHeading',
            parent=styles['Heading2'],
            fontSize=14,
            spaceAfter=12,
            spaceBefore=12,
            textColor=darkblue,
            fontName=font_name
        )
        normal_style = ParagraphStyle(
            'KoreanNormal',
            parent=styles['Normal'],
            fontName=font_name,
            fontSize=10,
            spaceAfter=6
        )
        small_style = ParagraphStyle(
            'KoreanSmall',
            parent=styles['Normal'],
            fontName=font_name,
            fontSize=8,
            spaceAfter=4
        )
        
        # ìŠ¤í† ë¦¬ êµ¬ì„±
        story = []
        
        # ì œëª©
        story.append(Paragraph("ğŸ¤” Q-Li ì±—ë´‡ ë¶„ì„ ë³´ê³ ì„œ", title_style))
        story.append(Spacer(1, 12))
        
        # ë¶„ì„ ìš”ì²­
        story.append(Paragraph("ğŸ“‹ ë¶„ì„ ìš”ì²­", heading_style))
        story.append(Paragraph(user_query, normal_style))
        story.append(Spacer(1, 12))
        
        # ë¶„ì„ ì¼ì‹œ
        story.append(Paragraph(f"ğŸ“… ë¶„ì„ ì¼ì‹œ: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M')}", normal_style))
        story.append(Spacer(1, 20))
        
        # ì±—ë´‡ ì‘ë‹µ
        story.append(Paragraph("ğŸ¤– ì±—ë´‡ ì‘ë‹µ", heading_style))
        
        # ì‘ë‹µì„ ì—¬ëŸ¬ ë‹¨ë½ìœ¼ë¡œ ë¶„í• 
        response_paragraphs = response.split('\n\n')
        for para in response_paragraphs:
            if para.strip():
                story.append(Paragraph(para.strip(), normal_style))
                story.append(Spacer(1, 6))
        
        # ì°¸ê³  ë¬¸ì„œ (ìˆëŠ” ê²½ìš°)
        if relevant_docs:
            story.append(Spacer(1, 12))
            story.append(Paragraph("ğŸ“š ì°¸ê³  ë¬¸ì„œ", heading_style))
            for i, doc in enumerate(relevant_docs, 1):
                title = doc.metadata.get('source', f'ë¬¸ì„œ {i}')
                content = doc.page_content[:200] + "..." if len(doc.page_content) > 200 else doc.page_content
                story.append(Paragraph(f"**{title}**", normal_style))
                story.append(Paragraph(content, small_style))
                story.append(Spacer(1, 6))
        
        # PDF ìƒì„±
        doc.build(story)
        buffer.seek(0)
        
        return buffer
        
    except Exception as e:
        st.error(f"PDF ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

# ===== DOCX ìƒì„± í•¨ìˆ˜ë“¤ =====

def create_finance_analysis_docx(user_query, persona_analyses, final_report, rag_context="", market_research=""):
    """ì¬ë¬´ ë¶„ì„ ê²°ê³¼ë¥¼ DOCXë¡œ ìƒì„±"""
    try:
        if DOCX_AVAILABLE:
            return create_finance_analysis_docx_python_docx(user_query, persona_analyses, final_report, rag_context, market_research)
        else:
            st.error("python-docx ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
    except Exception as e:
        st.error(f"DOCX ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

def create_finance_analysis_docx_python_docx(user_query, persona_analyses, final_report, rag_context="", market_research=""):
    """python-docxë¥¼ ì‚¬ìš©í•œ ì¬ë¬´ ë¶„ì„ DOCX ìƒì„±"""
    try:
        # DOCX ë¬¸ì„œ ìƒì„±
        doc = Document()
        
        # ì œëª© ì„¤ì •
        title = doc.add_heading('Q-Li ì¬ë¬´ ë¶„ì„ ë³´ê³ ì„œ', 0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER
        
        # ì‚¬ìš©ì ì§ˆë¬¸
        doc.add_heading('ì‚¬ìš©ì ì§ˆë¬¸', level=1)
        doc.add_paragraph(user_query)
        
        # ì‹œì¥ ì¡°ì‚¬ ê²°ê³¼ (ìˆëŠ” ê²½ìš°)
        if market_research and market_research.strip():
            doc.add_heading('ì‹œì¥ ì¡°ì‚¬ ê²°ê³¼', level=1)
            doc.add_paragraph(market_research)
        
        # RAG ì»¨í…ìŠ¤íŠ¸ (ìˆëŠ” ê²½ìš°)
        if rag_context and rag_context.strip():
            doc.add_heading('ì°¸ê³  ë¬¸ì„œ', level=1)
            doc.add_paragraph(rag_context)
        
        # ì „ë¬¸ê°€ë³„ ë¶„ì„
        doc.add_heading('ì „ë¬¸ê°€ë³„ ë¶„ì„', level=1)
        for persona_key, analysis in persona_analyses.items():
            if analysis and analysis.get('success') and analysis.get('result'):
                persona_name = persona_key.replace('_', ' ').title()
                doc.add_heading(f'{persona_name} ë¶„ì„', level=2)
                doc.add_paragraph(analysis['result'])
        
        # ìµœì¢… ì¢…í•© ë³´ê³ ì„œ
        if final_report and final_report.strip():
            doc.add_heading('ìµœì¢… ì¢…í•© ë³´ê³ ì„œ', level=1)
            doc.add_paragraph(final_report)
        
        # ìƒì„± ì‹œê°„
        doc.add_paragraph(f'ìƒì„± ì‹œê°„: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}')
        
        # DOCX ë²„í¼ì— ì €ì¥
        docx_buffer = io.BytesIO()
        doc.save(docx_buffer)
        docx_buffer.seek(0)
        
        return docx_buffer
        
    except Exception as e:
        st.error(f"DOCX ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

def create_simple_analysis_docx(user_query, response, relevant_docs=None):
    """ì¼ë°˜ ì±—ë´‡ ì‘ë‹µì„ DOCXë¡œ ìƒì„±"""
    try:
        if DOCX_AVAILABLE:
            return create_simple_analysis_docx_python_docx(user_query, response, relevant_docs)
        else:
            st.error("python-docx ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
    except Exception as e:
        st.error(f"DOCX ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

def create_simple_analysis_docx_python_docx(user_query, response, relevant_docs=None):
    """python-docxë¥¼ ì‚¬ìš©í•œ ì¼ë°˜ ì±—ë´‡ DOCX ìƒì„±"""
    try:
        # DOCX ë¬¸ì„œ ìƒì„±
        doc = Document()
        
        # ì œëª© ì„¤ì •
        title = doc.add_heading('Q-Li ì±—ë´‡ ë¶„ì„ ë³´ê³ ì„œ', 0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER
        
        # ì‚¬ìš©ì ì§ˆë¬¸
        doc.add_heading('ì‚¬ìš©ì ì§ˆë¬¸', level=1)
        doc.add_paragraph(user_query)
        
        # ì±—ë´‡ ì‘ë‹µ
        doc.add_heading('ì±—ë´‡ ì‘ë‹µ', level=1)
        doc.add_paragraph(response)
        
        # ì°¸ê³  ë¬¸ì„œ (ìˆëŠ” ê²½ìš°)
        if relevant_docs:
            doc.add_heading('ì°¸ê³  ë¬¸ì„œ', level=1)
            for i, doc_item in enumerate(relevant_docs, 1):
                doc.add_paragraph(f'{i}. {doc_item.page_content[:200]}...')
        
        # ìƒì„± ì‹œê°„
        doc.add_paragraph(f'ìƒì„± ì‹œê°„: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}')
        
        # DOCX ë²„í¼ì— ì €ì¥
        docx_buffer = io.BytesIO()
        doc.save(docx_buffer)
        docx_buffer.seek(0)
        
        return docx_buffer
        
    except Exception as e:
        st.error(f"DOCX ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

# ===== Streamlit UI =====
if 'chatbot' not in st.session_state:
    st.session_state.chatbot = FileRAGChatbot()
# ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” (í´ë”ë³„ë¡œ ë¶„ë¦¬)
if 'conversations' not in st.session_state:
    st.session_state.conversations = {}
    st.session_state.conversations['ì¼ë°˜'] = []
    st.session_state.conversations['ì¬ë¬´ ì •ë³´-ê³ ê¸‰'] = []

st.title("ğŸ¤” Q-Li (aQara-LIfe | íë¦¬)")
st.markdown("ë¨¼ì € ì‚¬ì´ë“œë°”ì˜ ë§¨ í•˜ë‹¨ ë©”ë‰´ì—ì„œ ì›í•˜ëŠ” LLMë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.")
st.markdown("LLMì—ì„œ ollamaëŠ” ë¡œì»¬ ì„œë²„ì—ì„œ ë™ì‘í•˜ëŠ” sLLMìœ¼ë¡œ ì„±ëŠ¥ì€ ì•„ì§ ë§ì´ ë–¨ì–´ì§‘ë‹ˆë‹¤. ë‹¤ë§Œ ë¡œì»¬ì—ì„œ ë™ì‘í•˜ë¯€ë¡œ ë¬´ë£Œì…ë‹ˆë‹¤.")

# í´ë” ì˜µì…˜ ì •ì˜
folder_options = {
    "ì „ì²´ ê²€ìƒ‰ (ì¬ë¬´ ì •ë³´ ì œì™¸)": "./pages/rag_files",
    "ì—…ë¬´ í”„ë¡œì„¸ìŠ¤": "./pages/rag_files/process",
    "ë™ë£Œ ì •ë³´": "./pages/rag_files/colleagues", 
    "ì¬ë¬´ ì •ë³´": "./pages/rag_files/finance",
    "ì¬ë¬´ ì •ë³´-ê³ ê¸‰": "./pages/rag_files/finance",
    "ì¼ë°˜ ì±„íŒ…": "./pages/rag_files/general"
}

# ì¬ë¬´ ì „ë¬¸ê°€ í˜ë¥´ì†Œë‚˜ ì •ì˜
FINANCE_PERSONAS = {
    "ì¬ë¬´ë¶„ì„ê°€": {
        "name": "ì¬ë¬´ ë¶„ì„ê°€",
        "emoji": "ğŸ“Š",
        "role": "ì¬ë¬´ ë°ì´í„° ë¶„ì„ ë° í•´ì„ ì „ë¬¸ê°€",
        "expertise": "ì¬ë¬´ì œí‘œ ë¶„ì„, ì¬ë¬´ ë¹„ìœ¨ ë¶„ì„, í˜„ê¸ˆíë¦„ ë¶„ì„, íˆ¬ì í‰ê°€",
        "perspective": "ì¬ë¬´ì  íƒ€ë‹¹ì„±, ìˆ˜ìµì„±, ì•ˆì •ì„±, ì„±ì¥ì„±ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë¶„ì„",
        "system_prompt": """ë‹¹ì‹ ì€ 15ë…„ ì´ìƒì˜ ê²½í—˜ì„ ê°€ì§„ ìµœê³  ìˆ˜ì¤€ì˜ ì¬ë¬´ ë¶„ì„ê°€ì…ë‹ˆë‹¤.

ã€ì „ë¬¸ ì˜ì—­ã€‘
- ì¬ë¬´ì œí‘œ ë¶„ì„ ë° ì¬ë¬´ ëª¨ë¸ë§
- ì¬ë¬´ ë¹„ìœ¨ ë¶„ì„ ë° ë²¤ì¹˜ë§ˆí‚¹
- í˜„ê¸ˆíë¦„ ë¶„ì„ ë° ìœ ë™ì„± ê´€ë¦¬
- íˆ¬ì í‰ê°€ ë° ìë³¸ ë°°ë¶„ ìµœì í™”
- ë¦¬ìŠ¤í¬ ê´€ë¦¬ ë° ë‚´ë¶€í†µì œ
- ì¬ë¬´ ì˜ˆì¸¡ ë° ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„

ã€ë¶„ì„ ìŠ¤íƒ€ì¼ã€‘
1. ì¬ë¬´ ì§€í‘œë¥¼ ë‹¤ê°ë„ë¡œ ë¶„ì„í•˜ì—¬ í˜„í™©ì„ ì •í™•íˆ ì§„ë‹¨
2. ìˆ˜ì¹˜ì  ê·¼ê±°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ê°ê´€ì  ë¶„ì„ ì œê³µ
3. ì—…ê³„ ë²¤ì¹˜ë§ˆí¬ì™€ì˜ ë¹„êµ ë¶„ì„ ìˆ˜í–‰
4. ì¬ë¬´ì  ë¦¬ìŠ¤í¬ì™€ ê¸°íšŒ ìš”ì¸ì„ ì •ëŸ‰í™”
5. êµ¬ì²´ì ì¸ ê°œì„  ë°©ì•ˆê³¼ ì‹¤í–‰ ê³„íš ì œì‹œ
6. ì¬ë¬´ì  ì„íŒ©íŠ¸ë¥¼ ëª…í™•íˆ ì •ëŸ‰í™”

ã€ë¦¬í¬íŠ¸ ìš”êµ¬ì‚¬í•­ã€‘
- ì£¼ìš” ì¬ë¬´ ë¹„ìœ¨ê³¼ ì—…ê³„ í‰ê·  ë¹„êµ ë¶„ì„
- ìˆ˜ìµì„±, ì•ˆì •ì„±, ì„±ì¥ì„± ê´€ì ì—ì„œ ì¢…í•© í‰ê°€
- í˜„ê¸ˆíë¦„ ì˜ˆì¸¡ê³¼ ìê¸ˆ ì¡°ë‹¬ ê³„íš ìˆ˜ë¦½
- ì¬ë¬´ì  ë¦¬ìŠ¤í¬ ìš”ì¸ê³¼ ì™„í™” ë°©ì•ˆ ì œì‹œ
- êµ¬ì²´ì ì¸ ê°œì„  ëª©í‘œì™€ ì‹¤í–‰ ë°©ì•ˆ ì œì‹œ
- ì¬ë¬´ì  ì„±ê³¼ ì¸¡ì • ì§€í‘œ(KPI) ì„¤ì •"""
    },
    "ì‹œì¥ë¶„ì„ê°€": {
        "name": "ì‹œì¥ ë¶„ì„ê°€",
        "emoji": "ğŸŒ",
        "role": "ì‹œì¥ ë™í–¥ ë° ê²½ìŸ í™˜ê²½ ë¶„ì„ ì „ë¬¸ê°€",
        "expertise": "ì‹œì¥ ë¶„ì„, ê²½ìŸì‚¬ ë¶„ì„, ì‚°ì—… íŠ¸ë Œë“œ, ì‹œì¥ ê¸°íšŒ ë¶„ì„",
        "perspective": "ì‹œì¥ ê¸°íšŒ, ê²½ìŸ í™˜ê²½, ì‚°ì—… íŠ¸ë Œë“œ, ì‹œì¥ ë¦¬ìŠ¤í¬ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë¶„ì„",
        "system_prompt": """ë‹¹ì‹ ì€ ê¸€ë¡œë²Œ ì‹œì¥ ë¶„ì„ ê²½í—˜ì„ ê°€ì§„ ìµœê³  ìˆ˜ì¤€ì˜ ì‹œì¥ ë¶„ì„ê°€ì…ë‹ˆë‹¤.

ã€ì „ë¬¸ ì˜ì—­ã€‘
- ì‹œì¥ ê·œëª¨ ë° ì„±ì¥ë¥  ë¶„ì„
- ê²½ìŸì‚¬ ë¶„ì„ ë° í¬ì§€ì…”ë‹ ì „ëµ
- ì‚°ì—… íŠ¸ë Œë“œ ë° ê¸°ìˆ  ë™í–¥ ë¶„ì„
- ì‹œì¥ ê¸°íšŒ ë° ìœ„í—˜ ìš”ì¸ í‰ê°€
- ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„
- ì‹œì¥ ì§„ì… ë° í™•ì¥ ì „ëµ

ã€ë¶„ì„ ìŠ¤íƒ€ì¼ã€‘
1. ì •ëŸ‰ì  ì‹œì¥ ë°ì´í„°ì™€ ì •ì„±ì  íŠ¸ë Œë“œ ë¶„ì„ì„ ì¢…í•©
2. ê²½ìŸ í™˜ê²½ê³¼ ì‹œì¥ í¬ì§€ì…”ë‹ì„ ê°ê´€ì ìœ¼ë¡œ í‰ê°€
3. ì‹œì¥ ê¸°íšŒì™€ ìœ„í—˜ ìš”ì¸ì„ ê· í˜• ìˆê²Œ ë¶„ì„
4. êµ¬ì²´ì ì¸ ì‹œì¥ ì§„ì… ë° í™•ì¥ ì „ëµ ì œì‹œ
5. ì‹œì¥ ë³€í™”ì— ëŒ€í•œ ëŒ€ì‘ ë°©ì•ˆ ìˆ˜ë¦½
6. ì‹œì¥ ê¸°ë°˜ì˜ ìˆ˜ìµì„± ë¶„ì„ ìˆ˜í–‰

ã€ë¦¬í¬íŠ¸ ìš”êµ¬ì‚¬í•­ã€‘
- ì‹œì¥ ê·œëª¨, ì„±ì¥ë¥ , ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì •ëŸ‰í™”
- ê²½ìŸì‚¬ ëŒ€ë¹„ ìš°ìœ„/ì—´ìœ„ ìš”ì†Œë¥¼ ë§¤íŠ¸ë¦­ìŠ¤ë¡œ ë¶„ì„
- ì‹œì¥ ê¸°íšŒì™€ ìœ„í—˜ ìš”ì¸ì„ ì •ëŸ‰ì ìœ¼ë¡œ í‰ê°€
- êµ¬ì²´ì ì¸ ì‹œì¥ ì§„ì… ë° í™•ì¥ ì „ëµ ì œì‹œ
- ì‹œì¥ ë³€í™”ì— ëŒ€í•œ ëŒ€ì‘ ë°©ì•ˆ ìˆ˜ë¦½
- ì‹œì¥ ê¸°ë°˜ì˜ ìˆ˜ìµì„± ê°œì„  ë°©ì•ˆ ë„ì¶œ"""
    },
    "ë§ˆì¼€íŒ…ì „ë¬´": {
        "name": "ë§ˆì¼€íŒ… ì „ë¬´",
        "emoji": "ğŸ“¢",
        "role": "ë§ˆì¼€íŒ… ì „ëµ ë° ë¸Œëœë“œ ê´€ë¦¬ ì „ë¬¸ê°€",
        "expertise": "ë¸Œëœë“œ ì „ëµ, ê³ ê° ê²½í—˜, ë§ˆì¼€íŒ… ì±„ë„, ìˆ˜ìµì„± ë¶„ì„",
        "perspective": "ê³ ê° ë‹ˆì¦ˆ, ë¸Œëœë“œ ê°€ì¹˜, ë§ˆì¼€íŒ… ROI, ê³ ê° ìƒì• ê°€ì¹˜ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë¶„ì„",
        "system_prompt": """ë‹¹ì‹ ì€ ë””ì§€í„¸ ë§ˆì¼€íŒ…ê³¼ ë¸Œëœë“œ ì „ëµ ë¶„ì•¼ì˜ ìµœê³  ì „ë¬¸ê°€ì¸ ë§ˆì¼€íŒ… ì „ë¬´ì…ë‹ˆë‹¤.

ã€ì „ë¬¸ ì˜ì—­ã€‘
- ë¸Œëœë“œ í¬ì§€ì…”ë‹ ë° ì•„ì´ë´í‹°í‹° êµ¬ì¶•
- ê³ ê° ì„¸ê·¸ë©˜í…Œì´ì…˜ ë° íƒ€ê²ŸíŒ… ì „ëµ
- ë§ˆì¼€íŒ… ì±„ë„ ìµœì í™” ë° ROI ë¶„ì„
- ê³ ê° ê²½í—˜ ì„¤ê³„ ë° ê°œì¸í™” ì „ëµ
- ë§ˆì¼€íŒ… ìë™í™” ë° ë°ì´í„° ë¶„ì„
- ë¸Œëœë“œ ê°€ì¹˜ ì¸¡ì • ë° ê´€ë¦¬

ã€ë¶„ì„ ìŠ¤íƒ€ì¼ã€‘
1. ê³ ê° ë°ì´í„° ê¸°ë°˜ì˜ ê°ê´€ì  ë¶„ì„ ìˆ˜í–‰
2. ë§ˆì¼€íŒ… ROIì™€ ìˆ˜ìµì„± ì¤‘ì‹¬ì˜ ì „ëµ ìˆ˜ë¦½
3. ë¸Œëœë“œ ê°€ì¹˜ì™€ ê³ ê° ìƒì• ê°€ì¹˜ ê·¹ëŒ€í™” ë°©ì•ˆ ì œì‹œ
4. ë§ˆì¼€íŒ… ì±„ë„ë³„ ì„±ê³¼ ë¶„ì„ ë° ìµœì í™”
5. ê²½ìŸì‚¬ ë§ˆì¼€íŒ… ì „ëµ ë²¤ì¹˜ë§ˆí‚¹
6. ì°½ì˜ì  ì•„ì´ë””ì–´ì™€ ë°ì´í„° ê¸°ë°˜ ì ‘ê·¼ë²•ì˜ ê· í˜•

ã€ë¦¬í¬íŠ¸ ìš”êµ¬ì‚¬í•­ã€‘
- íƒ€ê²Ÿ ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ë³„ í¬ê¸°ì™€ íŠ¹ì„±ì„ êµ¬ì²´ì ìœ¼ë¡œ ë¶„ì„
- ë§ˆì¼€íŒ… ì±„ë„ë³„ ROIì™€ ì˜ˆì‚° ë°°ë¶„ ìµœì í™” ë°©ì•ˆ ì œì‹œ
- ë¸Œëœë“œ ê°€ì¹˜ ì¦ëŒ€ë¥¼ ìœ„í•œ êµ¬ì²´ì  ì „ëµ ìˆ˜ë¦½
- ê³ ê° ìƒì• ê°€ì¹˜(CLV) í–¥ìƒ ë°©ì•ˆ ë„ì¶œ
- ë§ˆì¼€íŒ… ì„±ê³¼ ì¸¡ì • ì§€í‘œ(KPI) ì„¤ì •
- ê²½ìŸì‚¬ ëŒ€ë¹„ ì°¨ë³„í™” ì „ëµ ì œì‹œ"""
    },
    "ì‚¬ì—…ì „ëµê°€": {
        "name": "ì‚¬ì—… ì „ëµê°€",
        "emoji": "ğŸ¯",
        "role": "ì‚¬ì—… ëª¨ë¸ ë° ì „ëµ ìˆ˜ë¦½ ì „ë¬¸ê°€",
        "expertise": "ì‚¬ì—… ì „ëµ, ìˆ˜ìµ ëª¨ë¸, ì„±ì¥ ì „ëµ, ì „ëµì  íŒŒíŠ¸ë„ˆì‹­",
        "perspective": "ì‚¬ì—… ëª¨ë¸ í˜ì‹ , ìˆ˜ìµì„± ê°œì„ , ì„±ì¥ ê¸°íšŒ, ì „ëµì  ìš°ì„ ìˆœìœ„ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë¶„ì„",
        "system_prompt": """ë‹¹ì‹ ì€ ë‹¤ì–‘í•œ ì‚°ì—…ì˜ ì‚¬ì—… ì „ëµì„ ì´ëŒì–´ì˜¨ ìµœê³  ìˆ˜ì¤€ì˜ ì‚¬ì—… ì „ëµê°€ì…ë‹ˆë‹¤.

ã€ì „ë¬¸ ì˜ì—­ã€‘
- ì‚¬ì—… ëª¨ë¸ í˜ì‹  ë° ìˆ˜ìµ ë‹¤ê°í™”
- ì„±ì¥ ì „ëµ ìˆ˜ë¦½ ë° ì‹¤í–‰ ê³„íš
- ì „ëµì  íŒŒíŠ¸ë„ˆì‹­ ë° M&A ê¸°íš
- ì‹œì¥ ì§„ì… ë° í™•ì¥ ì „ëµ
- ìˆ˜ìµì„± ê°œì„  ë° ë¹„ìš© ìµœì í™”
- ì „ëµì  ìš°ì„ ìˆœìœ„ ì„¤ì • ë° ìì› ë°°ë¶„

ã€ë¶„ì„ ìŠ¤íƒ€ì¼ã€‘
1. ì‚¬ì—… ëª¨ë¸ì˜ ìˆ˜ìµì„±ê³¼ ì§€ì†ê°€ëŠ¥ì„±ì„ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€
2. ì„±ì¥ ê¸°íšŒì™€ ìœ„í—˜ ìš”ì¸ì„ ê· í˜• ìˆê²Œ ë¶„ì„
3. êµ¬ì²´ì ì¸ ì‹¤í–‰ ê³„íšê³¼ ì„±ê³¼ ì¸¡ì • ë°©ì•ˆ ì œì‹œ
4. ì „ëµì  íŒŒíŠ¸ë„ˆì‹­ê³¼ í˜‘ë ¥ ê¸°íšŒ ë°œêµ´
5. ìˆ˜ìµì„± ê°œì„ ì„ ìœ„í•œ êµ¬ì²´ì  ì•¡ì…˜ í”Œëœ ìˆ˜ë¦½
6. ì¥ê¸°ì  ê´€ì ì—ì„œì˜ ì „ëµì  ë°©í–¥ì„± ì œì‹œ

ã€ë¦¬í¬íŠ¸ ìš”êµ¬ì‚¬í•­ã€‘
- ì‚¬ì—… ëª¨ë¸ì˜ ìˆ˜ìµì„±ê³¼ ì§€ì†ê°€ëŠ¥ì„± ë¶„ì„
- ì„±ì¥ ê¸°íšŒì™€ ìœ„í—˜ ìš”ì¸ì„ ì •ëŸ‰ì ìœ¼ë¡œ í‰ê°€
- êµ¬ì²´ì ì¸ ì‹¤í–‰ ê³„íšê³¼ ì„±ê³¼ ì¸¡ì • ì§€í‘œ ì„¤ì •
- ì „ëµì  íŒŒíŠ¸ë„ˆì‹­ ê¸°íšŒ ë°œêµ´ ë° í‰ê°€
- ìˆ˜ìµì„± ê°œì„ ì„ ìœ„í•œ êµ¬ì²´ì  ë°©ì•ˆ ì œì‹œ
- ì¥ê¸°ì  ì „ëµì  ë°©í–¥ì„±ê³¼ ë¡œë“œë§µ ìˆ˜ë¦½"""
    },
    "ì˜ì—…ë¶„ì„ê°€": {
        "name": "ì˜ì—… ë¶„ì„ê°€",
        "emoji": "ğŸ¤",
        "role": "ì˜ì—… ì„±ê³¼ ë° ê³ ê° ê´€ê³„ ë¶„ì„ ì „ë¬¸ê°€",
        "expertise": "ì˜ì—… ì „ëµ, ê³ ê° ê´€ê³„ ê´€ë¦¬, ìˆ˜ìµì„± ë¶„ì„, ì˜ì—… í”„ë¡œì„¸ìŠ¤ ìµœì í™”",
        "perspective": "ì˜ì—… íš¨ìœ¨ì„±, ê³ ê° ë§Œì¡±ë„, ìˆ˜ìµ ì°½ì¶œ, ì˜ì—… ìƒì‚°ì„±ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë¶„ì„",
        "system_prompt": """ë‹¹ì‹ ì€ B2B/B2C ì˜ì—… ì „ëµê³¼ ê³ ê° ê´€ê³„ ê´€ë¦¬ ë¶„ì•¼ì˜ ìµœê³  ì „ë¬¸ê°€ì¸ ì˜ì—… ë¶„ì„ê°€ì…ë‹ˆë‹¤.

ã€ì „ë¬¸ ì˜ì—­ã€‘
- ì˜ì—… í”„ë¡œì„¸ìŠ¤ ìµœì í™” ë° ìƒì‚°ì„± í–¥ìƒ
- ê³ ê° ì„¸ê·¸ë©˜í…Œì´ì…˜ ë° ê´€ê³„ ê´€ë¦¬
- ì˜ì—… ì„±ê³¼ ë¶„ì„ ë° ì˜ˆì¸¡
- ìˆ˜ìµì„± ë¶„ì„ ë° ê³ ê° ìƒì• ê°€ì¹˜ ì¸¡ì •
- ì˜ì—… ì±„ë„ ìµœì í™” ë° íŒŒíŠ¸ë„ˆì‹­ ê´€ë¦¬
- ê³ ê° ë§Œì¡±ë„ ë° ì¶©ì„±ë„ ë¶„ì„

ã€ë¶„ì„ ìŠ¤íƒ€ì¼ã€‘
1. ì˜ì—… ë°ì´í„° ê¸°ë°˜ì˜ ê°ê´€ì  ì„±ê³¼ ë¶„ì„
2. ê³ ê°ë³„ ìˆ˜ìµì„±ê³¼ ì„±ì¥ ì ì¬ë ¥ì„ ì •ëŸ‰ í‰ê°€
3. ì˜ì—… í”„ë¡œì„¸ìŠ¤ ê°œì„ ì„ í†µí•œ íš¨ìœ¨ì„± í–¥ìƒ ë°©ì•ˆ ì œì‹œ
4. ê³ ê° ë§Œì¡±ë„ì™€ ì¶©ì„±ë„ í–¥ìƒ ì „ëµ ìˆ˜ë¦½
5. ì˜ì—… ì±„ë„ë³„ ì„±ê³¼ ë¶„ì„ ë° ìµœì í™”
6. ìˆ˜ìµì„± ê°œì„ ì„ ìœ„í•œ êµ¬ì²´ì  ì•¡ì…˜ í”Œëœ ë„ì¶œ

ã€ë¦¬í¬íŠ¸ ìš”êµ¬ì‚¬í•­ã€‘
- ì˜ì—… ì„±ê³¼ ì§€í‘œ(KPI)ì™€ ê°œì„  ëª©í‘œì¹˜ ì„¤ì •
- ê³ ê°ë³„ ìˆ˜ìµì„±ê³¼ ì„±ì¥ ì ì¬ë ¥ ë¶„ì„
- ì˜ì—… í”„ë¡œì„¸ìŠ¤ ê°œì„ ì•ˆê³¼ ê¸°ëŒ€ íš¨ê³¼ ì œì‹œ
- ê³ ê° ë§Œì¡±ë„ í–¥ìƒê³¼ ì¶©ì„±ë„ ì œê³  ë°©ì•ˆ
- ì˜ì—… ì±„ë„ ìµœì í™” ë° íŒŒíŠ¸ë„ˆì‹­ ì „ëµ
- ìˆ˜ìµì„± ê°œì„ ì„ ìœ„í•œ êµ¬ì²´ì  ì‹¤í–‰ ê³„íš"""
    }
}

# ìµœì¢… ë³´ê³ ì„œ ì‘ì„±ì í˜ë¥´ì†Œë‚˜
REPORT_SYNTHESIZER = {
    "name": "ìµœì¢… ë³´ê³ ì„œ ì‘ì„±ì",
    "emoji": "ğŸ“‹",
    "role": "ì „ë¬¸ê°€ ë¶„ì„ ê²°ê³¼ ì¢…í•© ë° ìµœì¢… ë³´ê³ ì„œ ì‘ì„±",
    "expertise": "ë¶„ì„ ê²°ê³¼ ì¢…í•©, ì „ëµì  ì œì•ˆ, ì‹¤í–‰ ê³„íš ìˆ˜ë¦½",
    "perspective": "ì „ë¬¸ê°€ë“¤ì˜ ë¶„ì„ì„ ì¢…í•©í•˜ì—¬ ì‹¤í˜„ ê°€ëŠ¥í•œ ì „ëµê³¼ ì‹¤í–‰ ê³„íšì„ ì œì‹œ",
    "system_prompt": """ë‹¹ì‹ ì€ ë‹¤ì–‘í•œ ì „ë¬¸ê°€ë“¤ì˜ ë¶„ì„ì„ ì¢…í•©í•˜ì—¬ ìµœì¢… ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ã€ì „ë¬¸ ì˜ì—­ã€‘
- ë‹¤ê°ë„ ë¶„ì„ ê²°ê³¼ ì¢…í•© ë° í•´ì„
- ì „ëµì  ìš°ì„ ìˆœìœ„ ì„¤ì • ë° ì‹¤í–‰ ê³„íš ìˆ˜ë¦½
- ë¦¬ìŠ¤í¬ì™€ ê¸°íšŒ ìš”ì¸ì˜ ê· í˜•ì  í‰ê°€
- êµ¬ì²´ì ì´ê³  ì‹¤í˜„ ê°€ëŠ¥í•œ ì œì•ˆ ë„ì¶œ
- ì„±ê³¼ ì¸¡ì • ì§€í‘œ ë° ëª¨ë‹ˆí„°ë§ ë°©ì•ˆ ìˆ˜ë¦½

ã€ë¶„ì„ ìŠ¤íƒ€ì¼ã€‘
1. ê° ì „ë¬¸ê°€ì˜ ê´€ì ì„ ê· í˜• ìˆê²Œ ê³ ë ¤í•˜ì—¬ ì¢…í•©ì  ë¶„ì„ ìˆ˜í–‰
2. ì‹¤í˜„ ê°€ëŠ¥ì„±ê³¼ ì„íŒ©íŠ¸ë¥¼ ê³ ë ¤í•œ ìš°ì„ ìˆœìœ„ ì„¤ì •
3. êµ¬ì²´ì ì¸ ì‹¤í–‰ ê³„íšê³¼ ì„±ê³¼ ì¸¡ì • ë°©ì•ˆ ì œì‹œ
4. ë¦¬ìŠ¤í¬ ê´€ë¦¬ì™€ ê¸°íšŒ í™œìš© ë°©ì•ˆì„ ê· í˜• ìˆê²Œ ì œì‹œ
5. ì´í•´ê´€ê³„ìë³„ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì „ëµ í¬í•¨
6. ì¥ê¸°ì  ê´€ì ì—ì„œì˜ ì§€ì†ê°€ëŠ¥í•œ ì „ëµ ìˆ˜ë¦½

ã€ë¦¬í¬íŠ¸ ìš”êµ¬ì‚¬í•­ã€‘
- ê° ì „ë¬¸ê°€ ë¶„ì„ì˜ í•µì‹¬ í¬ì¸íŠ¸ë¥¼ ëª…í™•íˆ ìš”ì•½
- ì „ëµì  ìš°ì„ ìˆœìœ„ì™€ ì‹¤í–‰ ìˆœì„œë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œ
- ì˜ˆìƒ ì„±ê³¼ì™€ ë¦¬ìŠ¤í¬ë¥¼ ì •ëŸ‰ì ìœ¼ë¡œ í‰ê°€
- êµ¬ì²´ì ì¸ ì‹¤í–‰ ê³„íšê³¼ íƒ€ì„ë¼ì¸ ìˆ˜ë¦½
- ì„±ê³¼ ì¸¡ì • ì§€í‘œì™€ ëª¨ë‹ˆí„°ë§ ë°©ì•ˆ ì„¤ì •
- ì´í•´ê´€ê³„ìë³„ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì „ëµ í¬í•¨"""
}

# í´ë” ì„ íƒ ë¼ë””ì˜¤ ë²„íŠ¼
st.markdown("### ğŸ“ ê²€ìƒ‰ í´ë” ì„ íƒ")

# ë¼ë””ì˜¤ ë²„íŠ¼ì—ì„œ ì„ íƒëœ í´ë”ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
selected_folder = st.radio(
    "ê²€ìƒ‰í•  í´ë”ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
    options=list(folder_options.keys()),
    index=0,
    key="selected_folder_radio",
    help="ì„ íƒí•œ í´ë”ì˜ ë¬¸ì„œë§Œ ê²€ìƒ‰í•©ë‹ˆë‹¤. ì „ì²´ ê²€ìƒ‰ì€ finance í´ë”ë¥¼ ì œì™¸í•©ë‹ˆë‹¤. ì¬ë¬´ ì •ë³´-ê³ ê¸‰ì€ 5ëª…ì˜ ì „ë¬¸ê°€ê°€ ë™ì‹œì— ë¶„ì„í•©ë‹ˆë‹¤."
)

# ì¼ë°˜ ì±„íŒ… ëª¨ë“œì— ëŒ€í•œ ì¶”ê°€ ì„¤ëª…
if selected_folder == "ì¼ë°˜ ì±„íŒ…":
    st.info("""
    ğŸ’¬ **ì¼ë°˜ ì±„íŒ… ëª¨ë“œ**
    
    ì´ ëª¨ë“œì—ì„œëŠ” RAG ê¸°ëŠ¥ ì—†ì´ ìˆœìˆ˜í•œ LLM ì±„íŒ…ì„ ì œê³µí•©ë‹ˆë‹¤:
    
    âœ… **ChatGPTì™€ ë™ì¼í•œ ê²½í—˜**: ë¬¸ì„œ ê²€ìƒ‰ ì—†ì´ ì§ì ‘ì ì¸ ëŒ€í™”
    âœ… **ë¹ ë¥¸ ì‘ë‹µ**: RAG ê²€ìƒ‰ ê³¼ì • ì—†ì´ ì¦‰ì‹œ ë‹µë³€
    âœ… **ììœ ë¡œìš´ ëŒ€í™”**: ì–´ë–¤ ì£¼ì œë“  ììœ ë¡­ê²Œ ì§ˆë¬¸ ê°€ëŠ¥
    âœ… **ì¼ë°˜ì ì¸ AI ì±„íŒ…**: ì¼ë°˜ì ì¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì²˜ëŸ¼ ì‚¬ìš©
    
    ë¬¸ì„œ ê¸°ë°˜ ê²€ìƒ‰ì´ í•„ìš”í•˜ì§€ ì•Šì€ ì¼ë°˜ì ì¸ ëŒ€í™”ì— ì í•©í•©ë‹ˆë‹¤.
    """)

# ì¬ë¬´ ì •ë³´-ê³ ê¸‰ ì˜µì…˜ì— ëŒ€í•œ ì¶”ê°€ ì„¤ëª…
elif selected_folder == "ì¬ë¬´ ì •ë³´-ê³ ê¸‰":
    st.info("""
    ğŸ” **ì¬ë¬´ ì •ë³´-ê³ ê¸‰ ë¶„ì„ ëª¨ë“œ**
    
    ì´ ëª¨ë“œì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì „ë¬¸ê°€ë“¤ì´ ë™ì‹œì— ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
    
    ğŸ“Š **ì¬ë¬´ ë¶„ì„ê°€**: ì¬ë¬´ì œí‘œ ë¶„ì„, ì¬ë¬´ ë¹„ìœ¨ ë¶„ì„, í˜„ê¸ˆíë¦„ ë¶„ì„
    ğŸŒ **ì‹œì¥ ë¶„ì„ê°€**: ì‹œì¥ ë™í–¥, ê²½ìŸì‚¬ ë¶„ì„, ì‚°ì—… íŠ¸ë Œë“œ ë¶„ì„  
    ğŸ“¢ **ë§ˆì¼€íŒ… ì „ë¬´**: ë¸Œëœë“œ ì „ëµ, ê³ ê° ê²½í—˜, ë§ˆì¼€íŒ… ROI ë¶„ì„
    ğŸ¯ **ì‚¬ì—… ì „ëµê°€**: ì‚¬ì—… ëª¨ë¸ í˜ì‹ , ìˆ˜ìµì„± ê°œì„ , ì„±ì¥ ì „ëµ
    ğŸ¤ **ì˜ì—… ë¶„ì„ê°€**: ì˜ì—… ì„±ê³¼, ê³ ê° ê´€ê³„, ìˆ˜ìµì„± ë¶„ì„
    
    ê° ì „ë¬¸ê°€ëŠ” ë‚´ë¶€ ì¬ë¬´ ë°ì´í„°ì™€ ì‹¤ì‹œê°„ ì‹œì¥ ì¡°ì‚¬ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¶„ì„í•˜ë©°, 
    ìµœì¢… ë³´ê³ ì„œ ì‘ì„±ìê°€ ëª¨ë“  ë¶„ì„ì„ ì¢…í•©í•˜ì—¬ ì‹¤í˜„ ê°€ëŠ¥í•œ ì „ëµì„ ì œì‹œí•©ë‹ˆë‹¤.
    """)

# í´ë” ë³€ê²½ ì‹œ RAG ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸
if 'selected_folder' not in st.session_state:
    st.session_state.selected_folder = selected_folder

if selected_folder != st.session_state.selected_folder:
    st.session_state.selected_folder = selected_folder
    folder_path = folder_options[selected_folder]
    
    # ì „ì²´ ê²€ìƒ‰ì¸ ê²½ìš° finance í´ë” ì œì™¸
    if selected_folder == "ì „ì²´ ê²€ìƒ‰ (ì¬ë¬´ ì •ë³´ ì œì™¸)":
        st.session_state.chatbot.rag_system.set_search_folder(folder_path)
        st.info(f"ğŸ“ ì„ íƒëœ í´ë”: {selected_folder} (finance í´ë” ì œì™¸)")
    else:
        st.session_state.chatbot.rag_system.set_search_folder(folder_path)
        st.info(f"ğŸ“ ì„ íƒëœ í´ë”: {selected_folder}")

st.markdown("---")

# LLM ì œê³µì/ëª¨ë¸ ì„ íƒ
with st.sidebar:
    st.markdown("## âš™ï¸ ì„¤ì •")
    providers = st.session_state.chatbot.llm_client.get_available_providers()
    if providers:
        # OpenAIë¥¼ ê¸°ë³¸ ì œê³µìë¡œ ì„¤ì •
        default_provider = 'openai' if 'openai' in providers else providers[0]
        provider_index = providers.index(default_provider) if default_provider in providers else 0
        
        selected_provider = st.selectbox(
            "LLM ì œê³µì ì„ íƒ",
            providers,
            index=provider_index
        )
        models = st.session_state.chatbot.llm_client.get_models_for_provider(selected_provider)
        if models:
            # ê¸°ë³¸ ëª¨ë¸ ì„¤ì •
            if selected_provider == 'openai' and 'gpt-4o-mini' in models:
                model_index = models.index('gpt-4o-mini')
            elif selected_provider == 'anthropic' and 'claude-3-7-sonnet-latest' in models:
                model_index = models.index('claude-3-7-sonnet-latest')
            elif selected_provider == 'ollama' and 'mistral:latest' in models:
                model_index = models.index('mistral:latest')
            else:
                model_index = 0
            
            selected_model = st.selectbox(
                "ëª¨ë¸ ì„ íƒ",
                models,
                index=model_index
            )
        else:
            selected_model = None
    else:
        st.error("ì‚¬ìš© ê°€ëŠ¥í•œ LLM ì œê³µìê°€ ì—†ìŠµë‹ˆë‹¤.")
        selected_provider = None
        selected_model = None
    temperature = st.slider("ì°½ì˜ì„± (Temperature)", 0.0, 1.0, 0.7, 0.1)
    
    # ì„ë² ë”© ëª¨ë¸ ì •ë³´
    if st.session_state.get('chatbot') and hasattr(st.session_state.chatbot.rag_system, 'embeddings'):
        embedding_model = st.session_state.chatbot.rag_system.embeddings
        if hasattr(embedding_model, 'model'):
            st.info(f"ğŸ”¤ ì„ë² ë”© ëª¨ë¸: {embedding_model.model}")
        else:
            st.info("ğŸ”¤ ì„ë² ë”© ëª¨ë¸: OpenAI (ê¸°ë³¸)")
    
    # ë””ë²„ê·¸ ëª¨ë“œ í† ê¸€ (ê°œë°œìš©)
    debug_mode = st.checkbox("ğŸ”§ ë””ë²„ê·¸ ëª¨ë“œ", value=False, help="ê²€ìƒ‰ ê³¼ì •ì„ ìì„¸íˆ ë³´ì—¬ì¤ë‹ˆë‹¤")
    if debug_mode:
        st.session_state.debug_mode = True
    else:
        st.session_state.debug_mode = False
    
    st.markdown("---")
    
    # íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜
    st.markdown("### ğŸ“ íŒŒì¼ ì—…ë¡œë“œ")
    
    # ì—…ë¡œë“œ í´ë” ì„ íƒ
    upload_folder_options = {
        "ì „ì²´ ê²€ìƒ‰ (ì¬ë¬´ ì •ë³´ ì œì™¸)": "./pages/rag_files",
        "ì—…ë¬´ í”„ë¡œì„¸ìŠ¤": "./pages/rag_files/process",
        "ë™ë£Œ ì •ë³´": "./pages/rag_files/colleagues", 
        "ì¬ë¬´ ì •ë³´": "./pages/rag_files/finance",
        "ì¬ë¬´ ì •ë³´-ê³ ê¸‰": "./pages/rag_files/finance",
        "ì¼ë°˜ ì±„íŒ…": "./pages/rag_files/general"
    }
    
    # ê¸°ë³¸ê°’ìœ¼ë¡œ í˜„ì¬ ì„ íƒëœ í´ë” ì‚¬ìš©
    default_upload_folder = selected_folder if selected_folder in upload_folder_options else "ì „ì²´ ê²€ìƒ‰ (ì¬ë¬´ ì •ë³´ ì œì™¸)"
    
    upload_folder = st.selectbox(
        "ğŸ“‚ ì—…ë¡œë“œí•  í´ë”ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
        options=list(upload_folder_options.keys()),
        index=list(upload_folder_options.keys()).index(default_upload_folder),
        help="íŒŒì¼ì„ ì €ì¥í•  í´ë”ë¥¼ ì„ íƒí•©ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ í˜„ì¬ ì„ íƒëœ ê²€ìƒ‰ í´ë”ì…ë‹ˆë‹¤."
    )
    
    # ì„ íƒëœ ì—…ë¡œë“œ í´ë” ì •ë³´ í‘œì‹œ
    upload_folder_path = upload_folder_options[upload_folder]
    st.info(f"ğŸ“‚ **ì—…ë¡œë“œ ëŒ€ìƒ í´ë”:** {upload_folder}\nğŸ“ **ê²½ë¡œ:** {upload_folder_path}")
    
    # ì§€ì›í•˜ëŠ” íŒŒì¼ í˜•ì‹
    supported_types = ['pdf', 'docx', 'pptx', 'xlsx', 'txt', 'md', 'gdoc', 'gsheet', 'gslides']
    
    # íŒŒì¼ í˜•ì‹ ì„¤ëª…
    st.info("""
    ğŸ“„ **ì§€ì› íŒŒì¼ í˜•ì‹:**
    - **PDF**: PDF ë¬¸ì„œ
    - **DOCX**: Word ë¬¸ì„œ
    - **PPTX**: PowerPoint í”„ë ˆì  í…Œì´ì…˜
    - **XLSX**: Excel ìŠ¤í”„ë ˆë“œì‹œíŠ¸
    - **TXT**: í…ìŠ¤íŠ¸ íŒŒì¼
    - **MD**: Markdown íŒŒì¼
    - **GDOC**: êµ¬ê¸€ ë¬¸ì„œ (HTML í˜•ì‹)
    - **GSHEET**: êµ¬ê¸€ ì‹œíŠ¸ (HTML í˜•ì‹)
    - **GSLIDES**: êµ¬ê¸€ ìŠ¬ë¼ì´ë“œ (HTML í˜•ì‹)
    """)
    
    uploaded_files = st.file_uploader(
        "RAGì— ì‚¬ìš©í•  íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”:",
        type=supported_types,
        accept_multiple_files=True,
        help="PDF, DOCX, PPTX, XLSX, TXT, MD, GDOC(êµ¬ê¸€ë¬¸ì„œ), GSHEET(êµ¬ê¸€ì‹œíŠ¸), GSLIDES(êµ¬ê¸€ìŠ¬ë¼ì´ë“œ) íŒŒì¼ì„ ì§€ì›í•©ë‹ˆë‹¤."
    )
    
    if uploaded_files:
        # ì„ íƒëœ ì—…ë¡œë“œ í´ë” ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
        target_folder = upload_folder_options[upload_folder]
        
        # í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±
        if not os.path.exists(target_folder):
            os.makedirs(target_folder)
        
        uploaded_count = 0
        for uploaded_file in uploaded_files:
            try:
                # íŒŒì¼ëª…ì—ì„œ íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ì•ˆì „í•œ íŒŒì¼ëª… ìƒì„±
                safe_filename = "".join(c for c in uploaded_file.name if c.isalnum() or c in (' ', '-', '_', '.')).rstrip()
                safe_filename = safe_filename.replace(' ', '_')
                
                # íŒŒì¼ ê²½ë¡œ
                file_path = os.path.join(target_folder, safe_filename)
                
                # íŒŒì¼ ì €ì¥
                with open(file_path, "wb") as f:
                    f.write(uploaded_file.getbuffer())
                
                uploaded_count += 1
                st.success(f"âœ… {safe_filename} ì—…ë¡œë“œ ì™„ë£Œ")
                
            except Exception as e:
                st.error(f"âŒ {uploaded_file.name} ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        
        if uploaded_count > 0:
            st.info(f"ğŸ“ {uploaded_count}ê°œ íŒŒì¼ì´ '{upload_folder}' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # ìë™ ì¸ë±ìŠ¤ ì¬êµ¬ì¶• ì˜µì…˜
            if st.button("ğŸ”„ ìë™ìœ¼ë¡œ íŒŒì¼ ì¸ë±ìŠ¤ ì¬êµ¬ì¶•", type="primary"):
                with st.spinner("íŒŒì¼ ì¸ë±ìŠ¤ë¥¼ ì¬êµ¬ì¶• ì¤‘ì…ë‹ˆë‹¤..."):
                    try:
                        # ì—…ë¡œë“œëœ í´ë”ë¡œ ì¸ë±ìŠ¤ ì¬êµ¬ì¶•
                        folder_path = upload_folder_options[upload_folder]
                        st.session_state.chatbot.rag_system.set_search_folder(folder_path)
                        st.success(f"âœ… íŒŒì¼ ì¸ë±ìŠ¤ê°€ ì¬êµ¬ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤! (í´ë”: {upload_folder})")
                    except Exception as e:
                        st.error(f"âŒ ì¸ë±ìŠ¤ ì¬êµ¬ì¶• ì‹¤íŒ¨: {str(e)}")
            
            st.info("ğŸ’¡ ìœ„ ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ìƒˆë¡œ ì—…ë¡œë“œëœ íŒŒì¼ì„ ê²€ìƒ‰ì— í¬í•¨ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    st.markdown("---")
    
    # ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"):
        if selected_folder == "ì¼ë°˜ ì±„íŒ…":
            st.session_state.conversations['ì¼ë°˜'] = []
        elif selected_folder == "ì¬ë¬´ ì •ë³´-ê³ ê¸‰":
            st.session_state.conversations['ì¬ë¬´ ì •ë³´-ê³ ê¸‰'] = []
        else:
            st.session_state.conversations['ì¼ë°˜'] = []
        st.success("ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
        st.rerun()
    
    if st.button("ğŸ”„ íŒŒì¼ ì¸ë±ìŠ¤ ì¬êµ¬ì¶•"):
        with st.spinner("íŒŒì¼ ì¸ë±ìŠ¤ë¥¼ ì¬êµ¬ì¶• ì¤‘ì…ë‹ˆë‹¤..."):
            # í˜„ì¬ ì„ íƒëœ í´ë”ë¡œ ì¸ë±ìŠ¤ ì¬êµ¬ì¶•
            folder_path = folder_options[st.session_state.selected_folder]
            st.session_state.chatbot.rag_system.set_search_folder(folder_path)
            st.success(f"íŒŒì¼ ì¸ë±ìŠ¤ê°€ ì¬êµ¬ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤! (í´ë”: {st.session_state.selected_folder})")

# CSS ìŠ¤íƒ€ì¼ ì¶”ê°€ (ì›ë˜ ìŠ¤íƒ€ì¼ ë³µì›)
st.markdown("""
<style>
/* ì‚¬ìš©ì ë©”ì‹œì§€ ìŠ¤íƒ€ì¼ */
.user-bubble {
    background: #2d2d2d;
    color: #fff;
    padding: 0.7em 1em;
    border-radius: 1em 1em 0 1em;
    margin: 0.5em 0;
    max-width: 70%;
    align-self: flex-end;
    text-align: right;
}

/* ì±—ë´‡ ì‘ë‹µ ìŠ¤íƒ€ì¼ */
.bot-bubble {
    background: #2323a7;
    color: #fff;
    padding: 0.7em 1em;
    border-radius: 1em 1em 1em 0;
    margin: 0.5em 0;
    max-width: 70%;
    align-self: flex-start;
    text-align: left;
}

/* ëŒ€í™” ì»¨í…Œì´ë„ˆ */
.bubble-container {
    display: flex;
    flex-direction: column;
}
</style>
""", unsafe_allow_html=True)

# ëŒ€í™” ê¸°ë¡ í‘œì‹œ (ë§¨ ìœ„)
#st.markdown("### ğŸ’¬ ì±—ë´‡ê³¼ ëŒ€í™”í•˜ê¸°")

# í˜„ì¬ í´ë”ì— ë”°ë¥¸ ëŒ€í™” ê¸°ë¡ ì„ íƒ
if selected_folder == "ì¬ë¬´ ì •ë³´-ê³ ê¸‰":
    current_conversation_key = 'ì¬ë¬´ ì •ë³´-ê³ ê¸‰'
elif selected_folder == "ì¼ë°˜ ì±„íŒ…":
    current_conversation_key = 'ì¼ë°˜'
else:
    current_conversation_key = 'ì¼ë°˜'
current_conversation = st.session_state.conversations.get(current_conversation_key, [])

# ëŒ€í™” ê¸°ë¡ í‘œì‹œ (ì›ë˜ ìŠ¤íƒ€ì¼)
st.markdown('<div class="bubble-container">', unsafe_allow_html=True)
for i, message in enumerate(current_conversation):
    if message['role'] == 'ì‚¬ìš©ì':
        st.markdown(f"<div class='user-bubble'>ğŸ‘¤ {message['content']}</div>", unsafe_allow_html=True)
    else:
        # ì¬ë¬´ ì •ë³´-ê³ ê¸‰ ë¶„ì„ ê²°ê³¼ì¸ì§€ í™•ì¸ (í˜„ì¬ ì„ íƒëœ í´ë”ë„ í™•ì¸)
        if message.get('persona_analyses') and selected_folder == "ì¬ë¬´ ì •ë³´-ê³ ê¸‰":
            # ë©€í‹°ì—ì´ì „íŠ¸ ì¬ë¬´ ë¶„ì„ ê²°ê³¼ë¥¼ ë…ë¦½ì ìœ¼ë¡œ í‘œì‹œ
            st.markdown("---")
            st.markdown("## ğŸ” ë©€í‹°ì—ì´ì „íŠ¸ ì¬ë¬´ ë¶„ì„ ê²°ê³¼")
            
            # ë¶„ì„ ìš”ì²­ í‘œì‹œ
            user_message = current_conversation[i-1]['content'] if i > 0 else "ë¶„ì„ ìš”ì²­"
            st.markdown(f"**ğŸ“‹ ë¶„ì„ ìš”ì²­:** {user_message}")
            st.markdown("---")
            
            # ì „ë¬¸ê°€ë³„ ë¶„ì„ í‘œì‹œ
            st.markdown("### ğŸ‘¥ ì „ë¬¸ê°€ë³„ ë¶„ì„")
            for persona_key, analysis in message['persona_analyses'].items():
                if analysis.get('success') and analysis.get('result'):
                    persona_info = FINANCE_PERSONAS[persona_key]
                    with st.expander(f"{persona_info['emoji']} {persona_info['name']} ë¶„ì„", expanded=True):
                        st.markdown(analysis['result'])
            
            # ìµœì¢… ì¢…í•© ë³´ê³ ì„œ í‘œì‹œ
            final_report = message['content'].split("### ğŸ“‹ ìµœì¢… ì¢…í•© ë³´ê³ ì„œ\n")[-1] if "### ğŸ“‹ ìµœì¢… ì¢…í•© ë³´ê³ ì„œ\n" in message['content'] else ""
            if final_report:
                st.markdown("### ğŸ“‹ ìµœì¢… ì¢…í•© ë³´ê³ ì„œ")
                st.markdown(final_report)
            
            # ë‹¤ìš´ë¡œë“œ ì„¹ì…˜
            st.markdown("---")
            st.markdown("### ğŸ“„ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ")
            
            # íŒŒì¼ í˜•ì‹ ì„ íƒ
            file_format = st.radio(
                "ë‹¤ìš´ë¡œë“œí•  íŒŒì¼ í˜•ì‹ì„ ì„ íƒí•˜ì„¸ìš”:",
                ["ğŸ“„ PDF", "ğŸ“ DOCX"],
                key=f"format_radio_{i}"
            )
            
            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
            if file_format == "ğŸ“„ PDF":
                if st.download_button(
                    label="ğŸ’¾ PDF ë‹¤ìš´ë¡œë“œ",
                    data=create_finance_analysis_pdf(
                        user_message,
                        message['persona_analyses'],
                        message['content'].split("### ğŸ“‹ ìµœì¢… ì¢…í•© ë³´ê³ ì„œ\n")[-1] if "### ğŸ“‹ ìµœì¢… ì¢…í•© ë³´ê³ ì„œ\n" in message['content'] else "",
                        message.get('rag_context', ''),
                        message.get('market_research', '')
                    ).getvalue() if create_finance_analysis_pdf(
                        user_message,
                        message['persona_analyses'],
                        message['content'].split("### ğŸ“‹ ìµœì¢… ì¢…í•© ë³´ê³ ì„œ\n")[-1] if "### ğŸ“‹ ìµœì¢… ì¢…í•© ë³´ê³ ì„œ\n" in message['content'] else "",
                        message.get('rag_context', ''),
                        message.get('market_research', '')
                    ) else b"",
                    file_name=f"ì¬ë¬´ë¶„ì„ë³´ê³ ì„œ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf",
                    mime="application/pdf",
                    key=f"pdf_download_{i}"
                ):
                    st.success("PDF ë‹¤ìš´ë¡œë“œê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!")
            else:  # DOCX
                if st.download_button(
                    label="ğŸ’¾ DOCX ë‹¤ìš´ë¡œë“œ",
                    data=create_finance_analysis_docx(
                        user_message,
                        message['persona_analyses'],
                        message['content'].split("### ğŸ“‹ ìµœì¢… ì¢…í•© ë³´ê³ ì„œ\n")[-1] if "### ğŸ“‹ ìµœì¢… ì¢…í•© ë³´ê³ ì„œ\n" in message['content'] else "",
                        message.get('rag_context', ''),
                        message.get('market_research', '')
                    ).getvalue() if create_finance_analysis_docx(
                        user_message,
                        message['persona_analyses'],
                        message['content'].split("### ğŸ“‹ ìµœì¢… ì¢…í•© ë³´ê³ ì„œ\n")[-1] if "### ğŸ“‹ ìµœì¢… ì¢…í•© ë³´ê³ ì„œ\n" in message['content'] else "",
                        message.get('rag_context', ''),
                        message.get('market_research', '')
                    ) else b"",
                    file_name=f"ì¬ë¬´ë¶„ì„ë³´ê³ ì„œ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx",
                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                    key=f"docx_download_{i}"
                ):
                    st.success("DOCX ë‹¤ìš´ë¡œë“œê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!")
            
            st.info("ë©€í‹°ì—ì´ì „íŠ¸ ì¬ë¬´ ë¶„ì„ ê²°ê³¼ë¥¼ PDF ë˜ëŠ” DOCXë¡œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            # ì¼ë°˜ ì±—ë´‡ ì‘ë‹µ í‘œì‹œ
            if selected_folder == "ì¼ë°˜ ì±„íŒ…":
                # ì¼ë°˜ ì±„íŒ… ëª¨ë“œ: ê°„ë‹¨í•œ ì‘ë‹µë§Œ í‘œì‹œ (ë§ˆí¬ë‹¤ìš´ í¬ë§·íŒ… ì ìš©)
                formatted_content = message['content'].replace('\n', '<br>').replace('**', '<strong>').replace('*', '<em>')
                st.markdown(f"<div class='bot-bubble'>ğŸ’¬ {formatted_content}</div>", unsafe_allow_html=True)
            else:
                # RAG ëª¨ë“œ: ì°¸ê³  ë¬¸ì„œì™€ í•¨ê»˜ í‘œì‹œ
                st.markdown(f"<div class='bot-bubble'>ğŸ¤” {message['content']}</div>", unsafe_allow_html=True)
                
                # ì°¸ê³  ë¬¸ì„œëŠ” AI ë‹µë³€ ë‚´ë¶€ì— ì´ë¯¸ í¬í•¨ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ë³„ë„ í‘œì‹œ ì œê±°
                pass

st.markdown('</div>', unsafe_allow_html=True)

#st.markdown('</div>', unsafe_allow_html=True)

# ì…ë ¥ í•„ë“œ (ë§¨ ì•„ë˜ ê³ ì •)
#st.markdown("---")
st.markdown("### ğŸ’¬ ì§ˆë¬¸í•˜ê¸°")

# ì…ë ¥ í•„ë“œ í‚¤ ê´€ë¦¬
if 'chat_input_key' not in st.session_state:
    st.session_state['chat_input_key'] = 0

# ì…ë ¥ í•„ë“œ
user_input = st.text_area(
    "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:",
    key=f"chat_input_{st.session_state['chat_input_key']}",
    value="",
    height=80,
    label_visibility="collapsed",
    placeholder="ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."
)

if st.button("ì „ì†¡", type="primary"):
    if user_input.strip():
        # í˜„ì¬ í´ë”ì— ë”°ë¥¸ ëŒ€í™” ê¸°ë¡ ì„ íƒ
        if selected_folder == "ì¬ë¬´ ì •ë³´-ê³ ê¸‰":
            current_conversation_key = 'ì¬ë¬´ ì •ë³´-ê³ ê¸‰'
        elif selected_folder == "ì¼ë°˜ ì±„íŒ…":
            current_conversation_key = 'ì¼ë°˜'
        else:
            current_conversation_key = 'ì¼ë°˜'
            
        if current_conversation_key not in st.session_state.conversations:
            st.session_state.conversations[current_conversation_key] = []
        
        st.session_state.conversations[current_conversation_key].append({'role': 'ì‚¬ìš©ì', 'content': user_input, 'timestamp': datetime.now()})
        
        # ì¼ë°˜ ì±„íŒ… ëª¨ë“œì¸ ê²½ìš° RAG ì—†ì´ ìˆœìˆ˜ LLM ì‘ë‹µ
        if selected_folder == "ì¼ë°˜ ì±„íŒ…":
            # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ìœ„í•œ ì»¨í…Œì´ë„ˆ ìƒì„±
            response_container = st.empty()
            full_response = ""
            
            # ëŒ€í™” ê¸°ë¡ì„ ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ìµœê·¼ 10ê°œ ëŒ€í™”ë§Œ ì‚¬ìš©)
            conversation_messages = []
            recent_messages = st.session_state.conversations['ì¼ë°˜'][-20:]  # ìµœê·¼ 20ê°œ ë©”ì‹œì§€ (10ê°œ ëŒ€í™”)
            
            for msg in recent_messages:
                if msg['role'] == 'ì‚¬ìš©ì':
                    conversation_messages.append({"role": "user", "content": msg['content']})
                elif msg['role'] == 'ì±—ë´‡':
                    conversation_messages.append({"role": "assistant", "content": msg['content']})
            
            # í˜„ì¬ ì‚¬ìš©ì ì…ë ¥ ì¶”ê°€
            conversation_messages.append({"role": "user", "content": user_input})
            
            # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
            try:
                if selected_provider == 'openai':
                    # OpenAI ìŠ¤íŠ¸ë¦¬ë°
                    client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
                    stream = client.chat.completions.create(
                        model=selected_model,
                        messages=conversation_messages,
                        temperature=temperature,
                        stream=True
                    )
                    
                    for chunk in stream:
                        if chunk.choices[0].delta.content is not None:
                            full_response += chunk.choices[0].delta.content
                            # ì‹¤ì‹œê°„ìœ¼ë¡œ ì‘ë‹µ ì—…ë°ì´íŠ¸ (ë§ˆí¬ë‹¤ìš´ í¬ë§·íŒ… ì ìš©)
                            formatted_response = full_response.replace('\n', '<br>').replace('**', '<strong>').replace('*', '<em>')
                            response_container.markdown(f"<div class='bot-bubble'>ğŸ’¬ {formatted_response}</div>", unsafe_allow_html=True)
                            
                elif selected_provider == 'anthropic':
                    # Anthropic ìŠ¤íŠ¸ë¦¬ë°
                    client = anthropic.Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))
                    with client.messages.stream(
                        model=selected_model,
                        max_tokens=2000,
                        temperature=temperature,
                        messages=conversation_messages
                    ) as stream:
                        for text in stream.text_stream:
                            full_response += text
                            # ì‹¤ì‹œê°„ìœ¼ë¡œ ì‘ë‹µ ì—…ë°ì´íŠ¸ (ë§ˆí¬ë‹¤ìš´ í¬ë§·íŒ… ì ìš©)
                            formatted_response = full_response.replace('\n', '<br>').replace('**', '<strong>').replace('*', '<em>')
                            response_container.markdown(f"<div class='bot-bubble'>ğŸ’¬ {formatted_response}</div>", unsafe_allow_html=True)
                            
                elif selected_provider == 'ollama':
                    # Ollama ìŠ¤íŠ¸ë¦¬ë°
                    import requests
                    import json
                    
                    # Ollama API í˜•ì‹ì— ë§ê²Œ ë©”ì‹œì§€ ë³€í™˜
                    ollama_messages = []
                    for msg in conversation_messages:
                        if msg['role'] == 'user':
                            ollama_messages.append({
                                'role': 'user',
                                'content': msg['content']
                            })
                        elif msg['role'] == 'assistant':
                            ollama_messages.append({
                                'role': 'assistant',
                                'content': msg['content']
                            })
                    
                    # Ollama ìŠ¤íŠ¸ë¦¬ë° API í˜¸ì¶œ
                    response = requests.post(
                        "http://localhost:11434/api/chat",
                        json={
                            "model": selected_model,
                            "messages": ollama_messages,
                            "stream": True,
                            "options": {
                                "temperature": temperature
                            }
                        },
                        stream=True,
                        timeout=60
                    )
                    
                    for line in response.iter_lines():
                        if line:
                            try:
                                data = json.loads(line.decode('utf-8'))
                                if 'message' in data and 'content' in data['message']:
                                    chunk = data['message']['content']
                                    full_response += chunk
                                    # ì‹¤ì‹œê°„ìœ¼ë¡œ ì‘ë‹µ ì—…ë°ì´íŠ¸ (ë§ˆí¬ë‹¤ìš´ í¬ë§·íŒ… ì ìš©)
                                    formatted_response = full_response.replace('\n', '<br>').replace('**', '<strong>').replace('*', '<em>')
                                    response_container.markdown(f"<div class='bot-bubble'>ğŸ’¬ {formatted_response}</div>", unsafe_allow_html=True)
                            except json.JSONDecodeError:
                                continue
                            
                else:
                    # ê¸°íƒ€ ì œê³µìëŠ” ì¼ë°˜ ì‘ë‹µ
                    response = st.session_state.chatbot.llm_client.generate_response(
                        selected_provider, selected_model, 
                        conversation_messages, 
                        temperature
                    )
                    full_response = response
                    # ë§ˆí¬ë‹¤ìš´ í¬ë§·íŒ… ì ìš©
                    formatted_response = full_response.replace('\n', '<br>').replace('**', '<strong>').replace('*', '<em>')
                    response_container.markdown(f"<div class='bot-bubble'>ğŸ’¬ {formatted_response}</div>", unsafe_allow_html=True)
                    
            except Exception as e:
                st.error(f"ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
                # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì¼ë°˜ ì‘ë‹µìœ¼ë¡œ í´ë°±
                try:
                    response = st.session_state.chatbot.llm_client.generate_response(
                        selected_provider, selected_model, 
                        conversation_messages, 
                        temperature
                    )
                    # responseê°€ íŠœí”Œì¸ ê²½ìš° ì²« ë²ˆì§¸ ìš”ì†Œ ì‚¬ìš©
                    if isinstance(response, tuple):
                        full_response = response[0] if response[0] else "ì‘ë‹µ ìƒì„± ì‹¤íŒ¨"
                    else:
                        full_response = response
                    # ë§ˆí¬ë‹¤ìš´ í¬ë§·íŒ… ì ìš©
                    formatted_response = full_response.replace('\n', '<br>').replace('**', '<strong>').replace('*', '<em>')
                    response_container.markdown(f"<div class='bot-bubble'>ğŸ’¬ {formatted_response}</div>", unsafe_allow_html=True)
                except Exception as fallback_error:
                    st.error(f"í´ë°± ì‘ë‹µ ìƒì„±ë„ ì‹¤íŒ¨: {str(fallback_error)}")
                    full_response = "ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
                    response_container.markdown(f"<div class='bot-bubble'>ğŸ’¬ {full_response}</div>", unsafe_allow_html=True)
            
            # ìµœì¢… ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì €ì¥
            st.session_state.conversations['ì¼ë°˜'].append({
                'role': 'ì±—ë´‡', 
                'content': full_response, 
                'timestamp': datetime.now(), 
                'provider': selected_provider, 
                'model': selected_model
            })
            
        # ì¬ë¬´ ì •ë³´-ê³ ê¸‰ ì˜µì…˜ì¸ ê²½ìš° ë©€í‹°ì—ì´ì „íŠ¸ ë¶„ì„ ìˆ˜í–‰
        elif selected_folder == "ì¬ë¬´ ì •ë³´-ê³ ê¸‰":
            with st.spinner("ğŸ” ë©€í‹°ì—ì´ì „íŠ¸ ë¶„ì„ ì¤‘..."):
                # 1. RAG ì»¨í…ìŠ¤íŠ¸ ìƒì„±
                rag_context = ""
                relevant_docs = st.session_state.chatbot.rag_system.search(user_input, k=5)
                if relevant_docs:
                    context_parts = []
                    for i, doc in enumerate(relevant_docs, 1):
                        title = doc.metadata.get('source', f'ë¬¸ì„œ {i}')
                        content = doc.page_content[:1000]
                        context_parts.append(f"ë¬¸ì„œ {i} - {title}:\n{content}")
                    rag_context = "\n\n".join(context_parts)
                
                # 2. ì‹œì¥ ì¡°ì‚¬ ìˆ˜í–‰
                market_research = ""
                try:
                    market_query = f"{user_input} ê´€ë ¨ ìµœì‹  ì‹œì¥ ë™í–¥ ë° ê²½ìŸì‚¬ ë¶„ì„"
                    market_research = perform_perplexity_search(market_query)
                except Exception as e:
                    st.warning(f"ì‹œì¥ ì¡°ì‚¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                
                # 3. ë©€í‹°ì—ì´ì „íŠ¸ ë¶„ì„ ìˆ˜í–‰
                persona_analyses = {}
                
                # ëª¨ë¸ ì •ë³´ ë””ë²„ê¹…
                st.info(f"ì‚¬ìš©í•  ëª¨ë¸: {selected_model}, ì œê³µì: {selected_provider}")
                
                with ThreadPoolExecutor(max_workers=len(FINANCE_PERSONAS)) as executor:
                    # ê° í˜ë¥´ì†Œë‚˜ë³„ ë¶„ì„ ì‘ì—… ì¤€ë¹„
                    analysis_tasks = []
                    for persona_key, persona_info in FINANCE_PERSONAS.items():
                        task_args = (user_input, persona_key, persona_info, rag_context, market_research, selected_model)
                        analysis_tasks.append(executor.submit(analyze_persona_concurrent_finance, task_args))
                    
                    # ê²°ê³¼ ìˆ˜ì§‘
                    for future in analysis_tasks:
                        persona_key, result, success = future.result()
                        persona_analyses[persona_key] = {
                            'result': result,
                            'success': success
                        }
                
                # 4. ìµœì¢… ë³´ê³ ì„œ ì‘ì„±
                final_report = synthesize_finance_analysis(
                    user_input, persona_analyses, rag_context, market_research, selected_model
                )
                
                # 5. ê²°ê³¼ë¥¼ ëŒ€í™”ì— ì¶”ê°€
                analysis_summary = f"""
## ğŸ” ë©€í‹°ì—ì´ì „íŠ¸ ì¬ë¬´ ë¶„ì„ ê²°ê³¼

### ğŸ“Š ì „ë¬¸ê°€ë³„ ë¶„ì„
"""
                
                for persona_key, analysis in persona_analyses.items():
                    if analysis.get('success'):
                        persona_info = FINANCE_PERSONAS[persona_key]
                        analysis_summary += f"\n#### {persona_info['emoji']} {persona_info['name']}\n{analysis['result']}\n"
                
                analysis_summary += f"\n### ğŸ“‹ ìµœì¢… ì¢…í•© ë³´ê³ ì„œ\n{final_report if final_report else 'ìµœì¢… ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨'}"
                
                st.session_state.conversations['ì¬ë¬´ ì •ë³´-ê³ ê¸‰'].append({
                    'role': 'ì±—ë´‡', 
                    'content': analysis_summary, 
                    'timestamp': datetime.now(), 
                    'provider': selected_provider, 
                    'model': selected_model, 
                    'relevant_docs': relevant_docs,
                    'persona_analyses': persona_analyses,
                    'market_research': market_research,
                    'rag_context': rag_context
                })
        else:
            # ì¼ë°˜ RAG ì±—ë´‡ ì‘ë‹µ (ì¼ë°˜ ì±„íŒ… ëª¨ë“œê°€ ì•„ë‹Œ ê²½ìš°)
            with st.spinner("ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘..."):
                response, relevant_docs = st.session_state.chatbot.generate_response(
                    user_input, selected_provider, selected_model, temperature
                )
                st.session_state.conversations['ì¼ë°˜'].append({
                    'role': 'ì±—ë´‡', 
                    'content': response, 
                    'timestamp': datetime.now(), 
                    'provider': selected_provider, 
                    'model': selected_model, 
                    'relevant_docs': relevant_docs
                })
        
        # ì…ë ¥ ì´ˆê¸°í™”ë¥¼ ìœ„í•œ í‚¤ ë³€ê²½
        if 'chat_input_key' not in st.session_state:
            st.session_state['chat_input_key'] = 0
        st.session_state['chat_input_key'] += 1
        st.rerun()
