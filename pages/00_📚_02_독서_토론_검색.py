import streamlit as st
import pandas as pd
from datetime import datetime
import mysql.connector
import os
from dotenv import load_dotenv
from openai import OpenAI
import requests
import json
import base64

load_dotenv()

def connect_to_db():
    """MySQL DB ì—°ê²°"""
    return mysql.connector.connect(
        user=os.getenv('SQL_USER'),
        password=os.getenv('SQL_PASSWORD'),
        host=os.getenv('SQL_HOST'),
        database=os.getenv('SQL_DATABASE_NEWBIZ'),
        charset='utf8mb4',
        collation='utf8mb4_unicode_ci'
    )

def summarize_for_tts(text, max_length=3500):
    """TTSë¥¼ ìœ„í•´ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½"""
    if len(text) <= max_length:
        return text
    
    # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ ê²½ìš° ì£¼ìš” ì„¹ì…˜ë§Œ í¬í•¨
    lines = text.split('\n')
    summary = []
    current_length = 0
    
    for line in lines:
        # ì œëª©ì´ë‚˜ ì¤‘ìš” ì„¹ì…˜ ì‹œì‘ ë¶€ë¶„ í¬í•¨
        if line.startswith('#') or line.startswith('##'):
            if current_length + len(line) + 2 <= max_length:
                summary.append(line)
                current_length += len(line) + 2
        # í•µì‹¬ ë‚´ìš© í¬í•¨
        elif '[í•µì‹¬ ìš”ì•½]' in line or '[ì£¼ìš” ë¶„ì„]' in line or '[ì‹¤í–‰ ì œì•ˆ]' in line:
            if current_length + len(line) + 2 <= max_length:
                summary.append(line)
                current_length += len(line) + 2
    
    return '\n'.join(summary)

def main():
    st.title("ğŸ“š ë…ì„œ í† ë¡  ì¡°íšŒ")
    
    # OpenAI API í‚¤ ì„¤ì •
    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
    if not OPENAI_API_KEY:
        st.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.stop()
    
    # AI ëª¨ë¸ ì„ íƒ (ê¸°ë³¸ê°’: GPT-4)
    MODEL_NAME = os.getenv('MODEL_NAME', 'gpt-4o-mini')
    ai_models = {
        "GPT-4": MODEL_NAME,
        "GPT-3.5": "gpt-3.5-turbo"
    }
    
    # ê³ ê¸‰ ì„¤ì • ì„¹ì…˜
    with st.expander("ê³ ê¸‰ ì„¤ì •"):
        use_local_llm = st.checkbox("ë¡œì»¬ LLM ì‚¬ìš©", value=False)
        
        if use_local_llm:
            local_models = {
                "Deepseek 14B": "deepseek-r1:14b",
                "Deepseek 32B": "deepseek-r1:32b",
                "Llama 3.1": "llama3.1:latest",
                "Phi-4": "phi4:latest",
                "Mistral": "mistral:latest"
            }
            selected_model = st.selectbox(
                "ë¡œì»¬ LLM ëª¨ë¸ ì„ íƒ",
                list(local_models.keys())
            )
            model_key = f"Local - {selected_model}"
            model_name = local_models[selected_model]
        else:
            selected_model = st.selectbox(
                "OpenAI ëª¨ë¸ ì„ íƒ",
                list(ai_models.keys()),
                index=0
            )
            model_key = selected_model
            model_name = ai_models[selected_model]
    
    # í•„í„° ì˜µì…˜
    col1, col2 = st.columns(2)
    
    with col1:
        titles = get_book_titles()
        if "í¼ìŠ¤ë„ MBA" not in titles:
            titles = ["í¼ìŠ¤ë„ MBA"] + titles
        
        selected_title = st.selectbox(
            "ì±… ì„ íƒ",
            titles,
            index=titles.index("í¼ìŠ¤ë„ MBA") if "í¼ìŠ¤ë„ MBA" in titles else 0
        )
    
    with col2:
        type_mapping = {
            "ìš”ì•½": "summary",
            "ì ìš©": "application",
            "ì ìš© ê³ ê¸‰": "application_advanced",
            "ì ìš© ë¹„êµ": "application_compare"
        }
        material_type = st.selectbox(
            "ìë£Œ ìœ í˜•",
            list(type_mapping.keys())
        )
    
    # ìš”ì•½ ëª¨ë“œì—ì„œ ì´ì „ í† ë¡  ë‚´ìš© ì…ë ¥ í•„ë“œ ì¶”ê°€
    previous_topic = None
    next_topic = None
    if material_type == "ìš”ì•½":
        previous_topic = st.text_input(
            "ì´ì „ í† ë¡  ì£¼ì œ",
            placeholder="ì´ì „ ë…ì„œ í† ë¡ ì˜ ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”",
            key="previous_topic"
        )
    elif material_type == "ì ìš©":
        next_topic = st.text_input(
            "ë‹¤ìŒ í† ë¡  ì£¼ì œ",
            placeholder="ë‹¤ìŒ ë…ì„œ í† ë¡ ì˜ ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”",
            key="next_topic"
        )
    
    # ì ìš© ìë£Œì¸ ê²½ìš° ë¶„ì„ í‚¤ì›Œë“œ ì„ íƒ
    analysis_keyword = None
    if material_type in ["ì ìš©", "ì ìš© ê³ ê¸‰", "ì ìš© ë¹„êµ"]:
        keywords = ["ê°€ì¹˜ ì°½ì¡°", "ë§ˆì¼€íŒ…", "ì„¸ì¼ì¦ˆ", "ê°€ì¹˜ ì „ë‹¬", "ì¬ë¬´", "ê¸°íƒ€"]
        selected_keyword = st.selectbox("ë¶„ì„ í‚¤ì›Œë“œ", keywords)
        
        if selected_keyword == "ê¸°íƒ€":
            analysis_keyword = st.text_input("í‚¤ì›Œë“œ ì§ì ‘ ì…ë ¥")
        else:
            analysis_keyword = selected_keyword
    
    # ì ìš© ë¹„êµ ëª¨ë“œ
    if material_type == "ì ìš© ë¹„êµ":
        show_application_comparison(selected_title, analysis_keyword, model_key, model_name)
    # ì ìš© ê³ ê¸‰ ëª¨ë“œ
    elif material_type == "ì ìš© ê³ ê¸‰":
        show_advanced_application(selected_title, analysis_keyword, model_key, model_name)
    else:
        # ê¸°ì¡´ íŒŒì¼ ëª©ë¡ ì¡°íšŒ ë° í‘œì‹œ ë¡œì§
        files = get_files(selected_title, type_mapping[material_type])
        
        if files:
            selected_file = st.selectbox(
                "íŒŒì¼ ì„ íƒ",
                files,
                format_func=lambda x: f"{x['file_name']} ({x['created_at'].strftime('%Y-%m-%d')})"
            )
            
            if selected_file:
                st.write(f"### {selected_file['file_name']}")
                st.markdown(selected_file['content'])
                st.write("---")
                st.write(f"*ë“±ë¡ì¼: {selected_file['created_at'].strftime('%Y-%m-%d')}*")
                
                # AI ë¶„ì„/ì˜ê²¬ ë²„íŠ¼
                if material_type == "ì ìš©" and analysis_keyword:
                    # AI ë¶„ì„ ê²°ê³¼ í‘œì‹œ ì»¨í…Œì´ë„ˆ ìƒì„±
                    analysis_container = st.container()
                    
                    if st.button("AI ë¶„ì„"):
                        with st.spinner("AIê°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                            analysis = analyze_content(
                                selected_file['content'],
                                analysis_keyword,
                                model_key,
                                model_name
                            )
                            st.session_state.ai_analysis = analysis
                    
                    # AI ë¶„ì„ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í‘œì‹œ
                    if 'ai_analysis' in st.session_state:
                        with analysis_container:
                            st.write("### AI ë¶„ì„ ê²°ê³¼")
                            st.write(st.session_state.ai_analysis)
                            
                            # ìŒì„± ì¬ìƒ ë²„íŠ¼
                            col1, col2 = st.columns([1, 3])
                            with col1:
                                if st.button("ğŸ”Š ìŒì„±ìœ¼ë¡œ ë“£ê¸°"):
                                    with st.spinner("ìŒì„±ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                                        # í´ë¡œì§• ë©˜íŠ¸ ìƒì„±
                                        closing_ment = f"ë‹¤ìŒ ì‹œê°„ì—ëŠ” {next_topic if next_topic else 'ë‹¤ìŒ ì£¼ì œ'}ì— ëŒ€í•œ ë…ì„œ í† ë¡ ì„ ì§„í–‰í•  ì˜ˆì •ì…ë‹ˆë‹¤. ì¦ê±°ìš´ í•˜ë£¨ ë˜ì„¸ìš”. ê°ì‚¬í•©ë‹ˆë‹¤."
                                        
                                        # AI ë¶„ì„ ê²°ê³¼ì™€ í´ë¡œì§• ë©˜íŠ¸ë§Œ í¬í•¨
                                        combined_text = f"""
                                        AI ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.
                                        {st.session_state.ai_analysis}
                                        
                                        {closing_ment}
                                        """
                                        audio_html = text_to_speech(combined_text)
                                        if audio_html:
                                            st.markdown(audio_html, unsafe_allow_html=True)
                
                elif material_type == "ìš”ì•½":
                    # AI ì˜ê²¬ í‘œì‹œ ì»¨í…Œì´ë„ˆ ìƒì„±
                    opinion_container = st.container()
                    
                    # AI ì˜ê²¬ ìƒì„± ë²„íŠ¼
                    if st.button("ğŸ¤– AI ì˜ê²¬ ìƒì„±"):
                        with st.spinner("AIê°€ ì˜ê²¬ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                            st.session_state.ai_opinion = generate_business_opinion(selected_file['content'])
                    
                    # AI ì˜ê²¬ì´ ìˆìœ¼ë©´ í‘œì‹œ
                    if 'ai_opinion' in st.session_state:
                        with opinion_container:
                            st.write("### ğŸ’¡ AI ì˜ê²¬")
                            st.write(st.session_state.ai_opinion)
                            
                            # ìŒì„± ì¬ìƒ ë²„íŠ¼
                            col1, col2 = st.columns([1, 3])
                            with col1:
                                if st.button("ğŸ”Š ìŒì„±ìœ¼ë¡œ ë“£ê¸°"):
                                    with st.spinner("ìŒì„±ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                                        # ì˜¤í”„ë‹ ë©˜íŠ¸ ìƒì„±
                                        opening_ment = f"ì•ˆë…•í•˜ì„¸ìš”. ì¢‹ì€ ì•„ì¹¨ì…ë‹ˆë‹¤. ì§€ë‚œë²ˆ ì‹œê°„ì—ëŠ” {previous_topic if previous_topic else 'ì´ì „ ì£¼ì œ'}ì˜ ë‚´ìš©ìœ¼ë¡œ ë…ì„œí† ë¡ ì„ ì§„í–‰í–ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¼ ì˜¤ëŠ˜ ë…ì„œ í† ë¡  ë‚´ìš©ì„ ìš”ì•½í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
                                        
                                        # ì „ì²´ í…ìŠ¤íŠ¸ êµ¬ì„± ë° ìš”ì•½
                                        full_text = f"""
                                        {opening_ment}
                                        
                                        ìš”ì•½ ë‚´ìš©ì…ë‹ˆë‹¤.
                                        {selected_file['content']}
                                        
                                        AI ì˜ê²¬ì…ë‹ˆë‹¤.
                                        {st.session_state.ai_opinion}
                                        """
                                        summarized_text = summarize_for_tts(full_text)
                                        audio_html = text_to_speech(summarized_text)
                                        if audio_html:
                                            st.markdown(audio_html, unsafe_allow_html=True)
        else:
            st.info(f"{selected_title}ì˜ {material_type} ìë£Œê°€ ì—†ìŠµë‹ˆë‹¤.")

def get_files(book_title, material_type):
    """íŒŒì¼ ëª©ë¡ ì¡°íšŒ"""
    conn = connect_to_db()
    cursor = conn.cursor(dictionary=True)
    
    try:
        cursor.execute("""
            SELECT *
            FROM reading_materials
            WHERE book_title = %s
            AND type = %s
            ORDER BY created_at DESC
        """, (book_title, material_type))
        
        return cursor.fetchall()
    finally:
        cursor.close()
        conn.close()

def get_book_titles():
    """ì €ì¥ëœ ì±… ì œëª© ëª©ë¡ ì¡°íšŒ"""
    conn = connect_to_db()
    cursor = conn.cursor()
    
    try:
        cursor.execute("""
            SELECT DISTINCT book_title
            FROM reading_materials
            ORDER BY book_title
        """)
        return [row[0] for row in cursor.fetchall()]
    finally:
        cursor.close()
        conn.close()

def analyze_content(content, keyword, model_key, model_name):
    """ë‚´ìš© ë¶„ì„"""
    client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
    
    prompt = f"""
    ë‹¤ìŒ ë‚´ìš©ì„ '{keyword}' ê´€ì ì—ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”.
    
    ë¶„ì„ ê²°ê³¼ëŠ” ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš” (ì „ì²´ ê¸€ì ìˆ˜ 1750ì ì´ë‚´ë¡œ ì‘ì„±).
    ë°˜ë“œì‹œ ì¡´ëŒ€ë§ì„ ì‚¬ìš©í•´ ì£¼ì„¸ìš”.
    
    [í•µì‹¬ ìš”ì•½] (150ì ì´ë‚´)
    - í•µì‹¬ ë‚´ìš©ì„ 1-2ì¤„ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”
    
    [ì£¼ìš” ë¶„ì„] (900ì ì´ë‚´)
    1. '{keyword}' ê´€ë ¨ ê°•ì 
    - ì£¼ìš” ê°•ì  2ê°œë¥¼ ì„¤ëª…í•´ ì£¼ì„¸ìš”
    
    2. '{keyword}' ì¸¡ë©´ì˜ ê°œì„ ì 
    - ì£¼ìš” ê°œì„ ì  2ê°œë¥¼ ì œì‹œí•´ ì£¼ì„¸ìš”
    
    [ì‹¤í–‰ ì œì•ˆ] (700ì ì´ë‚´)
    1. '{keyword}' ì¤‘ì‹¬ì˜ ë‹¨ê¸° ê³¼ì œ (1-3ê°œì›”)
    - êµ¬ì²´ì  ì‹¤í–‰ ë°©ì•ˆ 2ê°œë¥¼ ì œì‹œí•´ ì£¼ì„¸ìš”
    - ê° ë°©ì•ˆë³„ ê¸°ëŒ€íš¨ê³¼ë¥¼ ì„¤ëª…í•´ ì£¼ì„¸ìš”
    
    2. '{keyword}' ì¤‘ì‹¬ì˜ ì¤‘ê¸° ê³¼ì œ (3-6ê°œì›”)
    - êµ¬ì²´ì  ì‹¤í–‰ ë°©ì•ˆ 2ê°œë¥¼ ì œì‹œí•´ ì£¼ì„¸ìš”
    - ê° ë°©ì•ˆë³„ ê¸°ëŒ€íš¨ê³¼ë¥¼ ì„¤ëª…í•´ ì£¼ì„¸ìš”
    
    * ëª¨ë“  ë‚´ìš©ì€ ë°˜ë“œì‹œ ì¡´ëŒ€ë§ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
    * ì˜ˆì‹œ: "~í•´ì•¼ í•©ë‹ˆë‹¤", "~í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤", "~í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤" ë“±ì˜ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
    
    ë¶„ì„ ë‚´ìš©:
    {content}
    """
    
    try:
        if model_key.startswith("Local"):
            # ë¡œì»¬ LLM API í˜¸ì¶œ
            response = requests.post(
                "http://localhost:11434/api/generate",
                json={
                    "model": model_name,
                    "prompt": prompt,
                    "max_tokens": 700  # í† í° ìˆ˜ ì œí•œ (ì•½ 1750ì)
                }
            )
            return response.json()['response']
        else:
            # OpenAI API í˜¸ì¶œ
            response = client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•­ìƒ ì¡´ëŒ€ë§ì„ ì‚¬ìš©í•˜ì—¬ ë¶„ì„ ê²°ê³¼ë¥¼ ì‘ì„±í•˜ë˜, í•µì‹¬ì ì¸ ë‚´ìš©ë§Œ ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ì‘ì„±í•©ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=700,  # í† í° ìˆ˜ ì œí•œ (ì•½ 1750ì)
                temperature=0.2
            )
            return response.choices[0].message.content
    except Exception as e:
        st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def generate_business_opinion(summary_text):
    """ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì ì—ì„œì˜ AI ì˜ê²¬ ìƒì„±"""
    client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
    
    # ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ë ¨ í‚¤ì›Œë“œ
    business_keywords = [
        "ì „ëµ", "ì„±ê³¼", "íš¨ìœ¨", "ìƒì‚°ì„±", "í˜ì‹ ", "ì„±ì¥", "ë§¤ì¶œ", "ë¹„ìš©",
        "ê³ ê°", "ì‹œì¥", "ê²½ìŸ", "ê°€ì¹˜", "ë¦¬ë”ì‹­", "ê´€ë¦¬", "ìš´ì˜", "í”„ë¡œì„¸ìŠ¤"
    ]
    
    # ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì¥ ì„ íƒ
    sentences = [s.strip() for s in summary_text.split('.') if len(s.strip()) > 10]
    best_sentence = max(sentences, 
                       key=lambda x: sum(1 for keyword in business_keywords if keyword in x),
                       default=None)
    
    if not best_sentence:
        return "ìš”ì•½ ë‚´ìš©ì—ì„œ ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ë ¨ ì£¼ì œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # ë¬¸ì¥ì—ì„œ í•µì‹¬ ì£¼ì œ ì¶”ì¶œ
    prompt_for_topic = f"""
    ë‹¤ìŒ ë¬¸ì¥ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ë ¨ í•µì‹¬ ì£¼ì œ í•˜ë‚˜ë§Œ 3ë‹¨ì–´ ì´ë‚´ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”:
    "{best_sentence}"
    
    ì˜ˆì‹œ í˜•ì‹: "ê³ ê° ê°€ì¹˜", "íš¨ìœ¨ì  ë¦¬ë”ì‹­", "ì‹œì¥ ì „ëµ" ë“±
    """
    
    try:
        # í•µì‹¬ ì£¼ì œ ì¶”ì¶œ
        topic_response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ ì£¼ì œë¥¼ ì •í™•í•˜ê²Œ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt_for_topic}
            ],
            temperature=0.3,
            max_tokens=10
        )
        
        core_topic = topic_response.choices[0].message.content.strip().strip('"\'')
        
        # ì¶”ì¶œëœ ì£¼ì œì— ëŒ€í•œ ì˜ê²¬ ìƒì„±
        opinion_prompt = f"""
        ë‹¤ìŒì€ ë…ì„œ í† ë¡ ì—ì„œ ë‚˜ì˜¨ ì¤‘ìš”í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ì£¼ì œì…ë‹ˆë‹¤:
        
        ì£¼ì œ: "{core_topic}"
        
        ê´€ë ¨ ë¬¸ì¥: "{best_sentence}"
        
        ì´ ì£¼ì œì— ëŒ€í•´ ë¹„ì¦ˆë‹ˆìŠ¤ ì „ë¬¸ê°€ì˜ ì…ì¥ì—ì„œ ì˜ê²¬ì„ ì œì‹œí•´ì£¼ì„¸ìš”:
        - "ì˜¤ëŠ˜ ë…ì„œ í† ë¡ ì—ì„œ ë‹¤ë£¬ '{core_topic}'ì— ëŒ€í•´ ë§ì”€ë“œë¦¬ê² ìŠµë‹ˆë‹¤."ë¡œ ì‹œì‘í•˜ì—¬
        - ì´ ì£¼ì œê°€ ë¹„ì¦ˆë‹ˆìŠ¤ì— ì–´ë–¤ ì˜ë¯¸ê°€ ìˆëŠ”ì§€
        - ì–´ë–»ê²Œ ì‹¤ì œë¡œ ì ìš©í•´ë³¼ ìˆ˜ ìˆëŠ”ì§€
        ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
        
        150-250ì ë‚´ì™¸ë¡œ í•µì‹¬ì ì¸ ë‚´ìš©ë§Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
        """
        
        opinion_response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì‹¤ë¬´ ê²½í—˜ì´ í’ë¶€í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì£¼ì œì— ëŒ€í•´ ê°„ë‹¨ëª…ë£Œí•˜ê²Œ í•µì‹¬ì ì¸ í†µì°°ê³¼ ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ ì œê³µí•©ë‹ˆë‹¤."},
                {"role": "user", "content": opinion_prompt}
            ],
            temperature=0.7,
            max_tokens=500
        )
        
        return opinion_response.choices[0].message.content
    except Exception as e:
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ì‘ë‹µ
        return f"ì˜¤ëŠ˜ ë…ì„œ í† ë¡ ì—ì„œ ë‹¤ë£¬ '{best_sentence}'ì— ê´€í•œ ì£¼ì œëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ì— ì¤‘ìš”í•œ ì‹œì‚¬ì ì„ ì œê³µí•©ë‹ˆë‹¤."

def text_to_speech(text):
    """OpenAI TTS APIë¥¼ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜"""
    try:
        client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        
        # ìŒì„± ìƒì„± ìš”ì²­
        response = client.audio.speech.create(
            model="tts-1",  # ë˜ëŠ” "tts-1-hd"
            voice="alloy",  # 'alloy', 'echo', 'fable', 'onyx', 'nova', 'shimmer' ì¤‘ ì„ íƒ
            input=text
        )
        
        # ìŒì„± ë°ì´í„°ë¥¼ ë°”ì´íŠ¸ë¡œ ê°€ì ¸ì˜¤ê¸°
        audio_data = response.content
        
        # ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ base64ë¡œ ì¸ì½”ë”©
        audio_base64 = base64.b64encode(audio_data).decode('utf-8')
        
        # HTML audio íƒœê·¸ë¡œ í‘œì‹œ
        audio_html = f"""
            <audio controls>
                <source src="data:audio/mp3;base64,{audio_base64}" type="audio/mp3">
                Your browser does not support the audio element.
            </audio>
        """
        
        return audio_html
    except Exception as e:
        st.error(f"ìŒì„± ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def show_application_comparison(book_title, keyword, model_key, model_name):
    """ì ìš© ìë£Œ ë¹„êµ í™”ë©´ í‘œì‹œ"""
    st.write("### ì ìš© ìë£Œ ë¹„êµ")
    st.write("ë‘ ê°œì˜ ì ìš© ìë£Œë¥¼ ì„ íƒí•˜ì—¬ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    # ì ìš© ìë£Œ ëª©ë¡ ì¡°íšŒ
    files = get_files(book_title, "application")
    
    if not files or len(files) < 2:
        st.warning("ë¹„êµí•  ì ìš© ìë£Œê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìµœì†Œ 2ê°œ ì´ìƒì˜ ì ìš© ìë£Œê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return
    
    # íŒŒì¼ ì„ íƒ ì»¬ëŸ¼
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("#### ê¸°ì¤€ ìë£Œ (ì´ì „)")
        left_file = st.selectbox(
            "ë¹„êµí•  ì²« ë²ˆì§¸ ìë£Œ",
            files,
            format_func=lambda x: f"{x['file_name']} ({x['created_at'].strftime('%Y-%m-%d')})",
            key="left_file"
        )
        
        if left_file:
            st.write(f"**{left_file['file_name']}**")
            st.write(f"*ë“±ë¡ì¼: {left_file['created_at'].strftime('%Y-%m-%d')}*")
            st.text_area("ë‚´ìš©", left_file['content'], height=300, key="left_content", disabled=True)
    
    with col2:
        st.write("#### ë¹„êµ ìë£Œ (ì´í›„)")
        # ì™¼ìª½ì—ì„œ ì„ íƒí•œ íŒŒì¼ ì œì™¸
        right_files = [f for f in files if f['id'] != left_file['id']] if left_file else files
        
        right_file = st.selectbox(
            "ë¹„êµí•  ë‘ ë²ˆì§¸ ìë£Œ",
            right_files,
            format_func=lambda x: f"{x['file_name']} ({x['created_at'].strftime('%Y-%m-%d')})",
            key="right_file"
        )
        
        if right_file:
            st.write(f"**{right_file['file_name']}**")
            st.write(f"*ë“±ë¡ì¼: {right_file['created_at'].strftime('%Y-%m-%d')}*")
            st.text_area("ë‚´ìš©", right_file['content'], height=300, key="right_content", disabled=True)
    
    # ë¹„êµ ë¶„ì„ ë²„íŠ¼
    if left_file and right_file:
        # ë¶„ì„ ê²°ê³¼ í‘œì‹œ ì»¨í…Œì´ë„ˆ
        comparison_container = st.container()
        
        if st.button("ğŸ” AI ë¹„êµ ë¶„ì„"):
            with st.spinner("ë‘ ìë£Œë¥¼ ë¹„êµ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                comparison_result = compare_applications(
                    left_file['content'],
                    right_file['content'],
                    keyword,
                    model_key,
                    model_name
                )
                st.session_state.comparison_result = comparison_result
        
        # ë¹„êµ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í‘œì‹œ
        if 'comparison_result' in st.session_state:
            with comparison_container:
                st.write("### ğŸ“Š ë¹„êµ ë¶„ì„ ê²°ê³¼")
                st.markdown(st.session_state.comparison_result)
                
                # ìŒì„± ì¬ìƒ ë²„íŠ¼
                if st.button("ğŸ”Š ìŒì„±ìœ¼ë¡œ ë“£ê¸°", key="compare_audio"):
                    with st.spinner("ìŒì„±ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                        audio_html = text_to_speech(st.session_state.comparison_result)
                        if audio_html:
                            st.markdown(audio_html, unsafe_allow_html=True)

def compare_applications(content1, content2, keyword, model_key, model_name):
    """ë‘ ì ìš© ìë£Œ ë¹„êµ ë¶„ì„"""
    prompt = f"""
    ë‹¤ìŒì€ '{keyword}' ê´€ì ì—ì„œ ì‘ì„±ëœ ë‘ ê°œì˜ ì ìš© ìë£Œì…ë‹ˆë‹¤. 
    ì²« ë²ˆì§¸ ìë£Œ(ì´ì „)ì™€ ë¹„êµí•˜ì—¬ ë‘ ë²ˆì§¸ ìë£Œ(ì´í›„)ì—ì„œ ì–´ë–¤ ë‚´ìš©ì´ ë³´ê°•ë˜ì—ˆëŠ”ì§€ ë¶„ì„í•´ ì£¼ì„¸ìš”.
    
    [ì²« ë²ˆì§¸ ìë£Œ - ì´ì „]
    {content1}
    
    [ë‘ ë²ˆì§¸ ìë£Œ - ì´í›„]
    {content2}
    
    ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•´ ì£¼ì„¸ìš”:
    
    ## ë¹„êµ ë¶„ì„ ìš”ì•½
    - ë‘ ìë£Œì˜ ì „ë°˜ì ì¸ ì°¨ì´ì ì„ 2-3ì¤„ë¡œ ìš”ì•½
    - ë‘ ë²ˆì§¸ ìë£Œì—ì„œ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ë³´ê°•ëœ ë¶€ë¶„ 2ê°€ì§€
    
    ## ì„¸ë¶€ ë¹„êµ ë¶„ì„
    1. ë³´ê°•ëœ ë‚´ìš©
       - ë‘ ë²ˆì§¸ ìë£Œì—ì„œ ìƒˆë¡­ê²Œ ì¶”ê°€ë˜ê±°ë‚˜ í¬ê²Œ ë°œì „ëœ ë‚´ìš© 3ê°€ì§€
       - ê° ë‚´ìš©ì´ '{keyword}' ê´€ì ì—ì„œ ì–´ë–¤ ê°€ì¹˜ë¥¼ ë”í–ˆëŠ”ì§€ ì„¤ëª…
    
    2. ê°œì„ ëœ ë…¼ë¦¬ì„±
       - ë‘ ë²ˆì§¸ ìë£Œì—ì„œ ë…¼ë¦¬ì  êµ¬ì¡°ë‚˜ ì„¤ë“ë ¥ì´ í–¥ìƒëœ ë¶€ë¶„
       - êµ¬ì²´ì ì¸ ì˜ˆì‹œë‚˜ ë°ì´í„° ë³´ê°• ì‚¬í•­
    
    3. ì‹¤í–‰ ê°€ëŠ¥ì„± í–¥ìƒ
       - ë‘ ë²ˆì§¸ ìë£Œì—ì„œ ì‹¤í–‰ ê³„íšì´ë‚˜ êµ¬ì²´ì„±ì´ ê°œì„ ëœ ë¶€ë¶„
       - '{keyword}' ì¸¡ë©´ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥ì„±ì´ ë†’ì•„ì§„ ìš”ì†Œ
    
    ## ì¢…í•© í‰ê°€
    - ë‘ ë²ˆì§¸ ìë£Œê°€ ì²« ë²ˆì§¸ ìë£Œì— ë¹„í•´ '{keyword}' ê´€ì ì—ì„œ ì–¼ë§ˆë‚˜ ë°œì „í–ˆëŠ”ì§€ í‰ê°€
    - ì—¬ì „íˆ ë³´ì™„ì´ í•„ìš”í•œ ë¶€ë¶„ 1-2ê°€ì§€ ì œì•ˆ
    
    * ëª¨ë“  ë¶„ì„ì€ '{keyword}' ê´€ì ì— ì§‘ì¤‘í•˜ì—¬ ì‘ì„±í•´ ì£¼ì„¸ìš”.
    * êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ ê·¼ê±°ë¥¼ ë“¤ì–´ ì„¤ëª…í•´ ì£¼ì„¸ìš”.
    * ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•´ ì£¼ì„¸ìš”.
    """
    
    try:
        if "Local" in model_key:
            return analyze_content(prompt, keyword, model_key, model_name)
        else:
            return analyze_content(prompt, keyword, model_key, model_name)
    except Exception as e:
        st.error(f"ë¹„êµ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return "ë¹„êµ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."

def show_advanced_application(book_title, keyword, model_key, model_name):
    """ì ìš© ê³ ê¸‰ ëª¨ë“œ - AI ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜ì˜í•œ ê°œì„ ëœ ë³´ê³ ì„œ ìƒì„±"""
    # ê¸°ì¡´ get_files í•¨ìˆ˜ ì‚¬ìš© - í‚¤ì›Œë“œì™€ ìƒê´€ì—†ì´ ëª¨ë“  ì ìš© íŒŒì¼ í‘œì‹œ
    files = get_files(book_title, "application")
    
    if not files:
        st.info(f"{book_title}ì˜ ì ìš© ìë£Œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # íŒŒì¼ ì„ íƒ
    selected_file = st.selectbox(
        "ë¶„ì„í•  íŒŒì¼ ì„ íƒ",
        files,
        format_func=lambda x: f"{x['file_name']} ({x['created_at'].strftime('%Y-%m-%d')})"
    )
    
    if selected_file:
        # íŒŒì¼ ë‚´ìš© í‘œì‹œ
        st.write(f"### ğŸ“„ {selected_file['file_name']}")
        st.markdown(selected_file['content'])
        st.write("---")
        st.write(f"*ë“±ë¡ì¼: {selected_file['created_at'].strftime('%Y-%m-%d')}*")
        
        # AI ë¶„ì„ ì»¨í…Œì´ë„ˆ
        analysis_container = st.container()
        
        # AI ë¶„ì„ ë²„íŠ¼
        if st.button("ğŸ¤– AI ë¶„ì„"):
            with st.spinner("AIê°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                analysis_result = analyze_content(selected_file['content'], keyword, model_key, model_name)
                st.session_state.analysis_result = analysis_result
        
        # AI ë¶„ì„ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í‘œì‹œ
        if 'analysis_result' in st.session_state:
            with analysis_container:
                st.write("### ğŸ” AI ë¶„ì„ ê²°ê³¼")
                st.markdown(st.session_state.analysis_result)
                
                # ê°œì„ ëœ ë³´ê³ ì„œ ìƒì„± ë²„íŠ¼
                if st.button("âœ¨ ê°œì„ ëœ ë³´ê³ ì„œ ìƒì„±"):
                    with st.spinner("AIê°€ ê°œì„ ëœ ë³´ê³ ì„œë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                        improved_report = generate_improved_report(
                            selected_file['content'], 
                            st.session_state.analysis_result,
                            keyword
                        )
                        st.session_state.improved_report = improved_report
                
                # ê°œì„ ëœ ë³´ê³ ì„œê°€ ìˆìœ¼ë©´ í‘œì‹œ
                if 'improved_report' in st.session_state:
                    st.write("### ğŸ“ ê°œì„ ëœ ë³´ê³ ì„œ")
                    
                    # ê¸´ ë³´ê³ ì„œë¥¼ ì„¹ì…˜ë³„ë¡œ ë¶„í• í•˜ì—¬ í‘œì‹œ
                    improved_report = st.session_state.improved_report
                    sections = improved_report.split("\n## ")
                    
                    if len(sections) > 1:
                        # ì²« ë²ˆì§¸ ì„¹ì…˜ (ì œëª© í¬í•¨)
                        st.markdown(sections[0])
                        
                        # ë‚˜ë¨¸ì§€ ì„¹ì…˜ë“¤ì„ íƒ­ìœ¼ë¡œ í‘œì‹œ
                        tabs = st.tabs([s.split("\n")[0] for s in sections[1:]])
                        for i, tab in enumerate(tabs):
                            with tab:
                                st.markdown("## " + sections[i+1])
                    else:
                        # ì„¹ì…˜ì´ ì—†ìœ¼ë©´ ì „ì²´ í‘œì‹œ
                        st.markdown(improved_report)
                    
                    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                    download_filename = f"{selected_file['file_name'].split('.')[0]}_improved.md"
                    st.download_button(
                        label="ğŸ“¥ ê°œì„ ëœ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
                        data=st.session_state.improved_report,
                        file_name=download_filename,
                        mime="text/markdown"
                    )
                    
                    # ì €ì¥ ë²„íŠ¼
                    if st.button("ğŸ’¾ ê°œì„ ëœ ë³´ê³ ì„œ ì €ì¥"):
                        with st.spinner("ë³´ê³ ì„œë¥¼ ì €ì¥ ì¤‘ì…ë‹ˆë‹¤..."):
                            save_result = save_improved_report(
                                book_title,
                                keyword,
                                download_filename,
                                st.session_state.improved_report
                            )
                            if save_result:
                                st.success("ê°œì„ ëœ ë³´ê³ ì„œê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                            else:
                                st.error("ë³´ê³ ì„œ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

def generate_improved_report(original_content, analysis_result, keyword):
    """AI ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜ì˜í•˜ì—¬ ê°œì„ ëœ ë³´ê³ ì„œ ìƒì„±"""
    client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
    
    try:
        # ê¸´ ë‚´ìš©ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ì²­í¬ ê¸°ë°˜ ì ‘ê·¼ë²•
        if len(original_content) > 6000:
            st.info("ë³´ê³ ì„œê°€ ê¸¸ì–´ ì„¹ì…˜ë³„ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")
            
            # 1. ì›ë³¸ ë³´ê³ ì„œë¥¼ ì„¹ì…˜ìœ¼ë¡œ ë¶„í• 
            sections = split_into_sections(original_content)
            
            # 2. ë¶„ì„ ê²°ê³¼ì—ì„œ ê°œì„ ì‚¬í•­ ì¶”ì¶œ
            improvements = extract_improvements(analysis_result)
            
            # 3. ê° ì„¹ì…˜ë³„ë¡œ ê´€ë ¨ ê°œì„ ì‚¬í•­ ì ìš©
            improved_sections = []
            progress_bar = st.progress(0)
            
            for i, section in enumerate(sections):
                # ì´ ì„¹ì…˜ê³¼ ê´€ë ¨ëœ ê°œì„ ì‚¬í•­ ì°¾ê¸°
                relevant_improvements = find_relevant_improvements(section, improvements)
                
                # ì„¹ì…˜ ê°œì„ 
                if relevant_improvements:
                    improved_section = improve_section(section, relevant_improvements, keyword)
                else:
                    improved_section = section
                
                improved_sections.append(improved_section)
                progress_bar.progress((i + 1) / len(sections))
            
            # 4. ê°œì„ ëœ ì„¹ì…˜ ê²°í•©
            return "\n\n".join(improved_sections)
        
        else:
            # ê¸°ì¡´ ë°©ì‹: í•œ ë²ˆì— ì²˜ë¦¬
            prompt = f"""
            ë‹¤ìŒì€ '{keyword}' ê´€ì ì—ì„œ ì‘ì„±ëœ ì›ë³¸ ì‚¬ì—… ì „ëµ ë³´ê³ ì„œì…ë‹ˆë‹¤:
            
            [ì›ë³¸ ë³´ê³ ì„œ]
            {original_content}
            
            ë‹¤ìŒì€ ì´ ë³´ê³ ì„œì— ëŒ€í•œ AI ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:
            
            [AI ë¶„ì„ ê²°ê³¼]
            {analysis_result}
            
            ìœ„ AI ë¶„ì„ ê²°ê³¼ì—ì„œ ì œì‹œëœ ê°œì„ ì‚¬í•­ê³¼ ì‹¤í–‰ ì œì•ˆì„ ë°˜ì˜í•˜ì—¬ ì›ë³¸ ë³´ê³ ì„œë¥¼ ê°œì„ í•´ì£¼ì„¸ìš”.
            
            ì ˆëŒ€ì  ìš”êµ¬ì‚¬í•­:
            1. ì›ë³¸ ë³´ê³ ì„œì˜ ëª¨ë“  ë‚´ìš©ì„ 100% ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤. ì–´ë–¤ ë‚´ìš©ë„ ì‚­ì œí•˜ê±°ë‚˜ ì¶•ì•½í•˜ì§€ ë§ˆì„¸ìš”.
            2. ì›ë³¸ ë³´ê³ ì„œì˜ ëª¨ë“  ì„¹ì…˜, ì†Œì œëª©, êµ¬ì¡°ë¥¼ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ì„¸ìš”.
            3. AI ë¶„ì„ì—ì„œ ì§€ì ëœ ê°œì„ ì ê³¼ ì‹¤í–‰ ì œì•ˆì„ ì›ë³¸ ë³´ê³ ì„œì˜ ì ì ˆí•œ ìœ„ì¹˜ì— ì¶”ê°€í•˜ì„¸ìš”.
            4. ì¶”ê°€ëœ ë‚´ìš©ì€ ì›ë³¸ ë‚´ìš©ê³¼ ìì—°ìŠ¤ëŸ½ê²Œ í†µí•©ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
            5. ì›ë³¸ì˜ í†¤ê³¼ ìŠ¤íƒ€ì¼ì„ ìœ ì§€í•˜ì„¸ìš”.
            6. ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì„ ìœ ì§€í•˜ì„¸ìš”.
            
            ìµœì¢… ê²°ê³¼ë¬¼ì€ ì›ë³¸ ë³´ê³ ì„œì˜ ëª¨ë“  ë‚´ìš©ì„ ê·¸ëŒ€ë¡œ í¬í•¨í•˜ë©´ì„œ, AI ë¶„ì„ì˜ ê°œì„ ì‚¬í•­ê³¼ ì œì•ˆì‚¬í•­ì´ ìì—°ìŠ¤ëŸ½ê²Œ í†µí•©ëœ ë³´ê³ ì„œì—¬ì•¼ í•©ë‹ˆë‹¤.
            """
            
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ë¹„ì¦ˆë‹ˆìŠ¤ ì „ëµ ë³´ê³ ì„œ ê°œì„  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì›ë³¸ ë³´ê³ ì„œì˜ ëª¨ë“  ë‚´ìš©ê³¼ êµ¬ì¡°ë¥¼ 100% ìœ ì§€í•˜ë©´ì„œ ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜ì˜í•˜ì—¬ ë³´ê³ ì„œë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ê°œì„ í•©ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                max_tokens=4000
            )
            
            return response.choices[0].message.content
            
    except Exception as e:
        st.error(f"ê°œì„ ëœ ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return "ê°œì„ ëœ ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

def split_into_sections(content):
    """ë³´ê³ ì„œë¥¼ ì„¹ì…˜ìœ¼ë¡œ ë¶„í• """
    # ì œëª© íŒ¨í„´ìœ¼ë¡œ ë¶„í•  (# ë˜ëŠ” ## ë“±ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ë¼ì¸)
    import re
    sections = re.split(r'\n(#+\s+)', content)
    
    # ë¶„í• ëœ ê²°ê³¼ ì¬êµ¬ì„±
    if sections[0].strip() == '':
        sections = sections[1:]
    
    processed_sections = []
    for i in range(0, len(sections), 2):
        if i+1 < len(sections):
            processed_sections.append(sections[i] + sections[i+1])
        else:
            processed_sections.append(sections[i])
    
    return processed_sections if processed_sections else [content]

def extract_improvements(analysis_result):
    """ë¶„ì„ ê²°ê³¼ì—ì„œ ê°œì„ ì‚¬í•­ ì¶”ì¶œ"""
    client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
    
    prompt = f"""
    ë‹¤ìŒ AI ë¶„ì„ ê²°ê³¼ì—ì„œ ì£¼ìš” ê°œì„ ì‚¬í•­ê³¼ ì‹¤í–‰ ì œì•ˆì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”:
    
    {analysis_result}
    
    ê° ê°œì„ ì‚¬í•­ì„ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”:
    1. ê°œì„  ì˜ì—­: (ì˜ˆ: ë§ˆì¼€íŒ… ì „ëµ, ê³ ê° ê´€ê³„ ë“±)
    2. ê°œì„  ë‚´ìš©: (êµ¬ì²´ì ì¸ ê°œì„  ì œì•ˆ)
    3. ê´€ë ¨ í‚¤ì›Œë“œ: (ì´ ê°œì„ ì‚¬í•­ê³¼ ê´€ë ¨ëœ í‚¤ì›Œë“œ ëª©ë¡)
    """
    
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",  # ê°€ë²¼ìš´ ëª¨ë¸ ì‚¬ìš©
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë¶„ì„ ê²°ê³¼ì—ì„œ í•µì‹¬ ê°œì„ ì‚¬í•­ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.2
    )
    
    return response.choices[0].message.content

def find_relevant_improvements(section, improvements):
    """ì„¹ì…˜ê³¼ ê´€ë ¨ëœ ê°œì„ ì‚¬í•­ ì°¾ê¸°"""
    client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
    
    prompt = f"""
    ë‹¤ìŒ ë³´ê³ ì„œ ì„¹ì…˜ê³¼ ê´€ë ¨ëœ ê°œì„ ì‚¬í•­ì„ ì°¾ì•„ì£¼ì„¸ìš”:
    
    [ë³´ê³ ì„œ ì„¹ì…˜]
    {section}
    
    [ê°œì„ ì‚¬í•­ ëª©ë¡]
    {improvements}
    
    ì´ ì„¹ì…˜ê³¼ ê´€ë ¨ëœ ê°œì„ ì‚¬í•­ë§Œ ì„ íƒí•˜ì—¬ ë°˜í™˜í•´ì£¼ì„¸ìš”.
    """
    
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",  # ê°€ë²¼ìš´ ëª¨ë¸ ì‚¬ìš©
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë³´ê³ ì„œ ì„¹ì…˜ê³¼ ê´€ë ¨ëœ ê°œì„ ì‚¬í•­ì„ ì°¾ìŠµë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.2
    )
    
    return response.choices[0].message.content

def improve_section(section, relevant_improvements, keyword):
    """ì„¹ì…˜ ê°œì„ """
    client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
    
    prompt = f"""
    ë‹¤ìŒ ë³´ê³ ì„œ ì„¹ì…˜ì„ ê°œì„ í•´ì£¼ì„¸ìš”:
    
    [ì›ë³¸ ì„¹ì…˜]
    {section}
    
    [ê´€ë ¨ ê°œì„ ì‚¬í•­]
    {relevant_improvements}
    
    '{keyword}' ê´€ì ì—ì„œ ìœ„ ê°œì„ ì‚¬í•­ì„ ë°˜ì˜í•˜ì—¬ ì„¹ì…˜ì„ ê°œì„ í•´ì£¼ì„¸ìš”.
    
    ì ˆëŒ€ì  ìš”êµ¬ì‚¬í•­:
    1. ì›ë³¸ ì„¹ì…˜ì˜ ëª¨ë“  ë‚´ìš©ì„ 100% ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤. ì–´ë–¤ ë‚´ìš©ë„ ì‚­ì œí•˜ê±°ë‚˜ ì¶•ì•½í•˜ì§€ ë§ˆì„¸ìš”.
    2. ì›ë³¸ ì„¹ì…˜ì˜ êµ¬ì¡°ë¥¼ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ì„¸ìš”.
    3. ê°œì„ ì‚¬í•­ì„ ì›ë³¸ ë‚´ìš©ê³¼ ìì—°ìŠ¤ëŸ½ê²Œ í†µí•©í•˜ì„¸ìš”.
    4. ì›ë³¸ì˜ í†¤ê³¼ ìŠ¤íƒ€ì¼ì„ ìœ ì§€í•˜ì„¸ìš”.
    """
    
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ë¹„ì¦ˆë‹ˆìŠ¤ ì „ëµ ë³´ê³ ì„œ ê°œì„  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì›ë³¸ ë‚´ìš©ì„ 100% ìœ ì§€í•˜ë©´ì„œ ê°œì„ ì‚¬í•­ì„ í†µí•©í•©ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.2
    )
    
    return response.choices[0].message.content

def save_improved_report(book_title, keyword, file_name, content):
    """ê°œì„ ëœ ë³´ê³ ì„œë¥¼ ì €ì¥"""
    try:
        # ì €ì¥ ê²½ë¡œ ì„¤ì •
        save_dir = f"data/{book_title}/application"
        os.makedirs(save_dir, exist_ok=True)
        
        # íŒŒì¼ëª…ì— í‚¤ì›Œë“œì™€ ë‚ ì§œ ì¶”ê°€
        today = datetime.now().strftime("%Y%m%d")
        save_path = f"{save_dir}/{keyword}_{today}_improved.md"
        
        # íŒŒì¼ ì €ì¥
        with open(save_path, "w", encoding="utf-8") as f:
            f.write(content)
        
        return True
    except Exception as e:
        st.error(f"íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False

def get_application_files(book_title, keyword):
    """íŠ¹ì • ì±…ê³¼ í‚¤ì›Œë“œì— í•´ë‹¹í•˜ëŠ” ì ìš© íŒŒì¼ ëª©ë¡ ì¡°íšŒ"""
    try:
        conn = connect_to_db()
        cursor = conn.cursor(dictionary=True)
        
        # ê¸°ì¡´ get_files í•¨ìˆ˜ì™€ ë™ì¼í•œ í…Œì´ë¸” ì´ë¦„ ì‚¬ìš©
        # í…Œì´ë¸” ì´ë¦„ì„ book_materialsë¡œ ë³€ê²½ (ì˜ˆì‹œ)
        if keyword:
            query = """
                SELECT id, file_name, content, created_at
                FROM book_materials
                WHERE book_title = %s AND file_type = 'application' AND content LIKE %s
                ORDER BY created_at DESC
            """
            cursor.execute(query, (book_title, f"%{keyword}%"))
        else:
            query = """
                SELECT id, file_name, content, created_at
                FROM book_materials
                WHERE book_title = %s AND file_type = 'application'
                ORDER BY created_at DESC
            """
            cursor.execute(query, (book_title,))
        
        files = cursor.fetchall()
        cursor.close()
        conn.close()
        
        return files
    except Exception as e:
        st.error(f"íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return []

if __name__ == "__main__":
    main() 
    