import streamlit as st
import mysql.connector
import pandas as pd
import plotly.express as px
from datetime import datetime
import os
from dotenv import load_dotenv
from langchain.chat_models import ChatOllama
from langchain.embeddings import CacheBackedEmbeddings, OllamaEmbeddings
from langchain.vectorstores.faiss import FAISS
from langchain.text_splitter import CharacterTextSplitter
from langchain.document_loaders import DirectoryLoader
from langchain.document_loaders import (
    UnstructuredMarkdownLoader,
    UnstructuredPDFLoader,
    UnstructuredFileLoader,
    DirectoryLoader
)
import tempfile
import requests
import json

load_dotenv()

# Set page configuration
st.set_page_config(page_title="Vote ê²°ê³¼", page_icon="ğŸ“Š", layout="wide")

# Page header
st.title("íˆ¬í‘œ ê²°ê³¼")

# MySQL ì—°ê²° ì„¤ì •
def connect_to_db():
    return mysql.connector.connect(
        user=os.getenv('SQL_USER'),
        password=os.getenv('SQL_PASSWORD'),
        host=os.getenv('SQL_HOST'),
        database=os.getenv('SQL_DATABASE_NEWBIZ'),
        charset='utf8mb4',
        collation='utf8mb4_unicode_ci'
    )

def get_all_questions():
    conn = connect_to_db()
    cursor = conn.cursor(dictionary=True)
    
    try:
        cursor.execute("""
            SELECT q.*, 
                   COUNT(DISTINCT r.response_id) as total_votes,
                   COUNT(DISTINCT r.voter_name) as unique_voters
            FROM vote_questions q
            LEFT JOIN vote_responses r ON q.question_id = r.question_id
            GROUP BY q.question_id
            ORDER BY q.created_at DESC
        """)
        return cursor.fetchall()
    finally:
        cursor.close()
        conn.close()

def get_question_results(question_id):
    """íˆ¬í‘œ ê²°ê³¼ì™€ íˆ¬í‘œì ëª©ë¡ ì¡°íšŒ"""
    conn = connect_to_db()
    cursor = conn.cursor(dictionary=True)
    
    try:
        # ì „ì²´ íˆ¬í‘œ ìˆ˜ ì¡°íšŒ
        cursor.execute("""
            SELECT COUNT(DISTINCT r.response_id) as total_votes
            FROM vote_responses r
            WHERE question_id = %s
        """, (question_id,))
        total_votes = cursor.fetchone()['total_votes']
        
        # ì˜µì…˜ë³„ ê²°ê³¼ ì¡°íšŒ
        cursor.execute("""
            SELECT 
                o.option_id,
                o.option_text,
                COUNT(DISTINCT r.response_id) as vote_count,
                COALESCE(
                    ROUND(COUNT(DISTINCT r.response_id) * 100.0 / NULLIF(%s, 0), 1),
                    0.0
                ) as vote_percentage,
                GROUP_CONCAT(DISTINCT r.reasoning SEPARATOR '\n') as reasonings
            FROM vote_options o
            LEFT JOIN vote_responses r ON o.option_id = r.option_id
            WHERE o.question_id = %s
            GROUP BY o.option_id, o.option_text
            ORDER BY vote_count DESC
        """, (total_votes, question_id))
        results = cursor.fetchall()
        
        # íˆ¬í‘œì ëª©ë¡ ì¡°íšŒ (ì‹ ë¢°ë„ ì ìˆ˜ í¬í•¨)
        cursor.execute("""
            SELECT DISTINCT 
                r.voter_name,
                COALESCE(uc.credibility_score, 1.0) as credibility_score
            FROM vote_responses r
            LEFT JOIN dot_user_credibility uc 
                ON r.voter_name COLLATE utf8mb4_unicode_ci = uc.user_name COLLATE utf8mb4_unicode_ci
            WHERE r.question_id = %s AND r.voter_name IS NOT NULL
            ORDER BY r.voter_name
        """, (question_id,))
        voters = cursor.fetchall()
        
        return results, voters
    finally:
        cursor.close()
        conn.close()

def get_available_models():
    """Ollamaì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ë°˜í™˜"""
    return [
        "deepseek-r1:70b",  # 42GB - ê°€ì¥ í° ëª¨ë¸
        "deepseek-r1:32b",  # 19GB
        "deepseek-r1:14b",  # 9.0GB
        "phi4:latest",      # 9.1GB
        "gemma2:latest",    # 5.4GB
        "llama3.1:latest",  # 4.9GB
        "mistral:latest",   # 4.1GB
        "llama2:latest",    # 3.8GB
        "llama3.2:latest"   # 2.0GB
    ]

def get_llm_vote(question_id, model_name):
    """LLMì˜ íˆ¬í‘œ ê²°ê³¼ì™€ ì´ìœ  ê°€ì ¸ì˜¤ê¸°"""
    conn = connect_to_db()
    cursor = conn.cursor(dictionary=True)
    result = None
    
    try:
        cursor.execute("""
            SELECT o.option_text, lr.reasoning
            FROM vote_llm_responses lr
            JOIN vote_options o ON lr.option_id = o.option_id
            WHERE lr.question_id = %s AND lr.llm_model = %s
            ORDER BY lr.voted_at DESC
            LIMIT 1
        """, (question_id, model_name))
        
        # ê²°ê³¼ë¥¼ ì™„ì „íˆ ì½ì–´ì˜´
        result = cursor.fetchone()
        
    except mysql.connector.Error as err:
        st.error(f"LLM íˆ¬í‘œ ê²°ê³¼ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {err}")
    finally:
        # ì»¤ì„œì™€ ì—°ê²° ì •ë¦¬
        cursor.close()
        conn.close()
    
    return result

def load_single_file(file_path):
    """ë‹¨ì¼ íŒŒì¼ ë¡œë“œ"""
    try:
        if file_path.endswith('.md'):
            loader = UnstructuredMarkdownLoader(file_path)
        elif file_path.endswith('.pdf'):
            loader = UnstructuredPDFLoader(file_path)
        else:
            loader = UnstructuredFileLoader(file_path)
        
        return loader.load()
    except Exception as e:
        st.error(f"íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

def load_files(files):
    """ì—…ë¡œë“œëœ íŒŒì¼ë“¤ì„ ë¡œë“œ"""
    documents = []
    for file in files:
        try:
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(file.name)[1]) as tmp_file:
                tmp_file.write(file.getvalue())
                tmp_file.flush()
                
                # íŒŒì¼ ë¡œë“œ
                docs = load_single_file(tmp_file.name)
                documents.extend(docs)
                
                # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                os.unlink(tmp_file.name)
        except Exception as e:
            st.error(f"'{file.name}' íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    return documents

def create_vectorstore(documents):
    """ë²¡í„° ìŠ¤í† ì–´ ìƒì„±"""
    try:
        # í…ìŠ¤íŠ¸ ë¶„í• 
        text_splitter = CharacterTextSplitter(
            separator="\n",
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len
        )
        
        # ë¬¸ì„œ ë¶„í• 
        splits = text_splitter.split_documents(documents)
        
        # ì„ë² ë”© ìƒì„± (ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©)
        embeddings = OllamaEmbeddings(
            model="llama2"
        )
        
        # ChromaDBë¥¼ ì‚¬ìš©í•œ ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
        from langchain.vectorstores import Chroma
        
        # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        with tempfile.TemporaryDirectory() as temp_dir:
            vectorstore = Chroma.from_documents(
                documents=splits,
                embedding=embeddings,
                persist_directory=temp_dir  # ì„ì‹œ ë””ë ‰í† ë¦¬ ì§€ì •
            )
            
            return vectorstore
            
    except Exception as e:
        st.error(f"ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        if "404" in str(e):
            st.info("í•„ìš”í•œ ëª¨ë¸ì„ ì„¤ì¹˜í•˜ë ¤ë©´ í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:\n```bash\nollama pull llama2\n```")
        return None

def get_relevant_context(vectorstore, question, options):
    """ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ë§¥ ê²€ìƒ‰"""
    if not vectorstore:
        return ""
        
    # ì§ˆë¬¸ê³¼ ëª¨ë“  ì„ íƒì§€ë¥¼ ê²°í•©í•˜ì—¬ ê²€ìƒ‰
    search_text = f"{question}\n{options}"
    
    # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
    docs = vectorstore.similarity_search(search_text, k=3)
    
    # ë¬¸ë§¥ ê²°í•©
    context = "\n\n".join([doc.page_content for doc in docs])
    return context

def ask_llm(question, options, model_name, context=""):
    """LLMì—ê²Œ íˆ¬í‘œ ìš”ì²­í•˜ê³  ì‘ë‹µ ë°›ê¸°"""
    try:
        # Ollama API ì§ì ‘ í˜¸ì¶œ
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        if context:
            prompt = f"""
            ë‹¹ì‹ ì€ íˆ¬í‘œ ì‹œìŠ¤í…œì˜ ì°¸ì—¬ìì…ë‹ˆë‹¤. 
            ì•„ë˜ ì œê³µëœ ë¬¸ë§¥, ì§ˆë¬¸, ì„ íƒì§€ë¥¼ ì‹ ì¤‘íˆ ë¶„ì„í•˜ê³  ê°€ì¥ ì ì ˆí•œ ë‹µì„ ì„ íƒí•´ì£¼ì„¸ìš”.
            
            ì°¸ê³ í•  ë¬¸ë§¥:
            {context}
            
            ì§ˆë¬¸: {question}
            
            ì„ íƒì§€:
            {options}
            """
        else:
            prompt = f"""
            ë‹¹ì‹ ì€ íˆ¬í‘œ ì‹œìŠ¤í…œì˜ ì°¸ì—¬ìì…ë‹ˆë‹¤. 
            ì•„ë˜ ì§ˆë¬¸ê³¼ ì„ íƒì§€ë¥¼ ì‹ ì¤‘íˆ ë¶„ì„í•˜ê³  ê°€ì¥ ì ì ˆí•œ ë‹µì„ ì„ íƒí•´ì£¼ì„¸ìš”.
            
            ì§ˆë¬¸: {question}
            
            ì„ íƒì§€:
            {options}
            """
        
        prompt += """
        ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì •í™•íˆ ë‹µë³€í•´ì£¼ì„¸ìš”:
        {
            "selection": <ì„ íƒí•œ ë²ˆí˜¸>,
            "reasoning": "<ì„ íƒí•œ ì´ìœ ì— ëŒ€í•œ ìƒì„¸ ì„¤ëª…>",
            "reference": "<ì°¸ê³ í•œ ë¬¸ë§¥ ë‚´ìš© ìš”ì•½ ë˜ëŠ” 'ë¬¸ë§¥ ì—†ìŒ'>"
        }
        """
        
        # Ollama API í˜¸ì¶œ
        response = requests.post(
            "http://localhost:11434/api/generate",
            json={
                "model": model_name,
                "prompt": prompt,
                "stream": False,
                "format": "json",
                "temperature": 0.1
            }
        )
        
        response.raise_for_status()
        result = response.json()
        
        return result.get('response', '')
        
    except Exception as e:
        st.error(f"LLM í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def parse_llm_response(response_text):
    """LLM ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ ì„ íƒ ë²ˆí˜¸ì™€ ì´ìœ  ì¶”ì¶œ"""
    try:
        # ë””ë²„ê¹…ì„ ìœ„í•œ ì›ë³¸ ì‘ë‹µ ì¶œë ¥
        st.write("ë””ë²„ê·¸ - ì›ë³¸ ì‘ë‹µ:", response_text)
        
        # JSON í˜•ì‹ ì°¾ê¸°
        import re
        import json
        
        # JSON í˜•ì‹ ì°¾ê¸° ì‹œë„
        json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
        if json_match:
            try:
                response_json = json.loads(json_match.group())
                selection = int(response_json['selection'])
                reasoning = response_json['reasoning']
                return selection, reasoning
            except (json.JSONDecodeError, KeyError, ValueError):
                pass
        
        # JSON íŒŒì‹± ì‹¤íŒ¨ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì‹œë„
        lines = [line.strip() for line in response_text.split('\n') if line.strip()]
        selection = None
        reasoning = []
        parsing_reason = False
        
        for line in lines:
            if 'ì„ íƒ' in line.lower() or 'selection' in line.lower():
                numbers = [int(s) for s in line.split() if s.isdigit()]
                if numbers:
                    selection = numbers[0]
                    continue
            
            if 'ì´ìœ ' in line.lower() or 'reasoning' in line.lower() or parsing_reason:
                parsing_reason = True
                current_reason = line.replace('ì´ìœ :', '').replace('reasoning:', '').strip()
                if current_reason:
                    reasoning.append(current_reason)
        
        if selection is None:
            raise ValueError("ì„ íƒ ë²ˆí˜¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        reasoning_text = ' '.join(reasoning) if reasoning else "ì´ìœ ê°€ ëª…ì‹œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        return selection, reasoning_text
        
    except Exception as e:
        raise ValueError(f"ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {str(e)}\nì›ë³¸ ì‘ë‹µ: {response_text}")

def save_llm_vote(question_id, option_id, model_name, reasoning, weight):
    """LLMì˜ íˆ¬í‘œ ê²°ê³¼ë¥¼ DBì— ì €ì¥"""
    conn = connect_to_db()
    cursor = conn.cursor()
    
    try:
        cursor.execute("""
            INSERT INTO vote_llm_responses 
            (question_id, option_id, llm_model, reasoning, weight)
            VALUES (%s, %s, %s, %s, %s)
        """, (question_id, option_id, model_name, reasoning, weight))
        conn.commit()
    finally:
        cursor.close()
        conn.close()

def get_combined_results(question_id, apply_weights=False):
    """ì¼ë°˜ íˆ¬í‘œì™€ LLM íˆ¬í‘œ ê²°ê³¼ ëª¨ë‘ ê°€ì ¸ì˜¤ê¸°"""
    conn = connect_to_db()
    cursor = conn.cursor(dictionary=True)
    
    try:
        if apply_weights:
            # ì‹ ë¢°ë„ ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•œ ì¿¼ë¦¬
            cursor.execute("""
                WITH vote_data AS (
                    SELECT 
                        r.option_id,
                        COUNT(DISTINCT r.response_id) as vote_count,
                        SUM(COALESCE(uc.credibility_score, 1.0)) as total_credibility
                    FROM vote_responses r
                    LEFT JOIN dot_user_credibility uc 
                        ON r.voter_name COLLATE utf8mb4_unicode_ci = uc.user_name COLLATE utf8mb4_unicode_ci
                    WHERE r.question_id = %s
                    GROUP BY r.option_id
                ),
                llm_data AS (
                    SELECT 
                        option_id,
                        SUM(weight) as total_weight
                    FROM vote_llm_responses
                    WHERE question_id = %s
                    GROUP BY option_id
                )
                SELECT 
                    o.option_text,
                    COALESCE(v.vote_count, 0) as raw_human_votes,
                    CAST(COALESCE(v.total_credibility, 0) AS SIGNED) as human_votes,
                    CAST(COALESCE(l.total_weight, 0) AS SIGNED) as weighted_llm_votes,
                    CAST(
                        COALESCE(v.total_credibility, 0) + COALESCE(l.total_weight, 0)
                        AS SIGNED
                    ) as total_votes
                FROM vote_options o
                LEFT JOIN vote_data v ON o.option_id = v.option_id
                LEFT JOIN llm_data l ON o.option_id = l.option_id
                WHERE o.question_id = %s
                ORDER BY total_votes DESC
            """, (question_id, question_id, question_id))
        else:
            cursor.execute("""
                WITH vote_data AS (
                    SELECT 
                        option_id,
                        COUNT(DISTINCT response_id) as vote_count
                    FROM vote_responses
                    WHERE question_id = %s
                    GROUP BY option_id
                ),
                llm_data AS (
                    SELECT 
                        option_id,
                        SUM(weight) as total_weight
                    FROM vote_llm_responses
                    WHERE question_id = %s
                    GROUP BY option_id
                )
                SELECT 
                    o.option_text,
                    COALESCE(v.vote_count, 0) as human_votes,
                    CAST(COALESCE(l.total_weight, 0) AS SIGNED) as weighted_llm_votes,
                    CAST(
                        COALESCE(v.vote_count, 0) + COALESCE(l.total_weight, 0)
                        AS SIGNED
                    ) as total_votes
                FROM vote_options o
                LEFT JOIN vote_data v ON o.option_id = v.option_id
                LEFT JOIN llm_data l ON o.option_id = l.option_id
                WHERE o.question_id = %s
                ORDER BY total_votes DESC
            """, (question_id, question_id, question_id))
        
        results = cursor.fetchall()
        print("Combined Results:", results)  # Debugging output
        return results
    finally:
        cursor.close()
        conn.close()

def get_question_options(question_id):
    """ì§ˆë¬¸ì— ëŒ€í•œ ì„ íƒì§€ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
    conn = connect_to_db()
    cursor = conn.cursor(dictionary=True)
    
    try:
        cursor.execute("""
            SELECT option_id, option_text
            FROM vote_options
            WHERE question_id = %s
            ORDER BY option_id
        """, (question_id,))
        return cursor.fetchall()
    finally:
        cursor.close()
        conn.close()

def get_vote_results():
    """íˆ¬í‘œ ê²°ê³¼ ì¡°íšŒ"""
    conn = connect_to_db()
    cursor = conn.cursor(dictionary=True)
    
    try:
        cursor.execute("""
            SELECT 
                v.option_id,
                o.option_text,
                COUNT(v.vote_id) as vote_count,
                COALESCE(
                    (COUNT(v.vote_id) * 100.0 / 
                    NULLIF((SELECT COUNT(*) FROM votes), 0)), 
                    0
                ) as vote_percentage
            FROM vote_options o
            LEFT JOIN votes v ON o.option_id = v.option_id
            GROUP BY o.option_id, o.option_text
            ORDER BY vote_count DESC
        """)
        return cursor.fetchall()
    finally:
        cursor.close()
        conn.close()

def main():
    # ëª¨ë“  íˆ¬í‘œ ë¬¸ì œ ê°€ì ¸ì˜¤ê¸°
    questions = get_all_questions()
    
    if not questions:
        st.info("ë“±ë¡ëœ íˆ¬í‘œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ë¬¸ì œ ì„ íƒ
    selected_question = st.selectbox(
        "ê²°ê³¼ë¥¼ ë³¼ íˆ¬í‘œë¥¼ ì„ íƒí•˜ì„¸ìš”",
        questions,
        format_func=lambda x: f"{x['title']} ({x['created_at'].strftime('%Y-%m-%d %H:%M')})"
    )
    
    if selected_question:
        st.write("---")
        st.write(f"## {selected_question['title']}")
        st.write(selected_question['description'])
        
        # íˆ¬í‘œ ìƒíƒœ í‘œì‹œ
        status_color = "ğŸŸ¢" if selected_question['status'] == 'active' else "ğŸ”´"
        st.write(f"ìƒíƒœ: {status_color} {selected_question['status'].upper()}")
        
        # ê¸°ë³¸ í†µê³„
        st.write(f"ì´ íˆ¬í‘œ ìˆ˜: {selected_question['total_votes']}")
        st.write(f"ì°¸ì—¬ì ìˆ˜: {selected_question['unique_voters']}")
        
        # ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
        results, voters = get_question_results(selected_question['question_id'])
        
        if results:
            # Print the column names for debugging
            print("Column Names:", results[0].keys())  # Debugging output

            # Create DataFrame with correct column names
            df_results = pd.DataFrame(results).astype({
                'vote_count': 'int64',
                'vote_percentage': 'float64'
            })
            
            # ì°¨íŠ¸ ê·¸ë¦¬ê¸°
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.write("### íˆ¬í‘œ ê²°ê³¼ ì°¨íŠ¸")
                fig = px.bar(
                    df_results,
                    x='option_text',
                    y='vote_count',
                    text='vote_count',
                    title="ì„ íƒì§€ë³„ íˆ¬í‘œ ìˆ˜",
                    labels={'option_text': 'ì„ íƒì§€', 'vote_count': 'íˆ¬í‘œ ìˆ˜'}
                )
                fig.update_traces(textposition='outside')
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                st.write("### ìƒì„¸ ê²°ê³¼")
                for result in results:
                    st.write(f"#### {result['option_text']}")
                    
                    # ì•ˆì „í•œ ê°’ ì¶”ì¶œ
                    vote_count = result.get('vote_count', 0) or 0
                    vote_percentage = result.get('vote_percentage', 0.0) or 0.0
                    
                    # ê²°ê³¼ í‘œì‹œ
                    st.write(f"íˆ¬í‘œ ìˆ˜: {vote_count} ({vote_percentage:.1f}%)")
                    
                    # ì„ íƒ ì´ìœ  í‘œì‹œ
                    if result.get('reasonings'):
                        with st.expander("ğŸ’¬ ì„ íƒ ì´ìœ  ë³´ê¸°"):
                            reasonings = result['reasonings'].split('\n')
                            for reasoning in reasonings:
                                if reasoning.strip():
                                    st.markdown(f"- {reasoning}")
            
            # íˆ¬í‘œì ëª©ë¡ (ìµëª… ì œì™¸)
            if voters:
                with st.expander("íˆ¬í‘œì ëª©ë¡ ë³´ê¸° (ìµëª… ì œì™¸)"):
                    for voter in voters:
                        st.write(f"- {voter['voter_name']} (ì‹ ë¢°ë„: {voter['credibility_score']:.2f})")
            
            # ê´€ë¦¬ì ê¸°ëŠ¥
            if selected_question['status'] == 'active':
                if st.button("íˆ¬í‘œ ì¢…ë£Œí•˜ê¸°"):
                    conn = connect_to_db()
                    cursor = conn.cursor()
                    try:
                        cursor.execute("""
                            UPDATE vote_questions
                            SET status = 'closed'
                            WHERE question_id = %s
                        """, (selected_question['question_id'],))
                        conn.commit()
                        st.success("íˆ¬í‘œê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                        st.rerun()
                    except mysql.connector.Error as err:
                        st.error(f"íˆ¬í‘œ ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {err}")
                    finally:
                        cursor.close()
                        conn.close()

        # LLM íˆ¬í‘œ ì„¹ì…˜
        st.write("---")
        st.write("## ğŸ¤– LLM íˆ¬í‘œ")
        
        col1, col2 = st.columns([1, 2])
        
        with col1:
            selected_model = st.selectbox(
                "LLM ëª¨ë¸ ì„ íƒ",
                get_available_models()
            )
            
            # LLM íˆ¬í‘œ ê°€ì¤‘ì¹˜ ì„¤ì •
            llm_weight = st.slider(
                "LLM íˆ¬í‘œ ê°€ì¤‘ì¹˜",
                min_value=1,
                max_value=10,
                value=1,
                help="LLMì˜ íˆ¬í‘œê°€ ëª‡ ëª…ì˜ íˆ¬í‘œì™€ ë™ì¼í•œ ê°€ì¤‘ì¹˜ë¥¼ ê°€ì§ˆì§€ ì„¤ì •í•©ë‹ˆë‹¤."
            )
            
            # RAG ì‚¬ìš© ì—¬ë¶€ ì„ íƒ
            use_rag = st.checkbox("ë¬¸ì„œ ì°¸ì¡° ì‚¬ìš© (RAG)", 
                                help="ì„ íƒí•œ ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ì—¬ ë‹µë³€í•©ë‹ˆë‹¤.")
            
            if use_rag:
                # íŒŒì¼ ì…ë ¥ ë°©ì‹ ì„ íƒ
                input_method = st.radio(
                    "ì°¸ì¡° ë¬¸ì„œ ì…ë ¥ ë°©ì‹",
                    ["íŒŒì¼ ì—…ë¡œë“œ", "ë””ë ‰í† ë¦¬ ê²½ë¡œ"]
                )
                
                context = ""
                if input_method == "íŒŒì¼ ì—…ë¡œë“œ":
                    uploaded_files = st.file_uploader(
                        "ì°¸ì¡°í•  íŒŒì¼ ì„ íƒ (ì—¬ëŸ¬ íŒŒì¼ ê°€ëŠ¥)",
                        accept_multiple_files=True,
                        type=['txt', 'md', 'pdf']
                    )
                    
                    if uploaded_files:
                        with st.spinner("íŒŒì¼ ì²˜ë¦¬ ì¤‘..."):
                            documents = load_files(uploaded_files)
                            if documents:
                                vectorstore = create_vectorstore(documents)
                                
                else:  # ë””ë ‰í† ë¦¬ ê²½ë¡œ
                    doc_directory = st.text_input(
                        "ì°¸ì¡°í•  ë¬¸ì„œ ë””ë ‰í† ë¦¬ ê²½ë¡œ",
                        help="ë§ˆí¬ë‹¤ìš´/í…ìŠ¤íŠ¸/PDF íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬"
                    )
                    
                    if doc_directory and os.path.exists(doc_directory):
                        with st.spinner("ë””ë ‰í† ë¦¬ ì²˜ë¦¬ ì¤‘..."):
                            documents = load_documents(doc_directory)
                            if documents:
                                vectorstore = create_vectorstore(documents)
            
            # LLM íˆ¬í‘œ ë²„íŠ¼
            if st.button("LLM íˆ¬í‘œ ì‹¤í–‰"):
                options = get_question_options(selected_question['question_id'])
                options_text = "\n".join([f"{i+1}. {opt['option_text']}" 
                                        for i, opt in enumerate(options)])
                
                context = ""
                if use_rag and 'vectorstore' in locals():
                    with st.spinner("ê´€ë ¨ ë¬¸ë§¥ ê²€ìƒ‰ ì¤‘..."):
                        context = get_relevant_context(
                            vectorstore,
                            selected_question['description'],
                            options_text
                        )
                        if context:
                            st.write("### ì°¸ì¡°í•œ ë¬¸ë§¥:")
                            st.write(context)
                
                # LLMì—ê²Œ ë¬¼ì–´ë³´ê¸°
                with st.spinner("LLM ì‘ë‹µ ëŒ€ê¸° ì¤‘..."):
                    llm_response = ask_llm(
                        selected_question['description'],
                        options_text,
                        selected_model,
                        context if use_rag else ""
                    )
                
                # ì‘ë‹µ íŒŒì‹± ë° ì €ì¥
                try:
                    selection, reasoning = parse_llm_response(llm_response)
                    
                    if selection < 1 or selection > len(options):
                        st.error(f"LLMì´ ì˜ëª»ëœ ì„ íƒì§€ ë²ˆí˜¸ë¥¼ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤: {selection}")
                        return
                    
                    save_llm_vote(
                        selected_question['question_id'],
                        options[selection - 1]['option_id'],
                        selected_model,
                        reasoning,
                        llm_weight
                    )
                    st.success(f"LLM íˆ¬í‘œê°€ ê°€ì¤‘ì¹˜ {llm_weight}ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.rerun()
                    
                except ValueError as e:
                    st.error(str(e))
                except Exception as e:
                    st.error(f"LLM ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        with col2:
            # ê¸°ì¡´ LLM íˆ¬í‘œ ê²°ê³¼ í‘œì‹œ
            llm_vote = get_llm_vote(selected_question['question_id'], selected_model)
            if llm_vote:
                st.write("### ğŸ¤– LLM íˆ¬í‘œ ê²°ê³¼")
                st.write(f"**ì„ íƒí•œ í•­ëª©:** {llm_vote['option_text']}")
                st.write("**ì„ íƒ ì´ìœ :**")
                st.write(llm_vote['reasoning'])
        
        # ê²°ê³¼ ë¹„êµ í‘œì‹œ
        st.write("---")
        st.write("## ğŸ“Š í†µí•© ê²°ê³¼ ë¹„êµ")
        
        # ì‹ ë¢°ë„ ê°€ì¤‘ì¹˜ ì ìš© ì—¬ë¶€ ì„ íƒ
        apply_weights = st.checkbox("ì°¸ì—¬ì ì‹ ë¢°ë„ ê°€ì¤‘ì¹˜ ì ìš©", 
                                  help="ì²´í¬í•˜ë©´ 00_12_ì‹ ë¢°ë„_ê°€ì¤‘ì¹˜_ë¶€ì—¬.pyì—ì„œ ì„¤ì •ëœ ì‹ ë¢°ë„ ì ìˆ˜ê°€ íˆ¬í‘œì— ë°˜ì˜ë©ë‹ˆë‹¤.")
        
        results = get_combined_results(selected_question['question_id'], apply_weights)
        if results:
            # Print the column names for debugging
            print("Combined Results Column Names:", results[0].keys())

            # Create DataFrame with correct column names
            df_results = pd.DataFrame(results)
            
            # Convert numeric columns to appropriate types
            numeric_columns = ['human_votes', 'weighted_llm_votes', 'total_votes']
            if apply_weights:
                numeric_columns.append('raw_human_votes')
            
            for col in numeric_columns:
                if col in df_results.columns:
                    df_results[col] = pd.to_numeric(df_results[col], errors='coerce').fillna(0).astype('int64')
            
            # ì¸ê°„ íˆ¬í‘œ ì°¨íŠ¸
            fig1 = px.bar(
                df_results,
                x='option_text',
                y='raw_human_votes' if apply_weights else 'human_votes',
                title=f"ì¸ê°„ íˆ¬í‘œ ê²°ê³¼ {'(ê°€ì¤‘ì¹˜ ì ìš© ì „)' if apply_weights else ''}",
                labels={'option_text': 'ì„ íƒì§€', 
                       'raw_human_votes': 'íˆ¬í‘œ ìˆ˜', 
                       'human_votes': 'íˆ¬í‘œ ìˆ˜'}
            )
            st.plotly_chart(fig1, use_container_width=True)
            
            if apply_weights:
                # ê°€ì¤‘ì¹˜ê°€ ì ìš©ëœ ì¸ê°„ íˆ¬í‘œ ì°¨íŠ¸
                fig_weighted = px.bar(
                    df_results,
                    x='option_text',
                    y='human_votes',
                    title="ì¸ê°„ íˆ¬í‘œ ê²°ê³¼ (ê°€ì¤‘ì¹˜ ì ìš© í›„)",
                    labels={'option_text': 'ì„ íƒì§€', 'human_votes': 'ê°€ì¤‘ì¹˜ ì ìš©ëœ íˆ¬í‘œ ìˆ˜'}
                )
                st.plotly_chart(fig_weighted, use_container_width=True)
            
            # í†µí•© ê²°ê³¼ ì°¨íŠ¸
            df_melted = pd.melt(
                df_results,
                id_vars=['option_text'],
                value_vars=['human_votes', 'weighted_llm_votes']
            )
            
            fig2 = px.bar(
                df_melted,
                x='option_text',
                y='value',
                color='variable',
                title=f"í†µí•© íˆ¬í‘œ ê²°ê³¼ (ì¸ê°„{' (ê°€ì¤‘ì¹˜ ì ìš©)' if apply_weights else ''} + LLM)",
                labels={
                    'option_text': 'ì„ íƒì§€',
                    'value': 'íˆ¬í‘œ ìˆ˜',
                    'variable': 'íˆ¬í‘œì ìœ í˜•'
                },
                barmode='stack'
            )
            
            # ë²”ë¡€ ì´ë¦„ ë³€ê²½
            fig2.update_traces(
                name=f"ì¸ê°„ íˆ¬í‘œ{' (ê°€ì¤‘ì¹˜ ì ìš©)' if apply_weights else ''}",
                selector=dict(name="human_votes")
            )
            fig2.update_traces(
                name="LLM íˆ¬í‘œ (ê°€ì¤‘ì¹˜ ì ìš©)",
                selector=dict(name="weighted_llm_votes")
            )
            
            st.plotly_chart(fig2, use_container_width=True)

if __name__ == "__main__":
    os.environ['PYTHONPATH'] = os.getcwd()
    main() 